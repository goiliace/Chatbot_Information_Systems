"game and logical reasoning, the application of information sensing, and processing. In games or simulation systems, the application of such artificial intelligence is extraordinarily rich. Some techniques, applied in the chess program, such as looking forward a few steps and breaking down complex problems into some easy subproblems, are developed. It evolved into the basic technology of artificial intelligence such as search and problem summarization. At present, the project technology is developing rapidly and amazingly [3].The next generation of artificial intelligence system will affect our life more widely. Artificial intelligence will make more critical and personalized decisions for human beings through interaction with the environment.The research goal of \"3S Smart Service System\" [4] is to build a universal access system based on technologies such as Internet of Things, cloud computing, and big data, which can accept intelligent industry, intelligent agriculture, intelligent logistics, intelligent transportation, smart grid, intelligent environmental protection, intelligent security, intelligent medical treatment and smart home, etc. Different types of IoT specific applications [5] provide common solutions for different application scenarios of IoT technology and achieve unified management and control. Considering that the system will be built into an intelligent system with massive data, scientific control, intelligent services, etc., the system is particularly"
"application scenarios of IoT technology and achieve unified management and control. Considering that the system will be built into an intelligent system with massive data, scientific control, intelligent services, etc., the system is particularly important for the storage, management, processing, and transmission of data. The secure storage, specification management, intelligent processing, and reliable transmission of service environment data will provide reliable guarantee for data volume and data accuracy for system computing and decision-making.Aiming at the problems existing in intelligent products or systems, this paper intends to adopt a support system model based on intelligent decision-making to design an intelligent information system based on Internet management optimization. The research focuses on intelligent information systems to integrate different intelligent products into the same system and, through big data and cloud computing technology, provide users with truly intelligent, personalized, automated full-service, without the need to control the system through user behavior. Considering the massive data characteristics of the system expansion, according to the existing fuzzy fusion algorithm, a fuzzy fusion algorithm based on weight is designed to provide more accurate and reliable raw data for the decision module of the system.The remains of this paper are organized into four sections. Section2contains related works of our research field. In Section3, we"
"algorithm based on weight is designed to provide more accurate and reliable raw data for the decision module of the system.The remains of this paper are organized into four sections. Section2contains related works of our research field. In Section3, we give the design of system model. Section4covers on the experimental and results. In the last section, we draw the discussion and conclusion over our research.2. Related WorkDecision support system (DSS) is a computer application system that assists decision-makers to make semistructured or unstructured decisions by human-computer interaction through data, model, and knowledge [7]. It is an advanced information management system produced by the development of management information system (MIS) to a higher level. It provides an environment for decision- makers to analyze problems, establish models, simulate decision-making processes and schemes, and call various information resources and analysis tools to help decision-makers improve decision-making level and quality. Because DSS requires decision-makers to participate, man-machine dialogue is used to manipulate data through models. What is supported is only the structured and clearly procedural part of the decision-making process. The core content of decision support system is human-computer interaction. In order to help decision-makers deal with semistructured and unstructured problems, identify objectives and environmental constraints, further clarify problems, generate"
"process. The core content of decision support system is human-computer interaction. In order to help decision-makers deal with semistructured and unstructured problems, identify objectives and environmental constraints, further clarify problems, generate decision schemes, and comprehensively evaluate decision schemes, the system should have stronger human-computer interaction ability and become an interactive system. As the decision-making environment becomes more complex, the limitations of DSS in decision support are becoming more prominent:(1)Decision support system uses a static model to operate the data through the model. DSS is a system that makes comprehensive use of a large amount of data, organically combines many models, and assists decision-makers at all levels to realize scientific decision-making through human-computer interaction. The role of the system in decision support is passive and cannot be based on the decision environment. Changes provide active support [8,9].(2)Decision support system is modeled by the decision-makers and requires decision-making problems with procedural and clear computability [10,11], which cannot support the unstructured problems that are common in decision-making.(3)Decision support system is not a general product, but a solution. Each enterprise should combine its own situation, clarify the management difficulties to be solved, and then analyze, design, develop, and implement the decision support system, so as to truly meet the"
"system is not a general product, but a solution. Each enterprise should combine its own situation, clarify the management difficulties to be solved, and then analyze, design, develop, and implement the decision support system, so as to truly meet the needs of enterprise management decision-making. DSS is based on quantitative mathematical models and lacks corresponding support methods for qualitative, fuzzy, and uncertain problems in decision-making [12,13].Intelligent decision support system (IDSS) is a combination of artificial intelligence (AI) and DSS and applies expert system (ES) technology to enable DSS to more fully apply human knowledge, such as descriptive knowledge about decision-making problems and procedural knowledge in the decision-making process. Introducing AI technology into DSS is mainly through the combination of expert system and DSS and adding inference engine and rule base to DSS system. In the decision-making process, many knowledge amounts cannot be expressed by data or described by models, so there is no fixed way of expertise and historical experience. Researchers integrate AI technology into DSS, mainly through the combination of expert system and DSS, and add inference engine and rule base to DSS system. The rule base introduced by IDSS can store these knowledge amounts and provide important reference and basis for decision-making. IDSS can have many types of information bases: text base (TB), database (DB), arithmetic base (AB), model base (MB),"
"system. The rule base introduced by IDSS can store these knowledge amounts and provide important reference and basis for decision-making. IDSS can have many types of information bases: text base (TB), database (DB), arithmetic base (AB), model base (MB), and rule base (RB). The text library stores a large number of documents written in natural language. The database stores the field form of the key factors of things. Various models reflecting the essential relationship of information are stored in the model base. Rule base is the most refined form of knowledge. From the original unprocessed data to the processed information and then to the extracted knowledge, this evolution relationship of information is called evolution chain.From the viewpoint of system level, IDSS can be technically divided into three levels:(1)The application layer is directly oriented to IDSS users. In this layer, decision-makers can determine the status and constraints of IDSS according to their own needs. Decision-makers conduct system dialogue and input relevant information through the user interface; DSS understands user requests and commands through information conversion, carries out system reasoning operation, and reflects the results to users through the output interface. The whole process is transparent to users.(2)Control and coordination layer, for the chief designer of IDSS: its basic unit is the control and coordination module of the system central library. The system engineer establishes"
"through the output interface. The whole process is transparent to users.(2)Control and coordination layer, for the chief designer of IDSS: its basic unit is the control and coordination module of the system central library. The system engineer establishes the relationship between them through the standard interface of each library.(3)The basic structure layer is for professional programmers. Professional programmers implement each library through this layer, specifically defining the organizational structure and communication mode of each library, so as to complete the department management and external communication tasks of each library.During the operation of IDSS, each module needs to call the upper bridge repeatedly, which is less efficient than using the low-level call directly. However, considering that IDSS only operates when senior managers make major decisions, its operation frequency is much lower than that of other information systems, and the environmental conditions of each operation are very different; it is completely worth sacrificing part of the operation efficiency in exchange for the efficiency of system maintenance [14-16].With the development of computer and artificial intelligence technology, the research focus of IDSS has gradually shifted from expert IDSS to the research of IDSS model system, man-machine interface, knowledge processing unit, and distributed IDSS. Distributed IDSS introduces distributed artificial intelligence (DAI) technology on the"
"focus of IDSS has gradually shifted from expert IDSS to the research of IDSS model system, man-machine interface, knowledge processing unit, and distributed IDSS. Distributed IDSS introduces distributed artificial intelligence (DAI) technology on the basis of knowledge-based IDSS. Its main idea is to use agent and multiagent system technology in Da; that is, agents playing different roles are designed as intelligent agents of modules according to the main functional modules in IDSS [17]. Through the self-learning mechanism, it simulates the different steps of human intelligence to complete the decision-making task, so as to make scientific decision-making. Distributed IDSS mainly designs and establishes large-scale and complex intelligent decision support system supported by Internet [18].Expert system tools and technologies can be integrated into decision support system to provide users with consulting environment to improve decision quality and complete functions that conventional decision support system cannot complete. However, expert system is different from decision support system. When using decision support system, users must have certain professional knowledge and skills for the problems they deal with; that is, users should know how to reason about the problems, what questions should be put forward, how to get the answer, and how to proceed to the next step. At this time, the decision support system can only assist users to make decisions. However, the expert"
"users should know how to reason about the problems, what questions should be put forward, how to get the answer, and how to proceed to the next step. At this time, the decision support system can only assist users to make decisions. However, the expert system is different. It itself has the professional knowledge of experts in a certain field to solve problems. Users only need to put forward the facts and appearances of the problem to the expert system.3. System Model Design3.1. Intelligent Decision Support SystemSince the emergence of the intelligent decision support system, due to the great potential of expert system technology in the field of management decision-making, researchers at home and abroad have conducted a lot of research, integrating tools and methods such as computer science and artificial intelligence with human decision-making processes [19]. Intelligent decision system supports structure and function [20]. Holsapple summarized the system's support ability and learning ability for decision-making process and divided IDSS into 4 categories [21]: no adaptive, passive support; no adaptive, which can provide active support; adaptive, passive support; adaptive, active support.3.1.1. Active Decision Support SystemThe traditional decision support system provides the corresponding data and model, and the user chooses the corresponding method and model. The decision process is completely controlled by the user. The system only completes the auxiliary computing"
"SystemThe traditional decision support system provides the corresponding data and model, and the user chooses the corresponding method and model. The decision process is completely controlled by the user. The system only completes the auxiliary computing function. Like many developing things, active decision support system (ADSS) is a developing concept. The intelligent decision support system has part of the domain expert knowledge. Human intelligence has the ability of actively supporting decision-making. ADSS can change its behavior with the user's decision-making process, which is an important milestone in the research of decision support system, which is generated by intelligent decision support system [7]. Active decision-making is an important feature of ADSS. By establishing a human cognitive model, ADSS can provide decision-makers with different choices in different problem solving stages, thus forming different problem solving paths. ADSS provides decision-makers with different method choices at different stages of decision-making problem solving by establishing human cognitive model. ADSS is based on human prior knowledge, but its premise is that the system runs in a static decision-making environment. Therefore, ADSS still has the limitation of poor adaptability in practical application. However, the research on ADSS lays a foundation for the proposal of adaptive decision support.3.1.2. Adaptive Decision Support SystemADSS relies mainly on human prior knowledge."
"ADSS still has the limitation of poor adaptability in practical application. However, the research on ADSS lays a foundation for the proposal of adaptive decision support.3.1.2. Adaptive Decision Support SystemADSS relies mainly on human prior knowledge. The operating environment of the system is static. The domain knowledge and reasoning knowledge required for decision-making are known in advance. In fact, the decision-making environment is usually changeable, and the problem solving process is closely related to the decision-making environment. In relation to this, the knowledge that humans possess and can use for reasoning is also limited. Therefore, the above ADSS knowledge structure and function have many limitations. Adaptive decision support system is an important step toward better support decision. Adaptability is based on the environmental changes of the system and improves the ability of the system of dealing with problems. In order to overcome the limitations of ADSS in knowledge structure, data mining, data warehousing, case-based reasoning, and other data-driven decision support methods and machine learning techniques are adopted. Algorithms such as ANN, GA, and ROUGH SET attempt to discover knowledge that is critical to decision-making from a large amount of historical data and past experience, so that the system has the ability of adjusting its behavior over time and decision process changes, thus generating adaptive decision-making support system (ADSS)"
"is critical to decision-making from a large amount of historical data and past experience, so that the system has the ability of adjusting its behavior over time and decision process changes, thus generating adaptive decision-making support system (ADSS) [22].The researchers try to find the knowledge related to decision-making problems from a large number of historical data and past experience by using machine learning and case-based reasoning, so as to make the system have the ability of adjusting its behavior with the change of time and decision-making process. On this basis, people have carried out a lot of research on ADSS, including system structure adaptation, domain knowledge adaptation, and user interface adaptation. Adaptability and self-learning ability have become a main symbol of intelligent decision support system. ADSS has logic-based reasoning in addition to traditional process calculations and other forms of reasoning and also uses inductive reasoning to implement dynamic knowledge systems. Inductive reasoning is a kind of nonmonotonic reasoning, which can be limited or incomplete knowledge. The state introduces a complete state of knowledge. Through inductive learning, ADSS has a certain ability of innovating and can use inductive assertions as knowledge. When new contradictions are contradictory, the knowledge obtained by inductive reasoning can be overthrown, thus maintaining the consistency of knowledge [23].3.1.3. Decision Expert SystemThe decision"
"and can use inductive assertions as knowledge. When new contradictions are contradictory, the knowledge obtained by inductive reasoning can be overthrown, thus maintaining the consistency of knowledge [23].3.1.3. Decision Expert SystemThe decision expert system is a decision support system established by using expert technology. The decision expert system uses deductive reasoning and uses existing knowledge to derive conclusions. The correctness of the derivation process can be guaranteed. The problem of this system is that a complete axiom system is needed for the basis of reasoning. In fact, in the environment of uncertain, abrupt, and fuzzy information, this condition is difficult to achieve, so it is only suitable for the application of well-defined decision-making tasks. In recent years, the progress of artificial intelligence and expert system technology seems to break through the limitations of traditional decision-making expert systems; the application of nonmonotonic reasoning and qualitative reasoning technology is broadening the application scope of expert systems and has made some progress in combination with human intelligence [24].3.1.4. Holistic Decision Support SystemThe integrated decision support system is based on the adaptive decision support system and the decision expert system [7]. In the process of human expert decision-making, it faces incomplete, uncertain, and even conflicting knowledge, and human thinking often has nonprocesses. Sexuality"
"is based on the adaptive decision support system and the decision expert system [7]. In the process of human expert decision-making, it faces incomplete, uncertain, and even conflicting knowledge, and human thinking often has nonprocesses. Sexuality generally leads to decision-making through the synthesis of various knowledge and processes. The integrated decision support system (HDSS) emerges to mimic human advanced intelligence and can make full use of human in process analysis, logical reasoning, and cognition and learning. And it has the advantages of knowledge innovation, so that the system's auxiliary decision-making ability transcends the stage of fact, reasoning, and learning and can support the decision-making problem of ill-structured structure [25].The application of Internet technology in the field of decision support makes the decision environment have new characteristics; that is, the data in decision analysis are no longer concentrated in one physical location, but scattered in different departments or regions. The above discussion about the types of decision support systems is based on the main characteristics of the system, from the perspective of the development of system intelligence. Several types are mutually contained and complementary. More advanced models reflect the evolution of system intelligence [26,27], Excluding other types of features. In the big data environment, distributed decision support system will get more and more attention. In fact,"
"mutually contained and complementary. More advanced models reflect the evolution of system intelligence [26,27], Excluding other types of features. In the big data environment, distributed decision support system will get more and more attention. In fact, the research of intelligent decision support systems is showing a trend of integration [7]. Existing systems are generally hybrid systems formed by a combination of methods, with several models characteristics. Uncertainty is the key problem in the current research of artificial intelligence technology, and it is also the core problem throughout the whole process of big data intelligent decision-making. Table1compares several IDSSs from the aspects of system learning ability, intelligent behavior, and decision-making methods.Table  1.Comparison of IDSS models.SystemKnowledge base typeCompleteness of knowledgeKnowledge innovation abilityDecision process understandingMain reasoningMain decision-making toolActive decision support systemStaticCompleteness without conflictNoHaveAdopt a predefined processData, cognitive modelDecision expert system staticStaticCompleteness without conflictNoMaybe do not haveDeductive reasoningKnowledge baseAdaptive decision support systemDynamicAllowing incompleteness and conflictYesGenerally haveDeductive and inductive reasoningData, intelligent decision model, and knowledge baseIntegrated decision support systemDynamicAllowing incompleteness and conflictYesHaveDeductive, inductive, and"
"incompleteness and conflictYesGenerally haveDeductive and inductive reasoningData, intelligent decision model, and knowledge baseIntegrated decision support systemDynamicAllowing incompleteness and conflictYesHaveDeductive, inductive, and case-based reasoningCognitive model, intelligent computing method, machine learning, and knowledge base3.2. Intelligent Information System Requirements AnalysisSince the beginning of the 21st century, the wave of globalization has driven the rapid development of the social economy, and the quality of human life has been continuously improved. Together with the rapid development of information technology, human beings have begun to pursue the information technology and intelligence of the living environment. Such powerful human subjective needs have spawned the birth of intelligent information systems. Although the intelligent information products have been developed over a long period of time, this paper has found that the existing smart products or systems still have the following shortcomings after investigating the existing products or systems in the market:(1)Manufacturer's products are singularly mass-produced.The existing smart device manufacturers only carry out mass production of a single product and do not systematically carry out product design and mass production and do not form a unified industry standard or access standard resulting in a mixed market of products and systems. There is poor compatibility between the two; new"
"of a single product and do not systematically carry out product design and mass production and do not form a unified industry standard or access standard resulting in a mixed market of products and systems. There is poor compatibility between the two; new products are difficult to access the system.(2)The system control layer does not achieve true intelligence.In response to the above problems (1), many manufacturers have proposed their own intelligent system solutions, integrating different types of products into the system and providing decision control functions, realizing remote control, security alarm, and other functions. However, the decision-making control layer of the system is not intelligent, but the user behavior is used for control or decision-making; that is, the user needs to manually adjust it.(3)The pressure on data processing of system servers in the Internet of Things has increased dramatically.Most of the existing intelligent products use the intelligent gateway for data forwarding, and all the original data is sent to the remote server for analysis, storage, processing, etc. After the user scale is expanded, all the user's original data is processed by the remote server. The pressure on servers is getting bigger and bigger, and the cost of expansion is getting higher and higher.In view of the shortcomings of the above existing intelligent products or systems, the intelligent system studied in this paper hopes to make improvements and finally build a"
"bigger and bigger, and the cost of expansion is getting higher and higher.In view of the shortcomings of the above existing intelligent products or systems, the intelligent system studied in this paper hopes to make improvements and finally build a gateway that can provide a unified device interface, realize decision control intelligence, and include local data storage and processing functions. The intelligent information system of the device provides users with systematic, automated, intelligent, and personalized services.3.3. Hierarchical Structure Design of Intelligent Information SystemThe structure of the Internet of Things itself is complex and diverse. The current structure of an Internet of Things is divided into three levels: the perception layer, the network layer, and the application layer.The bottom layer of the Internet of Things is the perception layer, which is the basis for realizing the comprehensive perception of the Internet of Things. RFID, sensors, two-dimensional code, etc., are mainly used to collect device information with sensors and use radio frequency identification technology to achieve transmission and recognition within a certain range. The main function is to identify objects and collect information through sensing devices.The network layer is located above the sensing layer and is a network device and platform that serves the aggregation, transmission, and preliminary processing of IoT information. Through the existing three-network or"
"information through sensing devices.The network layer is located above the sensing layer and is a network device and platform that serves the aggregation, transmission, and preliminary processing of IoT information. Through the existing three-network or next-generation network NGN, the huge amount of data collected from the sensor network is seamlessly transmitted over long distances; it is responsible for the secure transmission of the information collected by the sensor and the analysis of the collected information, processing and providing the results to the application layer.The application layer is the top layer of the Internet of Things architecture. It mainly solves the problem of information processing and human-machine interface and provides the information services that people need through data processing and solutions. The application layer directly contacts the user and provides users with rich service functions. The user customizes the required service information, such as query information, monitoring information, and control information, on the application layer through the smart terminal.The application of Internet of Things technology in the service environment mainly focuses on home appliance automation and intelligent security systems. Home appliance automation is installing sensors in traditional household electrical appliances (such as air conditioners, TVs, and refrigerators), making them intelligent, nodding them, and accessing the Internet, so that"
"and intelligent security systems. Home appliance automation is installing sensors in traditional household electrical appliances (such as air conditioners, TVs, and refrigerators), making them intelligent, nodding them, and accessing the Internet, so that users can realize remote control of home appliances in the sky. The intelligent security system is equipped with sensor nodes for monitoring fire, gas concentration, etc., at home, so that the user gets the first time alarm feedback when there is a fire in the home and can timely handle the danger or escape in time to avoid personnel casualties.The basic framework of an intelligent information system can be divided into three layers: the environment-awareness layer, the network transmission layer, and the smart service application layer as shown in Figure1.Figure 1Open in figure viewerPowerPointIntelligent information system hierarchy diagram.3.3.1. Environment-Aware LayerThe environment-aware layer is the bottom layer of the system. If an analogy is made by one person, the environment-aware layer is like a human tactile nerve, which is composed of a large number of environmental information sensors. These sensors are like a neural node, distributed in every corner of the environment, collecting environmental information and sending the collected data to the upper layer of the intelligent information system through a certain short-range wireless transmission technology.From the perspective of network technology, the sensor"
"environment, collecting environmental information and sending the collected data to the upper layer of the intelligent information system through a certain short-range wireless transmission technology.From the perspective of network technology, the sensor of the environment-aware layer constructs a WPAN network within a certain range. The so-called WPAN is a network proposed to solve the \"last few meters of wireless communication connection\". Generally, this refers to short-range wireless networks with coverage within a radius of 10 m, especially for self-organizing networks that can be connected shortly between portable consumer appliances and communication devices. WPAN is a network that is parallel with wireless wide area network (WWAN), wireless metropolitan area network (WMAN), and wireless local area network (WLAN) but has a smaller coverage. The corresponding relationship is shown in Figure2.Figure 2Open in figure viewerPowerPointCorrespondence between WPAN and other wireless networks.3.3.2. Network Transport LayerThe network transport layer is the middle layer of the intelligent information system of the service environment, which assists network communication and data transmission between the entire system levels. It includes communication between environmental information collection sensors, communication between environmental information collection sensors and terminals, and communication between terminals and smart cloud platforms.3.3.3. Smart Service Application"
"includes communication between environmental information collection sensors, communication between environmental information collection sensors and terminals, and communication between terminals and smart cloud platforms.3.3.3. Smart Service Application LayerThe intelligent service application layer is the uppermost layer of the system and is the concentrated expression of the intelligence of the information system oriented to the service environment. It mainly includes the following functions:(a)Cloud data storage and management(b)Inducting user habits and building user knowledge base(c)Smart decision based on user habits(d)Sending control commands to the lower layer of the systemIf one person is used as an analogy, the intelligent service application layer is equivalent to the human brain, which can store memory, intelligently think, make optimal decisions, and control other parts of the human body through neural networks. The intelligent service layer learns knowledge through machine learning algorithms and makes decisions to control the underlying devices of the system.3.4. Improvement of Data Fusion AlgorithmThe limitations of the fuzzy fusion algorithm in the current environment are mainly reflected in the two aspects of time efficiency and energy consumption. The improvement of the algorithm will also start from these two aspects: first, it reduces the amount of data to be fused by setting a reasonable threshold to improve the fusion algorithm by setting weights for"
"of time efficiency and energy consumption. The improvement of the algorithm will also start from these two aspects: first, it reduces the amount of data to be fused by setting a reasonable threshold to improve the fusion algorithm by setting weights for data that fails to pass the threshold.In an intelligent information system, assuming that there arensensor nodes, they can form 2n− 1 sensor groups. As the number of nodesnincreases, the number of sensor groups increases exponentially. Each sensor group performs the calculation of the tolerance function and the fuzzy measure function, which will generate a huge amount of computation and take a lot of time. Correspondingly, if we can reduce the number ofnparticipating in the operation by a certain method, the calculation amount and time consumption of the algorithm will decrease exponentially. Therefore, reducing the amount of data with fusion is an effective way to solve the above problems.Assuming that the system enters a stable data transmission phase, if the monitoring index does not fluctuate significantly over a period of time, then this part of the data is relatively small for system decision-making. The method designed in this paper is to record the result of each fusion and set an appropriate threshold. The data to be transmitted is compared and decided to be retained or deleted. The results of the reservation are directly involved in the final fusion, and the data to be deleted is given a weight, giving it the"
"fusion and set an appropriate threshold. The data to be transmitted is compared and decided to be retained or deleted. The results of the reservation are directly involved in the final fusion, and the data to be deleted is given a weight, giving it the opportunity to reengage. The main process of the algorithm is as follows:Suppose that the output set ofnsensors is(1)After performing a fusion, the result of the fusion is recorded asC0, and, in addition, the threshold is set as(2)In the next fusion, the node outputxiis compared withThr. Ifxi∈Thr, the data is deleted and the change output isx1,x2, ...,xm,m≤n. There are three key points here: the selection of thresholds, the processing of deleted data, and the improvement of weight-based algorithms.3.4.1. Threshold SelectionChoosing the appropriate threshold is especially important in the improvement of the algorithm. If the threshold is selected to be too large, it will not be able to mask invalid data, and the accuracy of the data will be greatly reduced. If the threshold is selected to be too small, it will cause the data to be deleted and screened out in the next comparison, which will result in the algorithm. The amount of calculation and time consumption are not much different from those before the threshold is taken, and the meaning of the improved algorithm is lost. According to the aboveformula(2), the selection of the threshold in this paper is based on the result of the previous fusion C0. Here, we consider the"
"different from those before the threshold is taken, and the meaning of the improved algorithm is lost. According to the aboveformula(2), the selection of the threshold in this paper is based on the result of the previous fusion C0. Here, we consider the fusion of temperature data.Assume the following scenario: after the user enters the service environment, the room temperature is 8°C. The intelligent information system sets the air conditioner temperature to 25°C according to the user's habit. After the air conditioner is turned on, the room temperature rise curve is shown in Figure3.Figure 3Open in figure viewerPowerPointThe room temperature rise curve.From the figure, we can see that, in the first few minutes, since the main engine has just started running after the air conditioner is started, the heating effect is not obvious and the temperature is almost changed. With the normal operation of the air conditioner main unit, the heating effect begins to appear and the temperature rises faster; later, as the room temperature has risen, the temperature rise requires more heat, so the temperature rise tends to be slow.In this scenario, the fuzzy fusion of the temperature data is carried out. Obviously, the data in the first few minutes and the last few minutes shows a lot of redundancy, and some data can be eliminated by setting the threshold. After repeated experiments and measurements, this paper selectsμ= 0.5, which is the threshold of(3)3.4.2. Delete Data ProcessingIn the"
"minutes and the last few minutes shows a lot of redundancy, and some data can be eliminated by setting the threshold. After repeated experiments and measurements, this paper selectsμ= 0.5, which is the threshold of(3)3.4.2. Delete Data ProcessingIn the above threshold elimination process, the data within the threshold range is directly deleted, but if the amount of data deleted is large, it will also cause distortion of the final fuzzy fusion result. In order to prevent this from happening, this paper introduces a processing mechanism for deleting data, which is to give the data a weight value to reflect its importance in the system.The weight value mechanism of this paper is to assign a weightWto each data to be fused. The default value isW= 1.Wrepresents the number of data amounts similar to the data andW= 1 means that the data can only represent itself.According to the above, assuming that the result of the last fuzzy fusion isC0, a weighted data to be mergedxiis compared with the threshold value (3), and ifxi∈Thr, whether it is the first data entering the thresholdThr, then,C0is assigned toxi, and the weightWis still 1; the data that enters the thresholdThragain can be directly deleted, but each time a data enters the threshold the weightWofC0is increased by 1, indicating that the number of data amounts similar toC0is increased by one. Ifxi∉Thr, the data is not adjusted, participating in the next fusion, and the weightWis still 1. This process can be represented in"
"the threshold the weightWofC0is increased by 1, indicating that the number of data amounts similar toC0is increased by one. Ifxi∉Thr, the data is not adjusted, participating in the next fusion, and the weightWis still 1. This process can be represented in Figure4.Figure 4Open in figure viewerPowerPointData processing process that introduces weight values.3.4.3. Weight-Based Algorithm ImprovementSince the weight of the data to be merged is introduced, the fuzzy measure function of the traditional fuzzy fusion algorithm cannot be directly used, and corresponding improvement is needed. The following describes the improvement of the fuzzy measure.The fuzzy measure function reflects the reliability of the sensor group participating in the calculation. The range is between [0, 1]. The more the number of sensors participating in the fusion, the larger the fuzzy measure value and the higher the reliability. Otherwise, the number of participating sensors is less than the fuzzy measure value and thus the reliability is lower.Assume, that in the home service environment, the number of sensors in the sensor group isn. When the number of participating sensors ismwhen a data is fused, the reliability can be expressed asm/n.The result of the previous fusion isC0. After the next fusion, all data is compared with the thresholdT, and the weight ofC0isW=i.IfC0is not included in the sensor group data to be calculated,m/nis still used as the result of the fuzzy measure. IfC0is included in the"
"the previous fusion isC0. After the next fusion, all data is compared with the thresholdT, and the weight ofC0isW=i.IfC0is not included in the sensor group data to be calculated,m/nis still used as the result of the fuzzy measure. IfC0is included in the sensor group data to be calculated, the fuzzy measure of the sensor group can be expressed by(4)The improved fuzzy measure guarantees the integrity of the data and makes the fusion result more accurate.4. Designs and Analysis4.1. System Architecture DesignThis paper participates in the design of the presidential architecture of a service-oriented intelligent information system, as shown in Figure5.Figure 5Open in figure viewerPowerPointIntelligent information system architecture diagram.The intelligent information system is divided into functional modules, and the specific functions are designed. The functional modules include information collection template, data processing module, knowledge management module, decision control module, and device adjustment module. Their relationship to each other is shown in Figure6.Figure 6Open in figure viewerPowerPointIntelligent information system function module diagram.The data collected by the information acquisition module is the most primitive data prototype obtained by the data processing module. It is the nerve ending of the entire intelligent information system and collects the information of the surrounding environment as accurately as possible for system processing,"
"is the most primitive data prototype obtained by the data processing module. It is the nerve ending of the entire intelligent information system and collects the information of the surrounding environment as accurately as possible for system processing, calculation, and decision-making.The data processing module is a template for the intelligent information system. First, data is collected as input, then stored locally, and then preprocessed to provide a more accurate and reliable data prototype for the knowledge management module and decision control module.The knowledge management module is a positioning in the intelligent information system, which is equivalent to a memory module in the human brain. Its input mainly comes from the data prototype provided by the data processing module, and the output is the user habit obtained by massive data accumulation and data mining. These data are stored in the database together with the data prototype and, on the other hand, as decision control. The data also can be input to the module for reference by the decision control module.The decision control module is mainly responsible for making comprehensive decision judgments based on the information transmitted by the data processing module and the knowledge management module and producing control instructions.The device adjustment template is one of the ends of the intelligent information system, receives the control command of the decision control module as an input, and performs"
"module and the knowledge management module and producing control instructions.The device adjustment template is one of the ends of the intelligent information system, receives the control command of the decision control module as an input, and performs input information to control the device parameters.4.2. Experimental Analysis of Improved Data Fusion AlgorithmIn this section, by setting the specific application scenarios, the data is simulated by MATLAB, and the traditional fuzzy fusion algorithm and the improved algorithm are compared and analyzed.4.2.1. Comparison of the Number of Participating NodesFirst of all, this paper separately compares the number of sensors participating in each fusion of the two algorithms and obtains the results of Figure7as follows.Figure 7Open in figure viewerPowerPointComparison of the number of participating nodes.In Figure7, the blue dot curve represents the traditional data fusion algorithm, and the orange dot curve represents the improved fuzzy fusion algorithm. As can be seen from the figure, in the traditional algorithm, the number of nodes participating in the fusion has been fluctuating around 90∼100; this means that, in every fusion process, almost all the data collected by the nodes will participate, which will cause huge calculations and consume system resources and time. The improved fusion algorithm has dropped significantly by half since the second fusion and then basically maintains a stable fluctuation around 50. This shows"
"will participate, which will cause huge calculations and consume system resources and time. The improved fusion algorithm has dropped significantly by half since the second fusion and then basically maintains a stable fluctuation around 50. This shows that, from the second time, the number of nodes participating in the fusion is significantly reduced. That is, setting a reasonable threshold makes the number of nodes participating in the fusion greatly reduced. From the previous analysis, we already know that when there arennodes participating in the fusion, 2n− 1 kinds of node combinations will be generated. Whennis reduced, the number of node combinations will decrease exponentially, which will greatly reduce the calculation amount of the system and improve the timeliness of data processing. Therefore, in the improved fuzzy fusion algorithm, it is feasible and effective to reduce the amount of data to be fused by setting a reasonable threshold.4.2.2. Comparison of Fusion ResultsAt the same time, the fusion results of the traditional fuzzy fusion algorithm and the improved weight-based fuzzy fusion algorithm are compared. The comparison results are shown in Figure8.Figure 8Open in figure viewerPowerPointComparison of fusion results.In Figure8, the blue dot curve represents the temperature fusion result of 50 fusions by the traditional fuzzy fusion algorithm, and the orange dot curve represents the temperature fusion result of the improved weight-based fuzzy fusion algorithm."
"results.In Figure8, the blue dot curve represents the temperature fusion result of 50 fusions by the traditional fuzzy fusion algorithm, and the orange dot curve represents the temperature fusion result of the improved weight-based fuzzy fusion algorithm. It can be seen from the figure that the curve of the improved algorithm is more consistent with the curve of the improved algorithm and the error is smaller. This shows that the improved algorithm can still accurately integrate the data and the improved algorithm is accurate and reliable.5. ConclusionsSince the introduction of the concept of intelligent decision-making information system, after years of research and development, it has gradually entered the practical stage of the market. With the rapid development of technologies such as Internet of Things, big data, and cloud computing, its research has gradually focused on the wisdom of the system level. In view of the shortcomings of existing intelligent products or systems, this paper designs a data processing module of intelligent information system, considers the problem of data fusion after system expansion, and improves the data fusion algorithm. According to the analysis of requirements, the intelligent information system is designed, and the three-layer architecture of the system based on intelligent decision-making is proposed, including the sensing layer, the network transmission layer, and the intelligent service application layer. The module construction is"
"system is designed, and the three-layer architecture of the system based on intelligent decision-making is proposed, including the sensing layer, the network transmission layer, and the intelligent service application layer. The module construction is decomposed to explain how the modules interact with each other to cooperate in work. Considering the massive data problem after the expansion of intelligent information system, the data fusion algorithm is compared and improved according to the traditional fuzzy fusion algorithm. A weight-based fuzzy fusion algorithm is proposed to make it more adaptable to massive data and improve the accuracy and reliability of system data. Through the simulation diagram, the improved algorithm and the traditional algorithm are compared and analyzed, and the effectiveness of the weight-based fuzzy fusion algorithm is verified.Conflicts of InterestThe authors declare that they have no conflicts of interest.AcknowledgmentsThis work was supported by Qing Lan Project, Changzhou Key Laboratory of Industrial Internet and Data Intelligence (no. CM20183002), and Major Cultivating Projects of CZIMT (2019ZDXM09).Open ResearchData AvailabilityThe authors will make data available on request through a data access committee.References1Vemulapalli V.,Qu J.,Garren J. M.,Rodrigues L. O.,Kiebish M. A.,Sarangarajan R.,Narain N. R., andAkmaev V. R.,Non-obvious correlations to disease management unraveled by bayesian artificial intelligence analyses of CMS"
"a data access committee.References1Vemulapalli V.,Qu J.,Garren J. M.,Rodrigues L. O.,Kiebish M. A.,Sarangarajan R.,Narain N. R., andAkmaev V. R.,Non-obvious correlations to disease management unraveled by bayesian artificial intelligence analyses of CMS data,Artificial Intelligence in Medicine. (2016)74,1-8,https://doi.org/10.1016/j.artmed.2016.11.001, 2-s2.0-84997282757.10.1016/j.artmed.2016.11.001PubMedWeb of Science®Google Scholar2Xiong H.,Wang X., andZhu Y.,Modeling and verification of real-time interaction for IEC 61850 intelligent electronic device,Automation of Electric Power Systems. (2014)38, no. 19,90-95.Google Scholar3Dzikovska M.,Steinhauser N.,Farrow E.,Moore J., andCampbell G.,Beetle II: deep natural language understanding and automatic feedback generation for intelligent tutoring in basic electricity and electronics,International Journal of Artificial Intelligence in Education. (2014)24, no. 3,284-332,https://doi.org/10.1007/s40593-014-0017-9, 2-s2.0-84903699960.10.1007/s40593-014-0017-9Google Scholar4Zhu H.,Coordination innovation architechture for IoT and development strategy of smart service industry,Journal of Nanjing University of Posts & Telecommunications. (2014)34, no. 1,1-9.Google Scholar5Brambilla M.,Umuhoza E., andAcerbis R.,Model-driven development of user interfaces for IoT systems via domain-specific components and patterns,Journal of Internet Services and Applications. (2017)8, no. 1,https://doi.org/10.1186/s13174-017-0064-1,"
"Scholar5Brambilla M.,Umuhoza E., andAcerbis R.,Model-driven development of user interfaces for IoT systems via domain-specific components and patterns,Journal of Internet Services and Applications. (2017)8, no. 1,https://doi.org/10.1186/s13174-017-0064-1, 2-s2.0-85029936829.10.1186/s13174-017-0064-1Google Scholar6Bell M. C.,Environmental factors in future transport,Cuestiones Constitucionales. (2010)59, no. 18,349-356.Google Scholar7Sun X.,Li Q., andSun C.,Research on fuzzy adaptive intelligent decision-making in complex environment,Journal of Physics: Conference Series. (2019)1345, no. 5, 052085,https://doi.org/10.1088/1742-6596/1345/5/052085.10.1088/1742-6596/1345/5/052085Google Scholar8Phillips-Wren G.,Mora M.,Forgionne G. A., andGupta J. N. D.,An integrative evaluation framework for intelligent decision support systems,European Journal of Operational Research. (2009)195, no. 3,642-652,https://doi.org/10.1016/j.ejor.2007.11.001, 2-s2.0-56349150611.10.1016/j.ejor.2007.11.001Web of Science®Google Scholar9Rydahl P.,Hagelskjaer L., andPedersen L.,User interfaces and system architecture of a web-based decision support system for integrated pest management in cereals,Eppo Bulletin. (2010)33, no. 3,473-481.10.1111/j.1365-2338.2003.00684.xGoogle Scholar10Fan S. C.andYu K. C.,How an integrative STEM curriculum can benefit students in engineering design practices,International Journal of Technology & Design Education. (2015)27, no. 1,1-23,https://doi.org/10.1007/s10798-015-9328-x,"
"Scholar10Fan S. C.andYu K. C.,How an integrative STEM curriculum can benefit students in engineering design practices,International Journal of Technology & Design Education. (2015)27, no. 1,1-23,https://doi.org/10.1007/s10798-015-9328-x, 2-s2.0-84941007155.10.1007/s10798-015-9328-xCASWeb of Science®Google Scholar11Longinotti D.,Computationalism and the locality Principle,Minds and Machines. (2009)19, no. 4,495-506,https://doi.org/10.1007/s11023-009-9172-4, 2-s2.0-84898027826.10.1007/s11023-009-9172-4Web of Science®Google Scholar12Caruana R.,Carrington M. J., andChatzidakis A.,Beyond the attitude-behaviour gap: novel perspectives in consumer ethics\": introduction to the thematic symposium,Journal of Business Ethics. (2016)136, no. 2,215-218,https://doi.org/10.1007/s10551-014-2444-9, 2-s2.0-84921832029.10.1007/s10551-014-2444-9Web of Science®Google Scholar13Baldwin J. F.,Support logic programming,International Journal of Intelligent Systems. (2010)1, no. 2,73-104.10.1002/int.4550010202Google Scholar14Butzen P. F.,Dal Bem V., andReis A. I.,BTI and HCI first-order aging estimation for early use in standard cell technology mapping,Microelectronics Reliability. (2013)53, no. 9-11,1360-1364,https://doi.org/10.1016/j.microrel.2013.07.087, 2-s2.0-84886914933.10.1016/j.microrel.2013.07.087Web of Science®Google Scholar15Simmons A. R.andBaggerly K. B. R.,The emerging role of HE4 in the evaluation of epithelial ovarian and endometrial carcinomas,Oncology. (2013)27, no."
"2-s2.0-84886914933.10.1016/j.microrel.2013.07.087Web of Science®Google Scholar15Simmons A. R.andBaggerly K. B. R.,The emerging role of HE4 in the evaluation of epithelial ovarian and endometrial carcinomas,Oncology. (2013)27, no. 6,548-556.PubMedWeb of Science®Google Scholar16Seidl R.,Eastaugh C. S., andKramer K.,Scaling issues in forest ecosystem management and how to address them with models,European Journal of Forest Research. (2013)132, no. 5-6,653-666,https://doi.org/10.1007/s10342-013-0725-y, 2-s2.0-84887625224.10.1007/s10342-013-0725-yWeb of Science®Google Scholar17Hunink J. E.,Niadas I. A.,Antonaropoulos P.,Droogers P., andDe Vente J.,Targeting of intervention areas to reduce reservoir sedimentation in the Tana catchment (Kenya) using SWAT,Hydrological Sciences Journal. (2013)58, no. 3,600-614,https://doi.org/10.1080/02626667.2013.774090, 2-s2.0-84876437363.10.1080/02626667.2013.774090Web of Science®Google Scholar18Zhou Q.,Research on heterogeneous data integration model of group enterprise based on cluster computing,Cluster Computing. (2016)19, no. 3,1275-1282,https://doi.org/10.1007/s10586-016-0580-y, 2-s2.0-84969940439.10.1007/s10586-016-0580-yWeb of Science®Google Scholar19Zhou Q.andLuo J.,The study on evaluation method of urban network security in the big data era,Intelligent Automation and Soft Computing. (2018)24, no. 1,133-138,https://doi.org/10.1080/10798587.2016.1267444, 2-s2.0-85010677190.10.1080/10798587.2016.1267444Web of Science®Google Scholar20Zhou"
"method of urban network security in the big data era,Intelligent Automation and Soft Computing. (2018)24, no. 1,133-138,https://doi.org/10.1080/10798587.2016.1267444, 2-s2.0-85010677190.10.1080/10798587.2016.1267444Web of Science®Google Scholar20Zhou Q.,Multi-layer affective computing model based on emotional psychology,Electronic Commerce Research. (2018)18, no. 1,109-124,https://doi.org/10.1007/s10660-017-9265-8, 2-s2.0-85022212435.10.1007/s10660-017-9265-8Web of Science®Google Scholar21Li T.andKauffman R. J.,Adaptive learning in service operations,Decision Support Systems. (2012)53, no. 2,306-319,https://doi.org/10.1016/j.dss.2012.01.011, 2-s2.0-84862822818.10.1016/j.dss.2012.01.011Web of Science®Google Scholar22Matsatsinis N. F.,CCAS: an intelligent decision support system for credit card assessment,Journal of Multi-Criteria Decision Analysis. (2002)11, no. 4-5,213-235,https://doi.org/10.1002/mcda.329, 2-s2.0-33747046971.10.1002/mcda.329Google Scholar23Gahegan M.,On the application of inductive machine learning tools to geographical analysis,Geographical Analysis. (2000)32, no. 2,113-139.10.1111/j.1538-4632.2000.tb00420.xWeb of Science®Google Scholar24Ouerdane W.,Maudet N., andTsoukiàs A.,Argumentation theory and decision aiding,International Series in Operations Research & Management Science. (2010)142,177-208,https://doi.org/10.1007/978-1-4419-5904-1_7, 2-s2.0-84975688699.10.1007/978-1-4419-5904-1_7Google Scholar25Jimenez S.,De La Rosa T., andSusana F.,A review of"
"aiding,International Series in Operations Research & Management Science. (2010)142,177-208,https://doi.org/10.1007/978-1-4419-5904-1_7, 2-s2.0-84975688699.10.1007/978-1-4419-5904-1_7Google Scholar25Jimenez S.,De La Rosa T., andSusana F.,A review of machine learning for automated planning,The Knowledge Engineering Review. (2012)27, no. 4.10.1017/S026988891200001XWeb of Science®Google Scholar26Zhou Q.,Xu Z., andYen N. Y.,User sentiment analysis based on social network information and its application in consumer reconstruction intention,Computers in Human Behavior. (2019)100,177-183,https://doi.org/10.1016/j.chb.2018.07.006, 2-s2.0-85057208090.10.1016/j.chb.2018.07.006Web of Science®Google Scholar27Zhou Q.,Zhang Z., andWang Y.,Research on safety management system optimization of B2C e-commerce intelligent logistics information system based on data cube,Journal of Intelligent & Fuzzy Systems. (2020)38, no. 2,1585-1592,https://doi.org/10.3233/JIFS-179522.10.3233/JIFS-179522Web of Science®Google Scholar"
"AbstractThe system wide information management (SWIM) system infrastructure layer uses information-centric networking (ICN) to implement the cache routing and sharing of air traffic information data. The SWIM network searches and forwards routes on the basis of content names. The variable length, hierarchical name structure, and routing updates caused by the frequent publication and deletion of content make the implementation of fast name routing lookup algorithms a significant but arduous task. To address this problem, this study designed a name matching mechanism on the basis of the hybrid structure of the Bloom filter and the Tree. Compared with the traditional Bloom filter search scheme, this search mechanism reduces the quantity of Bloom filter insertion entries and reduces the possibility of hash collisions. Compared with the traditional Tree search scheme, the proposed mechanism can effectively solve the problem of numerous memory accesses caused by extremely long name prefixes, improving the query efficiency. In addition, the proposed composite structure is compared with several methods, such as DIPIT and NPT, by analyzing the effects of layering, global delay and search speed. The experimental results show that the proposed structure has a favourable performance in terms of storage overhead and search speed.1 INTRODUCTIONWith the ongoing development of system wide information management (SWIM), the demand for data content itself is becoming increasingly strong. Under"
"structure has a favourable performance in terms of storage overhead and search speed.1 INTRODUCTIONWith the ongoing development of system wide information management (SWIM), the demand for data content itself is becoming increasingly strong. Under such circumstances, resource names become more important lookup fields [1]. Routing entries have greatly increased, and each resource name prefix can consist of dozens or even hundreds of characters. The length of each name is variable, complicating the name prefix. Name routing may be larger than today's IP forwarding tables, and name-based routing lookups face many new challenges. The existing prefix matching methods cannot meet the high efficiency and accuracy requirements of routing addressing in SWIM in terms of memory consumption or matching efficiency, and cannot be directly applied to the search strategy for content names in SWIM. Therefore, it is very necessary to study a new name-matching algorithm adapted to SWIM network resources.At present, the research on algorithms based on name lookup mainly focuses on three structures, namely, search tree, hash, and the Bloom filter. Character search tree is the most used data structure for name lookups. This structure has the advantages of simplicity and convenient search. Hash-based routing algorithms are also commonly used classic algorithms, where the hash function is related to the speed of the lookup. Two factors affect the performance of a hash function, namely the amount of"
"of simplicity and convenient search. Hash-based routing algorithms are also commonly used classic algorithms, where the hash function is related to the speed of the lookup. Two factors affect the performance of a hash function, namely the amount of calculation of the hash function itself and the capability of the hash structure. An efficient hash function that quickly calculates the hash value of a string is required to reduce the search time of the hash. The performance indicators for evaluating different types of hash functions are mostly similar. Collisions must be avoided during design. Therefore, minimizing the impact of hash collisions on the string lookup performance is important.Bloom filters are often used to solve for the longest prefix match and for efficient match searches. Our approach associates a Bloom filter with the prefix extent of the sorted forwarding entry, and the prefix length of each name is related to each Bloom filter prefix length. At the beginning of the search, Bloom filter groups of different search lengths perform parallel member queries, and the results of some searches may be misjudged. Each prefix length uses the corresponding hash table to detect the shortest matching vector in the longest matching order. The main feature of this model is that the number of names inserted into the structure determines the name lookup performance. If the number of inserted names exceeds a certain limit, then the false-positive rate will rise sharply. Hence,"
"matching order. The main feature of this model is that the number of names inserted into the structure determines the name lookup performance. If the number of inserted names exceeds a certain limit, then the false-positive rate will rise sharply. Hence, the bit array size must be changed or the hash function mapping must be increased to prevent the filter from crashing.To minimize the lookup time while controlling the memory consumption, the time needed for update, and the false positives within a small range, the algorithm, which uses the combined structure, has the following features:i. The SWIM name contains an unlimited number of name components. Confirming the number of bloom filters that can meet the requirements when they are applied is challenging work.ii. The SWIM name is long and thus difficult to search and store. These names can be divided into two parts, namely, prefix B and suffix T, which are operated in different ways. Prefix B uses a fixed length to facilitate the search for the Bloom filter.iii. Tree structure has good flexibility and scalability, facilitating the longest prefix matching for suffix T with variable length. Meanwhile, the query efficiency can be controlled because suffix T is shortened.To better understand the search algorithm for SWIM content names, the name-based data forwarding process is first introduced in SWIM, as shown in Figure1.FIGURE 1Open in figure viewerPowerPointName-based data forwarding process in SWIM. SWIM, system wide"
"better understand the search algorithm for SWIM content names, the name-based data forwarding process is first introduced in SWIM, as shown in Figure1.FIGURE 1Open in figure viewerPowerPointName-based data forwarding process in SWIM. SWIM, system wide information management.The SWIM service node includes a three-part structure. The forwarding information base (FIB) is used to record the next-hop service node forwarded by the interest packet. The pending interest table (PIT) is used to store all content sources that fail to satisfy the FIB. The content store (CS) is used to store a copy of the information that passed.When the SWIM service node searches for a content, it must first send the interest packet. After the interest packet is sent to the service node, the node first retrieves the local CS to see if a service information matches the requested information prefix. If matching information is found, then the service information is returned to the input port and the interest packet is dropped. If no matching information is found, then longest prefix matching should be performed in the FIB to confirm the next-hop node to be forwarded, which is included in the interest packet. If the corresponding information is found in the FIB, then the input interface is saved in the PIT and sent to the node specified by the FIB. If the same service information entry exists in the PIT, then the information has been previously requested. The node adds the input interface to this PIT and"
"the FIB, then the input interface is saved in the PIT and sent to the node specified by the FIB. If the same service information entry exists in the PIT, then the information has been previously requested. The node adds the input interface to this PIT and drops the interest packet.When the requested name of the intermediate node in the CS can obtain the matching service information, the interest packet will be dropped, and the service information will be returned in the form of a data packet. On the basis of the form information saved in the PIT, the information will be sent to the subscriber. After the node receives the data packet, it makes a copy of the information and saves it in the CS and then performs longest prefix matching to ensure that the return interface matches the data packet. When multiple interfaces appear in the PIT entry, the data should be copied to implement multicast transmission. Then, the node sends the data packet to the corresponding interfaces and deletes the entries in the PIT. If no matching information is found in the PIT, then the router drops the data packet and eventually implements the return of service information.The contributions of this paper can be summarized as follows.On the basis of the implementation method of the longest prefix matching principle of the search tree and the Bloom filter, this paper proposes the combination of a structure-based lookup algorithm and a lookup strategy based on SWIM data. The higher the false-positive"
"the implementation method of the longest prefix matching principle of the search tree and the Bloom filter, this paper proposes the combination of a structure-based lookup algorithm and a lookup strategy based on SWIM data. The higher the false-positive rate of a single Bloom filter and the deeper the tree are, the worse the search performance will be. The combinatorial structure algorithm proposed in this paper compensates for the shortcomings in the search performance of a single structure, exploits the superiority of both structures, improves the speed of searching for content names, controls the delay within an acceptable range, and effectively improves the timeliness of information transmission.2 RELATED WORKThe rapid search and discovery of resource names is a core issue of the SWIM network. In recent years, many research institutions and scholars have conducted intensive research on resource name search. Li et al. [2] designed a naming scheme and hybrid communication mode suitable for water-depth-aware. Ahrned et al. [3] proposed a way to quickly find content in a P2P system from a software perspective. The proposed method does not require the exact match of the content name and only looks for a pattern for the content name. These studies have made important contributions in fast resource matching, but their implementation is completed at the application layer and thus difficult to directly apply at the packet forwarding level and cannot satisfy the packet level's"
"name. These studies have made important contributions in fast resource matching, but their implementation is completed at the application layer and thus difficult to directly apply at the packet forwarding level and cannot satisfy the packet level's fast-forwarding requirements [4].Rajahalme studied the search tree and proposed an efficient name component encoding to accelerate the lookup of the name prefix lookup tree [5]. Li et al. [6] proposed a paradigm called content-centric quality of experience (QoE), which defined each user's QoE requirements as a hierarchical content naming tree, and achieved high QoE by caching data content with different priorities. This method reduced the average end-to-end delay time. Meanwhile, Bloom filters are utilized to detect whether an element is a member of a collection and can be used to find routing entries. Recently, a series of research schemes based on Bloom filters have been developed for resource search and matching. You et al. [7] proposed a distributed Bloom-filter-based name storage data table to improve the name processing speed and reduce the routing node memory consumption. Dharmapurikar S applied Bloom filters to prefix matching scenarios. However, the Bloom filter structure has a misjudgment rate due to hash collisions [8]. A fetch-fetch BF scheme was designed by Yan to reduce the multiple fetches from the original BF to one [9]. In 2017, Zhang et al. [10] proposed the adaptive compression Trie-based Bloom Filter for"
"has a misjudgment rate due to hash collisions [8]. A fetch-fetch BF scheme was designed by Yan to reduce the multiple fetches from the original BF to one [9]. In 2017, Zhang et al. [10] proposed the adaptive compression Trie-based Bloom Filter for filtering out unmatched requests in an effort to reduce the average lookup latency of the CS. This solution is mainly composed of a Bloom filter, that is, the Trie and Counting Bloom Filter. In 2005, to increase the lookup speed, Yuan [11] proposed a data storage method for the CS, using package buffers to store the data for each cache and index the content table of the d-left hash table. To improve the performance of lookup and cache replacement, Afanasyev et al. [12] modified the CS used in the NFD, which consists of the cache policy and the table. In 2012, You et al. [13,14] proposed a distributed DiPIT solution based on the Bloom filter to decrease the memory occupancy. Given that forwarding information cannot be stored in the Bloom filter, they designed a small PIT at each interface, and each PIT is carried out by a counting Bloom filter. In 2013, Varvello et al. [15] proposed an open addressing d-left hash-table to decrease the memory consumption. Saxena and Raychoudhury proposed Radient [16] in 2016 to further decrease the memory usage, which is nearly the same as that of RaCE. Wang et al. [17] proposed NameFilter in 2013 using a two-stage Bloom filter. In the solution, the first stage uses several Bloom filters, and each"
"Radient [16] in 2016 to further decrease the memory usage, which is nearly the same as that of RaCE. Wang et al. [17] proposed NameFilter in 2013 using a two-stage Bloom filter. In the solution, the first stage uses several Bloom filters, and each Bloom filter records prefixes of the same length, and the second stage for each interface is assigned a Bloom filter. In 2017, Shubbar and Ahmadi [18] proposed an unprecedented method called fast two-dimensional filter with a hash table to reduce the redundant access to the hash table and make the lookup time shorten as much as possible. Through the use of the router hardware parallelism, Wang et al. [19] proposed parallel name lookup (PNL). This approach groups different levels of lookup status in the NPT on the basis of the access situation of each state and stores them in a plurality of physical modules, where each physical module manages a group.Aiming at the data security problem in SWIM service sharing, Ma et al. [20] analyzed the security hidden danger in the SWIM business process, and proposed a malicious data filtering method based on the LDA topic model and content mining. The KMP matching algorithm was used to find pattern strings in the main string. The SWIM service data containing malicious keywords can be detected. In order to alleviate data transmission delay and high load of data source nodes, Wu et al. [21] introduced named Data Network (NDN) routing mechanism into SWIM network and named SWIM information in a"
"data containing malicious keywords can be detected. In order to alleviate data transmission delay and high load of data source nodes, Wu et al. [21] introduced named Data Network (NDN) routing mechanism into SWIM network and named SWIM information in a hierarchical way to improve route aggregation. This scheme improves the quick response capability of SWIM network to the same information request.To sum up, some studies mainly analyze the uniqueness, safety, and effectiveness of naming methods. The theoretical analysis and experimental research of SWIM content search algorithm is still in the preliminary exploration stage, which is not perfect in detail, and does not match the existing civil aviation system, and is not closely related. Many standard specifications about SWIM content search need to be improved, the relevant research mainly adopts some qualitative research methods to analyze the network naming system, and applies the corresponding naming methods to specific systems. Up to now, no one has proposed a suitable naming method definition and relatively complete naming scheme for SWIM network architecture.According to the above research and considering the flexibility and scalability of the implementation, the innovations of this article are as follows. A new hybrid query structure was designed, combining a search tree and a Bloom filter [22]. In this method, a very long content name can be divided into two shorter segments: a fixed-length Bloom filter prefix for the"
"of this article are as follows. A new hybrid query structure was designed, combining a search tree and a Bloom filter [22]. In this method, a very long content name can be divided into two shorter segments: a fixed-length Bloom filter prefix for the first part and a variable-length search tree prefix for the second part. The Bloom filter structure and the search tree structure-based method can be respectively used. Then, by constructing a set of small-scale hash tables, the Bloom filter is bound to the search tree for synchronous lookup.The remainder parts of this article are arranged as follows. Section 3 presents the combined Tree and Bloom filter model. Section 4 analyzes the combined model. Section 5 presents an overview of the experimental procedure and the analysis of the performance of the experimental scheme. Section 6 concludes of the paper.3 FALSE POSITIVE OF BLOOM FILTERThe Bloom filter algorithm maps each element in the set to a point on an array of lengthmusing a hash function, wheremrepresents the size of the Bloom filter. The default value for all the bits of the bloom filter is 0, and the bit to which the element is mapped is set to 1. In the search process, the same hash function is used for mapping. When the mapping position is 1 [18], the set contains the element; otherwise, the set does not contain the element. However, when many elements are detected, hash collisions may occur in this approach, causing query misjudgment.The false-positive probability of"
"mapping position is 1 [18], the set contains the element; otherwise, the set does not contain the element. However, when many elements are detected, hash collisions may occur in this approach, causing query misjudgment.The false-positive probability of the Bloom filter is analyzed from the perspective of mathematical theory. If the probability of a hash function mapping each bit is the same, themrepresents the size of the bloom filter, that is, the number of bits. When an element is inserted into the Bloom filter, the probability that the mapping bit is not 1 is(1)When usingkhash function mappings at the same time, the probability that the bit mapped by any one hash function is not 1 is(2)Whennelement insertion tasks are completed, the probability that a bit value is still 0 is(3)Whennelement insertion tasks are completed, the probability of a bit value being 1 is(4)In an element set test, if the mapping positions of theKhash functions are all 1, then a false-positive misjudgment occurred, and the probability of occurrence is(5)This equation intuitively expresses the false-positive probability of a Bloom filter. This case is often encountered in practice. An effective mitigation method is to usekhash functions, which correspond tokpositions [23]. Only when all mapping positions are 1 are the elements considered to be in a set; if one 0 exists, the elements are not in a set. Given that the probability of multiple hash functions conflicting at the same time is very small, the"
"tokpositions [23]. Only when all mapping positions are 1 are the elements considered to be in a set; if one 0 exists, the elements are not in a set. Given that the probability of multiple hash functions conflicting at the same time is very small, the misjudgment rate caused by hash conflicts is greatly reduced.4 COMBINED MODEL OF TREE AND BLOOM FILTERProblems are encountered in the search of content names for a single data structure, that is, the tree is the most commonly used search algorithm, but its performance decreases linearly with the depth, making it unsuitable for variable-length named data network name structures [24,25]. The Bloom filter is a space-efficient search strategy, but in many named data networks, the error rate of the Bloom filter has an unacceptable effect. The characteristics of SWIM data naming were investigated in this study, and a simple and effective combination structure name lookup strategy was designed to exploit the advantages of both to address the shortcomings of a single model.4.1 Overall frame descriptionAiming at the characteristics of SWIM content name, this chapter discussed the new combined structure query engine, which uses a joint count Bloom filter and search tree structure for name query [26]. The following factors are mainly considered.The SWIM content name is a sequence of variable-length lexical components, which makes counting the sets of filters required by the Bloom filter scheme difficult.Very long names are divided into two"
"query [26]. The following factors are mainly considered.The SWIM content name is a sequence of variable-length lexical components, which makes counting the sets of filters required by the Bloom filter scheme difficult.Very long names are divided into two short segments: the former query tree prefix and the second latter variable Bloom filter prefix with a fixed length. The segments can respectively use the search tree and the Bloom filter for processing.Calculating length of the SWIM content names is conducive for aggregation, which means that with the proper length, the amount of distinct Bloom filter prefixes will be restricted to a small range, reducing the false-positive rate of the Bloom filters [27].When the data structure of the search tree is used, the length of the name is far less than the length of the whole name, the processing speed of the search tree will be greatly improved, and the flexibility and scalability of the dynamic memory can be fully realized.The combined data structure model of the Bloom filter combined with the search tree is shown in Figure2.FIGURE 2Open in figure viewerPowerPointBF combined search tree model.As shown in Figure2, each name is divided into two components: prefix B and suffix T. Prefix B is divided intoB1,B2,B3, ...,, and the length is fixed, which is dealt with Bloom filters. Bloom filters are ideal for prefix B. Suffix T is divided intoT1,T2, ...,. The search length of the tree is variable and shorter than their full name, and"
"Prefix B is divided intoB1,B2,B3, ...,, and the length is fixed, which is dealt with Bloom filters. Bloom filters are ideal for prefix B. Suffix T is divided intoT1,T2, ...,. The search length of the tree is variable and shorter than their full name, and its prefix aggregation is very high. The search tree can be used for suffix T. Then, a small set of hash tables should be built to bind the Bloom filter to the search tree.4.2 Division of model boundariesTo better analyze the problem, we assume thatUis the name data set in SWIM, andSis the set of all prefixes. Given an arbitrary, an efficient route search method (L)can be used to ensure the corresponding longest match prefix in the set. The objective function is timeT, which takes into amount factors, such as storage time and false-positive rate.In Equation (6),Wis a function to find time,Mis the available space, ε is the largest available space, and σ is the threshold of false positive rate. The goal is to reduce the query timeT, and consider a reasonable space efficiency and a suitable false-positive rate.The problem is more generally expressed according to Equation (6)(6)In Equation (7),is the time of the Bloom filter group query,is the time of searching the tree structure query,is the time spent connecting the Bloom filter and the search tree,is the time consumed by a hash lookup, and the total time is mainly consideredand. Among them,satisfies the time query function of the Bloom filter, andsatisfies the time query"
"query,is the time spent connecting the Bloom filter and the search tree,is the time consumed by a hash lookup, and the total time is mainly consideredand. Among them,satisfies the time query function of the Bloom filter, andsatisfies the time query function of the search tree structure, and they are mainly concerned to the length of the search tree and the Bloom filter, so it depends on how to divide the name prefix [28].The total name search time of the combined structure is expressed as Equation (7)(7)This model has several advantages for improving the efficiency of name lookups.i. The model reduces the amount of entries embedded in the Bloom filter and reduces the error rate.ii. The length of the name in the search tree is shortened, and the aggregation mechanism of the name prefix is fully utilized to reduce the branch of the word search tree, so that the structure of the word search tree can be effectively used.iii. The length of the processing name of the Bloom filter is reduced to facilitate the realization of the Bloom filter [29].5 NAME LOOKUP PROCESS OF COMBINED STRUCTUREThe name lookup process consists of two steps. In the first step, the prefix of the content name is processed by a counted Bloom filter, and the hash table determines the position of the corresponding search tree suffix. When the content name is short enough, the query result is returned directly [30,31]. In the second step, when the name prefix is very long, prefix matching should be performed"
"hash table determines the position of the corresponding search tree suffix. When the content name is short enough, the query result is returned directly [30,31]. In the second step, when the name prefix is very long, prefix matching should be performed along the search tree according to the position of the suffix. When the longest prefix match is found, the corresponding forwarding port is returned. The hierarchical structure will make different content name prefixes have the same prefix B, significantly reducing the number of different prefixes B.The specific content name lookup process is shown in Figure3.FIGURE 3Open in figure viewerPowerPointName lookup process of the combined structure.The procedure of name lookup is as follows.The total length of the name is calculated asL. The length of the B-prefix is fixed atm, and the first 1 layer, the first 2 layers of the name, ..., the first min (L,m) as B-prefix-1, B-prefix-2, ..., B-prefix-min (L,m). The number of layers in the remaining part corresponds to T-suffix-1, T-suffix-2, ..., T-suffix-min (L,m).B-prefix-1, B-prefix-2, ..., B-prefix-min (L,m) are sought in parallel in the Bloom filter, and the search results are stored in an ascending order in stack s.Whensis empty, the search result is forwarded from the default port. Whensis not empty, the top element of the stack is removed.The firstmlayers of the name are the B-prefix, and the latermlayers are the T-suffix. When the T-suffix is not empty, the length of the name"
"the search result is forwarded from the default port. Whensis not empty, the top element of the stack is removed.The firstmlayers of the name are the B-prefix, and the latermlayers are the T-suffix. When the T-suffix is not empty, the length of the name is greater than the number of Bloom filters. A query must be made on whether the Trie corresponding to the B-prefix contains the T-suffix. If it contains, then the T-suffix will be forwarded. Otherwise, the T-suffix will be forwarded on the default port. When the T-suffix is empty, the length of the name is less than or equal to the number of Bloom filters. Then, the root node of the Trie corresponding to the B-prefix must be checked for a forwarding port. If a forwarding port exists, the result found will be forwarded. Otherwise, the result will be forwarded from the default port.The advantages of combined structures for searching are as follows.The number of Bloom filters and the false-positive rate are reduced.The Bloom filter is only used in the first stage, and the search process can be implemented in the hardware. In summary, the combined structure fully exploits the advantages of the two data structures. The combined structure has great advantages over the single-search structure in terms of speed and storage space.6 MODEL ANALYSISAfter the SWIM content name is sliced into two parts, the first half is processed using a Bloom filter structure. AssumingwBloom filter groups and thatfrepresents the false-positive rate of"
"structure in terms of speed and storage space.6 MODEL ANALYSISAfter the SWIM content name is sliced into two parts, the first half is processed using a Bloom filter structure. AssumingwBloom filter groups and thatfrepresents the false-positive rate of each group, the expected value of the number of accesses to the routing index table required for each route search is shown in Equation (8).(8)In the process of model analysis, the length of the names is assumed to follow a gamma distribution.Here,h> 0, λ> 0, θ > 0, andrepresents a gamma function with parameter λ. Therefore, the length of the name satisfies the corresponding distribution density function(9)From this equation, the distribution of the names can be obtained, and the length distribution of the search tree is summarized as the probability that the length of the name is less thant, which is the division value of the search tree and the Bloom filter (div =t).(10)Equation (10) represents an incomplete gamma function(11)Equation (11) indicates that if the boundary of the name division ist, then the name will be divided into two parts. The firsttwords will be processed by the search tree, and fromt +1words to the end of the name, the structure of the Bloom filter will be used. The Bloom filter's average length is(12)Here, δ> 0, the value is determined byt, and the name prefix length fromtto infinity is obtained according to the density distribution function [32].Given that the length of the prefix follows the gamma"
"be used. The Bloom filter's average length is(12)Here, δ> 0, the value is determined byt, and the name prefix length fromtto infinity is obtained according to the density distribution function [32].Given that the length of the prefix follows the gamma distribution, that is,. The parameters are set as follows:. The distribution structure diagram is shown in Figure4.FIGURE 4Open in figure viewerPowerPointLength distribution of name prefix.Figure4demonstrates that the distribution of the name prefixes in the naming structure is uneven. Most of the lengths of the name prefixes are gathered in an interval, and the long names account for a small proportion. Letbe the total number of all prefixes. The different prefixes () among all the prefixes are counted, and then the degree of aggregation is defined as shown in Equation (13)(13)Therefore, we can obtain the differentiation rate of.Figure5shows the differentiation rate of the name prefix. When the name prefix is short, the differentiation rate is low, and the differentiation rate increases with the length of the name [33]. This phenomenon indicates that if the number of prefixes for all names is known, the number of prefixes inserted into the Bloom filter should be evaluated. Analysis shows that short-level names account for most of the name composition, long-level names are few, and short components are more convenient to use than long components.FIGURE 5Open in figure viewerPowerPointDifferentiation rate of name prefix.The"
"Analysis shows that short-level names account for most of the name composition, long-level names are few, and short components are more convenient to use than long components.FIGURE 5Open in figure viewerPowerPointDifferentiation rate of name prefix.The mathematical features of the name are determined in two aspects, namely, the distribution of all the components of each name and the level of differentiation rate under different length name prefixes [34].If the error rate of theith Bloom filter in the Bloom filter group is, the bit vector size is, and the amount of storage elements is, then the amount of hash functions is(14)In the name routing table, the amount of entries isN, and the size of all the bit vectors in the Bloom filter group isM. The following relationships must be satisfied:All error rates are expressed as Equation (15).(15)WithLBloom filter groups, the average number of times of each route lookup with Bloom filter groups is(16)The influencing factors of the division of thedivon the result parameters are as follows [35].To lessen the false-positive rate, it is essential to reduce the name entries inserted into the Bloom filter structure. Therefore, the div value should be as small as possible, and the div value must be maintained above 4 to obtain a good result.To achieve low memory cost, the number of name entries inserted into the search tree structure should be as few as possible. Thedivvalue should be as small as possible, and less than 6 is best.The"
"value must be maintained above 4 to obtain a good result.To achieve low memory cost, the number of name entries inserted into the search tree structure should be as few as possible. Thedivvalue should be as small as possible, and less than 6 is best.The evaluation should have a reasonable time complexity and storage cost. Thedivvalue should be set between 4 and 6.These factors improve the lookup efficiency. Assigning a correspondingly shorter T-suffix and a relatively long B-prefix is the best way to use this structure. It can efficiently avoid the large number of redundant and repeated matches, further accelerating the processing.7 EXPERIMENT AND RESULT ANALYSISThis chapter mainly discusses the experimental environment, scenario, and parameter configuration and the SWIM content data source, data volume, and data content. The experimental content indicators emphasize the storage overhead of different structures in the routing table, the influences of different numbers of layers on the delay, and the final comparative experiments with other search schemes.7.1 Experiment environmentAccording to the SWIM architecture and business process, this study established an experimental environment to test the solution. The network topology of the experimental environment is shown in Figure6.FIGURE 6Open in figure viewerPowerPointExperimental test environment.This experiment simulates the information exchange between multiple departments in the two SWIM access nodes of the airline and"
"of the experimental environment is shown in Figure6.FIGURE 6Open in figure viewerPowerPointExperimental test environment.This experiment simulates the information exchange between multiple departments in the two SWIM access nodes of the airline and the Air Traffic Management Bureau, and the data used comes from the China Civil Aviation Network. The function and configuration of each server in the experimental environment are briefly introduced below [36].The airline's access server is responsible for connecting its internal flight, dispatch, and technical support departments [37]. It provides SWIM systems with the flight plan information formulated by the dispatch department and transmits access information for such information to authorized servers [38]. The access server is responsible for connecting its internal regulatory, meteorological, and flight services departments. It also provides SWIM systems with the aeronautical meteorological information issued by the meteorological department, and transmits access policies for such information to authorized servers [39].The access control server is responsible for determining the rights of visitors and protecting the privacy and security in the domain [40]. It is combined with an access server to form an access node, which enables the secure interaction between various agencies and the SWIM system [41].The authorization server is mainly responsible for managing the access policies of various types of service information and"
"an access server to form an access node, which enables the secure interaction between various agencies and the SWIM system [41].The authorization server is mainly responsible for managing the access policies of various types of service information and returning the policy set required by the access control server for its determination [42].In addition, this experiment uses the enterprise service bus (ESB) to implement the functions of the SWIM infrastructure. The ESB is a message-based framework for inter-service connectivity. Its core functions include message mechanism, message transformation, content-based routing, and service container. ESB provides information interaction and collaboration services for heterogeneous platforms through a standardized communication infrastructure. In this experiment, the ESB is responsible for service publication, discovery, and information routing of SWIM.The data selected in the experiment are meteorological information data. The name prefix table is used as the data set in the experiment, and the sizes of the prefix tables are 1 and 10 M respectively. The 1 M prefix table contains 4,532,167 name prefix entries, and the 10 M prefix table contains 896,262 name prefix entries. The table structures for the two prefix tables are shown in Tables1and2. Table3presents the data set utilized in the experiment. A total of 10 data sets are used from Test 1 to Test 10. For Test 1, the data set has a size of 1 MB, and the subsequent data sets were"
"structures for the two prefix tables are shown in Tables1and2. Table3presents the data set utilized in the experiment. A total of 10 data sets are used from Test 1 to Test 10. For Test 1, the data set has a size of 1 MB, and the subsequent data sets were added 1 MB of data randomly in order.TABLE  1.1 M prefix table.LayerName lengthPercentageNumber of names14.110.01224214.8287.302,129,835320.6315.38391,377425.760.8521,6645-931.860.061694TABLE  2.10 M prefix table.LayerName lengthPercentageNumber of names16.150.011248216.3475.347,150,441320.5622.062,106,879427.652.56264,7785-935.670.051578TABLE  3.Experimental collection data set.Data setTest 1Test 2Test 3Test 4Test 5Test 6Test 7Test 8Test 9Test 10Data size1 M2 M3 M4 M5 M6 M7 M8 M9 M10 M7.2 Memory overhead analysisIn the experiment, the storage costs of the six structures under different routing table sizes are compared. They are the combined structures (with div = 3, 4, 5, 6), the traditional Bloom filter structure, and the search tree structure.Figure7shows the memory overhead of the tree, the Bloom filter, and the combined structure with different div values.FIGURE 7Open in figure viewerPowerPointMemory overhead of composite structures.Figure7shows that the memory consumption increases with the data size, basically exhibiting a linearly increasing trend. The tree has the largest storage cost, indicating that the tree has the worst scalability in large systems. Bloom filters have the lowest storage consumption because they"
"increases with the data size, basically exhibiting a linearly increasing trend. The tree has the largest storage cost, indicating that the tree has the worst scalability in large systems. Bloom filters have the lowest storage consumption because they use the idea of bitmaps, which greatly improves storage efficiency. Considering the div value again, the storage cost increases with the div value because the larger the div value is, the longer the search tree structure and the closer the storage efficiency is to the storage efficiency of the search tree. Conversely, it is closer to the search efficiency of the Bloom filter. Therefore, decreasing the div value decreases the storage consumption. However, the storage cost of div is also much lower than that of the tree, indicating that the storage consumption of the combined structure of the search tree and the Bloom filter is significantly improved, and in the case of div = 1, the storage consumption is near that of the BF structure.Figure8shows the memory overhead under different name routing table sizes. The comparison schemes used in the experiments are DIPIT in Reference [13], NPT in Reference [19], and Bloom Hash structure.FIGURE 8Open in figure viewerPowerPointMemory overhead under different name routing table sizes.Figure8shows that the memory overhead cost of each structure increases nearly linearly with the size of the routing table. The memory overhead of the NPT is the largest, and the maximum value reaches 700. CSL"
"under different name routing table sizes.Figure8shows that the memory overhead cost of each structure increases nearly linearly with the size of the routing table. The memory overhead of the NPT is the largest, and the maximum value reaches 700. CSL has the second most memory overhead. The combined and DIPIT structures have the smallest overhead. The overheads of the two structures are nearly the same.7.3 Stratified impact analysisFigure9presents a comparison of the overall search delays in the layers.FIGURE 9Open in figure viewerPowerPointHierarchical overall search delay.The time consumed in searching for the tree increases with the div value and gradually increases at the beginning. When the div value exceeds 4, the increase starts to become obvious. The time consumption of the Bloom filter decreases with the increase of the div value, and the decreasing trend is nearly linear. The results show that the total elapsed time initially decreases as the div increases and the time starts to increase from div = 5 to div = 6. When div = 5, the total elapsed time is the lowest value.As can be seen from Figure9, when no layering is performed, the delay of the Bloom filter and the search tree presents an upward trend as the size of the routing table increases. For combined structures with different numbers of layers, when the number of layers increases, the search delay gradually decreases. When the number of layers increases from 5 to 6, the overall delay gradually increases again,"
"the routing table increases. For combined structures with different numbers of layers, when the number of layers increases, the search delay gradually decreases. When the number of layers increases from 5 to 6, the overall delay gradually increases again, indicating that when the number of layers is 5, the overall delay is the lowest.7.4 Overall delay analysisThe overall delay of different naming schemes is analyzed below, clearly showing the search efficiency of different structures. The search delays of different schemes under different routing table sizes are shown in Figure10.FIGURE 10Open in figure viewerPowerPointOverall latency of the scheme.Figure10shows that the delay of each lookup scheme increases with the number of routing tables, but the increase varies. The delay of NPT is the largest because its efficiency decreases as the depth of the tree increases. The second largest delay belongs to DIPIT because it not only needs to search for each name but also deals with conflicts that occur, consuming a huge amount of time. When the number of layers in the combined structure is 5, the delay is minimal. Similarly, the overall delay is also the smallest among the schemes compared.7.5 Lookup speed analysisThe lookup speed of different naming schemes is analyzed below, clearly showing the search efficiency of different structures. The lookup speeds of different schemes under different routing table sizes are shown in Figure11.FIGURE 11Open in figure viewerPowerPointLookup"
"of different naming schemes is analyzed below, clearly showing the search efficiency of different structures. The lookup speeds of different schemes under different routing table sizes are shown in Figure11.FIGURE 11Open in figure viewerPowerPointLookup speed under different name routing table sizes.Figure11indicates that with the increase in the size of the routing table, the lookup speed of the NPT and the DIPIT has always been extremely low, almost not even 5 MSPS. However, the speeds of the CSL and combined structure schemes are nearly ideal. The lookup speed of the combined structure is maintained between 30 and 40 MSPS, reflecting the superiority of the combined structure.8 CONCLUSIONIn the paper, the features of SWIM names are studied, and a simple and effective name routing lookup model is proposed. This model combines the characteristics of the name, makes full use of the characteristics of the Bloom filter and the search tree, and eliminates the disadvantages brought by a single data model. By analyzing and comparing the impacts of the prefix tree and the Bloom filter structure of different lengths, an optimal length prefix tree is found to improve the search efficiency. The results show that this model speeds up the search efficiency and reduces the error rate caused by the Bloom filter itself. It uses less memory than the structure of a single prefix tree.AUTHOR CONTRIBUTIONSlizhe zhang; Conceptualization, Data curation, Methodology, Writing - original draft,"
"up the search efficiency and reduces the error rate caused by the Bloom filter itself. It uses less memory than the structure of a single prefix tree.AUTHOR CONTRIBUTIONSlizhe zhang; Conceptualization, Data curation, Methodology, Writing - original draft, Zhuoning Bai; Software, Supervision, Writing - review & editing, Bohua Cui; Supervision, Writing - review & editing, Zhijun Wu; Conceptualization, Project administration, Supervision, Writing - review & editing.ACKNOWLEDGEMENTSThis work was supported by the funds of National Natural Science Foundation of China (62172418, U2133203), the Open Fund of Key Laboratory of Civil Aircraft Airworthiness Technology (SH2021111907), and the Education Commission scientific research project of Tianjin China (2022KJ081)CONFLICT OF INTEREST STATEMENTThe authors declare no conflict of interest.Open ResearchDATA AVAILABILITY STATEMENTThe data that support the findings of this study are available on request from the corresponding author. The data are not publicly available due to privacy or ethical restrictions.REFERENCES1Lu, X.,Koga, T.:Real-time oriented system wide information management for service assurance. In:2015 IEEE Twelfth International Symposium on Autonomous Decentralized Systems (ISADS), IEEE, pp.175-180(2015)Google Scholar2Li, J., et al.:Information-centric wireless sensor networking scheme with water-depth-awareness content caching for underwater IoT.IEEE IoT J.9(2),858-867(2022)Web of Science®Google Scholar3Ahmed, R.,Plexus,"
"(ISADS), IEEE, pp.175-180(2015)Google Scholar2Li, J., et al.:Information-centric wireless sensor networking scheme with water-depth-awareness content caching for underwater IoT.IEEE IoT J.9(2),858-867(2022)Web of Science®Google Scholar3Ahmed, R.,Plexus, B.:A scalable peer-to-peer protocol enabling efficient subset search.IEEE/ACM Trans. Networking.17(1),130-143(2009)10.1109/TNET.2008.2001466Web of Science®Google Scholar4Quan, W.,QiaoXu, C.,Guan, J.,Zhang, H.,Grieco, L.A.:Scalable name lookup with adaptive prefix bloom filter for named data networking.IEEE Commun. Lett.18(1),102-105(2014)10.1109/LCOMM.2013.112413.132231Web of Science®Google Scholar5Rajahalme, J.,Sarela, M.,Visala, K., et al.:On name-based inter-domain routing.Comput. Networks.55(4),975-986(2011)10.1016/j.comnet.2010.12.014Web of Science®Google Scholar6Li, G.,Dong, M.,Ota, K.,Wu, J.,Li, J.,Ye, T.:Towards QoE named content-centric wireless multimedia sensor networks with mobile sinks. In:2017 IEEE International Conference on Communications (ICC), pp.1-6(2017).https://doi.org/10.1109/ICC.2017.799685110.1109/ICC.2017.7996851Google Scholar7You, W.,Mathieu, B.,Truong, P.,Peltier, J.,Simon, G.:DiPIT: A distributed bloom-filter based PIT table for CCN nodes. In:2012 21st International Conference on Computer Communications and Networks (ICCCN),Munich, pp.1-7(2012)Google Scholar8Dharmapurikar, S.,Krishnamurthy, P.,Taylor, D.E.:Longest prefix matching using bloom filters.IEEE/ACM Trans."
"PIT table for CCN nodes. In:2012 21st International Conference on Computer Communications and Networks (ICCCN),Munich, pp.1-7(2012)Google Scholar8Dharmapurikar, S.,Krishnamurthy, P.,Taylor, D.E.:Longest prefix matching using bloom filters.IEEE/ACM Trans. Networking.14(2),397-409(2006)10.1109/TNET.2006.872576Web of Science®Google Scholar9Qiao, Y.,Li, T.,Chen, S.:One memory access bloom filters and their generalization. In:2011 Proceedings IEEE INFOCOM,Shanghai, pp.1745-1753(2011)Google Scholar10Zhang, R.,Liu, J.,Huang, T.,Pan, T.,Wu, L.:Adaptive compression trie based bloom filter: Request filter for NDN content store.IEEE Access.5,23647-23656(2017)10.1109/ACCESS.2017.2764106Web of Science®Google Scholar11Yuan, H.:Data structures and algorithms for scalable NDN forwarding. PhD Dissertation, Dept. Comp. Sci. Eng., Washington Univ. in St. Loui, St. Louis, MO, USA (2015).https://openscholarship.wustl.edu/cgi/viewcontent.cgi?article=1143&context=eng_etsGoogle Scholar12Afanasyev, A., et al.:NFD developer's guide.Named Data Netw., Rep. NDN-0021 (2016).http://named-data.net/Google Scholar13You, W.,Mathieu, B.,Truong, P.,Peltier, J.-F.,Simon, G.:DiPIT: A distributed bloom-filter based PIT table for CCN nodes. In:Proceedings of 21st International Conference on Comput. Commun. Netw,Munich, Germany, pp.1-7(2012)Google Scholar14You, W.,Mathieu, B.,Truong, P.,Peltier, J.-F.,Simon, G.:Realistic storage of pending requests in content-centric network routers. In:Proceedings of IEEE"
"of 21st International Conference on Comput. Commun. Netw,Munich, Germany, pp.1-7(2012)Google Scholar14You, W.,Mathieu, B.,Truong, P.,Peltier, J.-F.,Simon, G.:Realistic storage of pending requests in content-centric network routers. In:Proceedings of IEEE International Confernce on Commun,Beijing, China, pp.120-125(2012)Google Scholar15Varvello, M.,Perino, D.,Linguaglossa, L.:On the design and implementation of a wire-speed pending interest table. In:Proceedings of Comput. Commun. Workshops,Turin, Italy, pp.369-374(2013)Google Scholar16Saxena, D.,Raychoudhury, V.:Radient: Scalable, memory efficient name lookup algorithm for named data networking.J. Netw. Comput. Appl.63,1-13(2016)10.1016/j.jnca.2015.12.009Web of Science®Google Scholar17Wang, Y., et al.:NameFilter: Achieving fast name lookup with low memory cost via applying two-stage bloom filters. In:Proceedings of IEEE INFOCOM,Turin, Italy, pp.95-99(2013)Google Scholar18Shubbar, R.,Ahmadi, M.:Efficient name matching based on a fast two-dimensional filter in named data networking.Int. J. Parallel Emergent Distrib. Syst.34(2),203-221(2019)10.1080/17445760.2017.1363202Web of Science®Google Scholar19Wang, Y., et al.:Parallel name lookup for named data networking. In:Proceedings of Glob. Telecommun. Conference (GLOBECOM),Kathmandu, Nepal, pp.1-5(2011)Google Scholar20Ma, L.A.N.,Jingjie, W.,Huan, C.:Business data security of wide area information management system based on content mining.Comput. Appl.39(02),488-493(2019)Google"
"of Glob. Telecommun. Conference (GLOBECOM),Kathmandu, Nepal, pp.1-5(2011)Google Scholar20Ma, L.A.N.,Jingjie, W.,Huan, C.:Business data security of wide area information management system based on content mining.Comput. Appl.39(02),488-493(2019)Google Scholar21Zhijun, W.,Xinran, X.U.:A SWIM network routing mechanism based on NDN.J. Civil Aviation Univ. China.39(01),11-16(2021)Google Scholar22Li, F.,Chen, F.,Wu, J.,Xie, H.:Longest prefix lookup in named data networking: how fast can it be?In:2014 9th IEEE International Conference on Networking, Architecture, and Storage, Tianjin, pp.186-190(2014)Google Scholar23Wang, Y.,Dai, H.,Jiang, J., et al.:Parallel name lookup for named data networking.Acm Sigmetrics Performance Evaluation Review.58(11),1-5(2011)Google Scholar24Zhou, Z.,Song, T.,Jia, Y.:A high-performance URL lookup engine for URL filtering systems. In:2010 IEEE International Conference on Communications, Cape Town, pp.1-5(2010)Google Scholar25Sun, Y.,Zhang, Y.,Su, S.,Zhang, H.,Fang, B.:Geometric name routing for ICN in dynamic world.China Commun.12(7),47-59(2015)10.1109/CC.2015.7188524Web of Science®Google Scholar26Wang, P.-C.,Chan, C.-T.,Hu, S.-C.,Shin, Y.-C.,Chen, Y.-C.:Hardware-based IP routing lookup with incremental update. In:Ninth International Conference on Parallel and Distributed Systems, 2002. Proceedings,Taiwan, China, pp.183-188(2002)Google Scholar27Quan, W.,Xu, C.,Vasilakos, A.V.,Guan, J.,Zhang, H.,Grieco, L.A.:TB2F: Tree-bitmap and bloom-filter for a"
"update. In:Ninth International Conference on Parallel and Distributed Systems, 2002. Proceedings,Taiwan, China, pp.183-188(2002)Google Scholar27Quan, W.,Xu, C.,Vasilakos, A.V.,Guan, J.,Zhang, H.,Grieco, L.A.:TB2F: Tree-bitmap and bloom-filter for a scalable and efficient name lookup in content-centric networking. In:2014 IFIP Networking Conference,Trondheim, pp.1-9(2014)Google Scholar28Zhijun, W.,Qing, X.,Jingjie, W.,Meng, Y.,Liang, L.:Low-rate DDoS attack detection based on factorization machine in software defined network.IEEE Access.8,17404-17418(2020)10.1109/ACCESS.2020.2967478Web of Science®Google Scholar29Wang, Y., et al.:Fast name lookup for named data networking. In:Proceedings of IEEE 22nd Int. Symp. Qual. Service, Hong Kong, pp.198-207(2014)Google Scholar30Dai, H.,Liu, B.:CONSERT: Constructing optimal name-basedrouting tables.Comput. Netw.94,62-79(2016)10.1016/j.comnet.2015.11.020Web of Science®Google Scholar31Lee, J.,Lim, H.:A new name prefix trie with path compression. In:Proceedings of IEEE International Conference on Consum. Electron. Asia,Seoul, South Korea, pp.1-4(2016)Google Scholar32Fang, C., et al.:A survey of mobile information-centric networking: Research issues and challenges.IEEE Commun. Surveys Tuts.20(3),2353-2371(2018)10.1109/COMST.2018.2809670Web of Science®Google Scholar33Perino, D.,Varvello, M.,Linguaglossa, L.,Laufer, R.,Boislaigue, R.:Caesar: A content router for high-speed forwarding on content names. In:Proceedings of 10th ACM/IEEE Symp."
"of Science®Google Scholar33Perino, D.,Varvello, M.,Linguaglossa, L.,Laufer, R.,Boislaigue, R.:Caesar: A content router for high-speed forwarding on content names. In:Proceedings of 10th ACM/IEEE Symp. Archit. Netw. Commun. Syst., Marina Del Rey.CA, USA, pp.137-148(2014)Google Scholar34Saxena, D.,Raychoudhury, V.,Suri, N.,Becker, C.,Cao, J.:Named data networking: A survey.Comput. Sci. Rev.19,15-55(2016)10.1016/j.cosrev.2016.01.001Web of Science®Google Scholar35Chen, Q., et al.:Transport control strategies in named data networking: A survey.IEEE Commun. Surveys Tuts.18(3),2052-2083(2016)10.1109/COMST.2016.2528164Web of Science®Google Scholar36Ghasemi, C.,Yousefi, H.,Shin, K.G.,Zhang, B.:A fast and memory-efficient trie structure for name-based packet forwarding. In:Proceedings of IEEE Int. Conf. Netw. Protocols,Cambridge, UK, pp.302-312(2018)Google Scholar37Lim, H.,Shim, M.,Lee, J.:Name prefix matching using bloom filter pre-searching. In:Proceedings of 11th ACM/IEEE Symp. Archit. Netw. Commun. Syst,Oakland, CA, USA, pp.203-204(2015)Google Scholar38Xu, D.,Zhang, H.,Sun, Y.,Liu, Y.:Scalable multi-hash name lookup method for named data networking.J. Harbin Inst. Technol.22(6),62-68(2015)Google Scholar39Lee, J.,Shim, M.,Lim, H.:Name prefix matching using bloom filter pre-searching for content centric network.J. Netw. Comput. Appl.65,36-47(2016)10.1016/j.jnca.2016.02.008Web of Science®Google Scholar40Dai, H.,Lu, J.,Wang, Y.,Pan, T.,Liu, B.:BFAST: High-speed and memory-efficient"
"prefix matching using bloom filter pre-searching for content centric network.J. Netw. Comput. Appl.65,36-47(2016)10.1016/j.jnca.2016.02.008Web of Science®Google Scholar40Dai, H.,Lu, J.,Wang, Y.,Pan, T.,Liu, B.:BFAST: High-speed and memory-efficient approach for NDN forwarding engine.IEEE/ACMTrans. Netw.25(2),1235-1248(2017)10.1109/TNET.2016.2623379Web of Science®Google Scholar41Li, Z.,Liu, K.,Liu, D.,Shi, H.,Chen, Y.:Hybrid wireless networks with FIB-based named data networking.EURASIP J. Wireless Commun. Netw.2017(1),54(2017)10.1186/s13638-017-0836-0Web of Science®Google Scholar42Li, Z.,Xu, Y.,Liu, K.,Wang, X.,Liu, D.:5G with B-MaFIB based named data networking.IEEE Access.6,30501-30507(2018)10.1109/ACCESS.2018.2844294Web of Science®Google Scholar"
"AbstractIn this article, we look at research published over a five-year time span in the economics of information systems (IS) area in four premier journals, includingManagement Science,Information Systems Research,MIS Quarterly, andProduction and Operations Management, to identify research themes that have implications for future research in the area of Management of Technology (MOT). Through our examination of the literature, we identify three emergent themes that can be used to form foundations for future MOT research from an economics of IS perspective: productivity, vertical relations, and platforms. Within each of these themes, we classify previous research into subthemes, summarize the major findings, and explore future research opportunities within the MOT domain that are relevant to these subthemes. Specifically, we examine how information technology has impacted firm productivity, their product design and development process, innovation capabilities, knowledge management capabilities, and supply chain integration.1 IntroductionRevolutions in fundamental technologies last a very long time - much longer than most people believe - when applied to production and operations. Two common examples are the printing press and the steam engine. The first fifty years after 1455 when Gutenberg perfected the printing press resulted in an explosion in communication and information from automation of the printed word. In the early 1500s, Luther's German Bible and Machiavelli'sThe"
"the steam engine. The first fifty years after 1455 when Gutenberg perfected the printing press resulted in an explosion in communication and information from automation of the printed word. In the early 1500s, Luther's German Bible and Machiavelli'sThe Princeinitiated a social and economic revolution that continued for the rest of that century. Similarly, the steam engine applied to industrial operations (the spinning of cotton) in 1785 initiated an industrial revolution in automation and production that lasted until the early 1820s. Then the steam engine was applied to transportation through railroads, beginning a forty-plus year revolution that compressed time and space that fundamentally changed production and distribution as well as instigated economic and social change (Drucker1999). These revolutions in fundamental technologies resonated for close to 100 years.Comparatively, the information revolution beginning with the industrial use of chip-based information technology (IT) started in the late 1950s, and for the first forty years followed a performance/price evolution - characterized by Moore's Law doubling approximately every two years - that far outmatched that of the printing press or steam engine. The widespread availability of the Internet in the mid-1990s has had similarly significant social and economic impacts as broadly distributed influential books and railroads in the prior revolutions. Productivity increases from IT (when measured properly) to around 2010"
"availability of the Internet in the mid-1990s has had similarly significant social and economic impacts as broadly distributed influential books and railroads in the prior revolutions. Productivity increases from IT (when measured properly) to around 2010 are unprecedented. In recent years, IT's potential has increased further with cloud computing, nano technology, multi-processor arrays, quantum computing, telecommunications and mobile computing, and other new developments. These information and communication technologies provide the basis for new IT applied to production and operations, and new research challenges in how to manage these technologies.Our objective in this article is to identify emergent themes for future research in the interface of management of technology (MOT) applied to operations management (OM), and the economics of information systems (econ of IS). The three emergent themes that result from our analysis areproductivity,vertical relations, andplatforms. Our article proceeds as follows. First we discuss the role of the econ of IS in MOT research and the applicable methodologies, and describe our approach to searching the literature. Next, for each emergent theme, we summarize some of the relevant research that has appeared in a set of top journals over the last five years, and then explore possible future research opportunities in each theme. We conclude with suggestions for integrating different aspects of the emergent themes.2 The Role of the"
"research that has appeared in a set of top journals over the last five years, and then explore possible future research opportunities in each theme. We conclude with suggestions for integrating different aspects of the emergent themes.2 The Role of the Economics of Information Systems in MOTAs a sub-discipline of the broader management information systems discipline, the econ of IS studies the impact of IT on individuals, organizations, industries, and society from an economics perspective. Although not comprehensive, the econ of IS entails studying individuals maximizing utility through choice decisions; organizations choosing prices, quantities, incentive systems, channel structures, and production technologies to maximize profits; industries that aggregate supply and demand, and have supply chain and input-output relationships with other industries; and society where planners or governments impose policy-based regulations and incentive systems.In the context of the MOT in OM, the role of the econ of IS is to examine how IT in its various forms is used to enhance and integrate the product development process (e.g., improving time-to-market), aid in production and operations as well as manage their impacts (e.g., expanding the mix of products), change the structure and efficiency of vertical supply chains from raw materials to different channels offered to consumers (e.g., cost reductions in inventory from real-time information), and more effectively use internal and"
"the mix of products), change the structure and efficiency of vertical supply chains from raw materials to different channels offered to consumers (e.g., cost reductions in inventory from real-time information), and more effectively use internal and external resources to generate productivity (e.g., smaller workforce with improved capabilities). Many of these are also reflected in Gaimon et al. (2017) in this issue.2.1 Approach to Searching the LiteratureWe took a two-pass approach to searching the literature in order to identify and elaborate on our three emergent themes:productivity,vertical relations, andplatforms. We started by selecting the four highest quality journals where we expect to find research combining MOT with the econ of IS:Information Systems Research, Management Information Systems Quarterly, Management Science, and Production and Operations Management. On the first pass, starting from 2010 and proceeding to mid-2015 (5.5 years), we went through the four journals identifying articles that combined MOT with econ of IS. From this set of articles we identified and chose the three emergent themes in which there exists recent research and for which we believe there are important new research challenges. Then on a second pass we reduced the set of articles to those that are most relevant to the emergent themes we chose. Our two-pass approach was by necessity subjective: emergent themes could not be defined a priori.The three emergent themes are not meant to be"
"on a second pass we reduced the set of articles to those that are most relevant to the emergent themes we chose. Our two-pass approach was by necessity subjective: emergent themes could not be defined a priori.The three emergent themes are not meant to be mutually exclusive or collectively exhaustive - there is existing and potential future work that is consistent with multiple themes. Our emergent themes and subthemes are shown in Figure1. Conceptually, we believe platforms form a technical basis for firms to vertically integrate. Platforms also provide the necessary technical capability for firms to coordinate their activities and increase their productivity. Vertical relations, similarly, can impact productivity - higher level of IT adoption and integration allows firms to take advantage of IT, which increases their productivity. Within each theme we considered broad categories of research. In productivity we considered different types of spillovers, substitution of IT for other inputs, coordination, and sustainability. In vertical relations we examined the partially opposing options of integration and intermediation, and how IT adoption occurs in vertical structures. In platforms we identified capabilities, and the effects of these capabilities on new product development, on knowledge markets, and on manufacturing and customization.Figure 1Open in figure viewerPowerPointEmergent Themes and Subthemes3 Productivity: Emergent Theme 1To understand how IT can affect MOT in"
"of these capabilities on new product development, on knowledge markets, and on manufacturing and customization.Figure 1Open in figure viewerPowerPointEmergent Themes and Subthemes3 Productivity: Emergent Theme 1To understand how IT can affect MOT in OM, it is helpful to introduce a production function. A production function describes output as a function of inputs and assumes a technological relationship within and between inputs to product output. A commonly-used function form for a production function is a Cobb-Douglas:(1)whereYis output,Lis labor,Kis non-IT capital,Zis IT capital, andMis intermediate inputs. Intermediate inputs typically include materials, energy, and purchased services. All are measured in real dollars to capture the concept of quantities except labor that is measured in hours or full-time equivalents. The parametersα,β,γ, andθare the output elasticities with respect to labor, non-IT capital, IT capital, and intermediate inputs, respectively. For a constant returns to scale production technology the output elasticities sum to one. Linearizing Equation1using logs yields a simpler form:(2)where lower cases are the log of the upper case variables. The parametersin Equation2, which would be the intercept in a regression model of Equation2, represents total factor productivity (TFP) that captures the combined effect of the inputs on output separate from their direct effect through the production function. As Kundisch et al. (2014) show, TFP can be further"
"in a regression model of Equation2, represents total factor productivity (TFP) that captures the combined effect of the inputs on output separate from their direct effect through the production function. As Kundisch et al. (2014) show, TFP can be further partitioned into rates of returns on the inputs together with a remaining technological effect.From the perspective of MOT, IT has a set of different effects on Equation2. There is a direct effect through the IT input that is reflected inγas well as an indirect effect through TFP. There are also potential indirect effects through the quantity of labor, non-IT capital, and intermediate inputs needed to produce a certain level of output as the presence of more or less IT can affect how much of these other inputs are needed.3.1 SpilloversIn past research, spillovers have been defined in two separate ways. The first comes from a stream of research in R&D that identifies spillovers as coming from knowledge that moves between firms within an industry, between IT service firms and their clients, or even among trading partners. Such knowledge spillovers from IT have been shown to affect productivity. Tambe and Hitt (2014) examine the effect of IT labor moving between firms. They use a slightly modified version of Equation1that in log form is(3)wherevais the log of value added (output less intermediate inputs) andxis IT investment by related firms weighted by the flow of IT labor between firms. The parameterνis the output elasticity"
"a slightly modified version of Equation1that in log form is(3)wherevais the log of value added (output less intermediate inputs) andxis IT investment by related firms weighted by the flow of IT labor between firms. The parameterνis the output elasticity of the spillover. Although TFP is not captured in their estimation form, they find that IT labor moving between firms is responsible for increased productivity. From the perspective of MOT, this points to operations benefitting from IT knowledge \"elsewhere\" through IT labor hired from IT intensive firms, and a receiving firm's absorptive capacity may determine the value of this benefit. Chang and Gurbaxani (2012a) examine knowledge spillovers from IT service industries - their R&D, and from trading partner industries - their IT capital, on firm productivity. They also use a slightly modified version of Equation1in log form:(4)wheresp1 is the IT knowledge spillovers from IT service industries andsp2 is the IT spillovers from trading partner industries. Both types of IT spillovers result in a greater increase in productivity for IT intensive firms and these increases are persistent. From the perspective of MOT, this suggests the need for complementary investments in IT in order to leverage the spillovers. Both of these studies employ somewhat dated firm-level productivity data, 1987-1994, in that it predates the Internet.The second stream of research in spillovers identifies IT spillovers between industries along the supply"
"to leverage the spillovers. Both of these studies employ somewhat dated firm-level productivity data, 1987-1994, in that it predates the Internet.The second stream of research in spillovers identifies IT spillovers between industries along the supply chain that come from increased information-sharing through various interorganizational systems or from IT that is reflected in the traded good. Cheng and Nault (2012) examine the effect of IT investments upstream on the productivity of supplying industries. As this reverses the flow of traded goods, this effect is posited to come from information sharing and coordination. In addition, they account for the relative concentration of the trading industries, and estimate a form that includes intermediate inputs on the right-hand side:(5)wherecis the log of the customer IT spillover andris the relative industry concentration. Using two industry-level data sets spanning 1987-2005 they find customer IT spillovers increase productivity and relative industry concentration affects the magnitude of the spillover. From the perspective of MOT, customer IT spillovers result from improved channel coordination and improved productivity. In an earlier related study, Cheng and Nault (2007) modeled supplier IT spillovers as an unmeasured increase in the quality of the traded good (e.g., improved features and reliability), and found substantial impacts on downstream productivity - highlighting that technology embedded in goods, whether through IT"
"supplier IT spillovers as an unmeasured increase in the quality of the traded good (e.g., improved features and reliability), and found substantial impacts on downstream productivity - highlighting that technology embedded in goods, whether through IT in the good or IT used in the production of the good, can increase productivity.3.1.1 Future OpportunitiesThe research above partitions the spillovers into three categories: IT knowledge, information sharing, and unmeasured increases in quality. The former two have significant potential for future research. IT knowledge spillovers may be generic IT knowledge, or they may be knowledge about particular implementations that are industry best practice. This means delving deeper intoxin Equation3which will affectνand any embedded measurement of TFP, and intosp1 andsp2 in Equation4that will affectandas well as TFP (s). From an MOT perspective, this distinction is important: if the IT knowledge spillovers are specific artifacts and implementations then choices of technology investments are more focused.Next, the IT spillovers upstream from information sharing and coordination - which may also happen downstream - reduce transaction costs. The finding that relative concentration affects which partner receives the productivity benefit from these reduced transaction costs opens two separate questions with implications for MOT. First, which transaction costs are being reduced: uncertainty, specificity, opportunism, etc? Second, how does"
"which partner receives the productivity benefit from these reduced transaction costs opens two separate questions with implications for MOT. First, which transaction costs are being reduced: uncertainty, specificity, opportunism, etc? Second, how does competition affect the allocation of productivity benefits from IT spillovers: using the terminology of Clemons and Kimbrough (1986), is it a case of competitive advantage or strategic necessity? This means expanding the specification ofcandrcin Equation5, and thus the estimatesμandηas well as TFP.3.2 SubstitutionDetermining whether a new technology is a substitute or complement to existing capital and labor is a key aspect of managing technology. The classic economic approach is to assess the elasticity of substitution between inputs. Following an earlier study by Dewan and Min (1997), Chwelos et al. (2010) extend the 1987-1994 firm level dataset described above to 1999 and find that increasing use of IT in production comes at the expense of labor. In contrast, IT can be a complement to non-IT capital - possibly reflecting positive effects of TFP. Decentralized IT (e.g., personal computers) are more price elastic than other IT capital. From the perspective of MOT, decentralized IT in operations may become a cheaper input that can be used in a broader set of applications.The studies immediately above use the Allen elasticity of substitution (AES), and as Zhang et al. (2015) point out, with more than two inputs as would be the"
"IT in operations may become a cheaper input that can be used in a broader set of applications.The studies immediately above use the Allen elasticity of substitution (AES), and as Zhang et al. (2015) point out, with more than two inputs as would be the case with a third input such as IT capital the AES is a relatively uninformative measure. The less well-known Morishima elasticity of substitution (MES) is a more informative measure as the scale of the measure is meaningful and the measure differs depending on which input price is changing. In particular, IT has had a consistent decline in price for a given level of performance. Across industries Zhang et al. (2015) find that reductions in the price of IT increase the quantity of IT in use without changing input share, and that in this way IT is a complementary input to both labor and non-IT capital. The implication for MOT is that the complementarity of IT with other inputs in operations makes them more productive.Substitution in the broader sense is not only about one input substituting for another, but also about firms' make or buy decisions. Thus, firms can choose to buy technology services such as using fee-for-service cloud computing and IT outsourcing, or they can choose to produce them internally using labor and capital. In a study closely related to their work cited in an earlier subsection, Chang and Gurbaxani (2012b) examine productivity gains from IT outsourcing, and start by identifying firm characteristics that"
"to produce them internally using labor and capital. In a study closely related to their work cited in an earlier subsection, Chang and Gurbaxani (2012b) examine productivity gains from IT outsourcing, and start by identifying firm characteristics that are more likely to lead to IT outsourcing such as larger firms and firms that face more variability in demand and in their input mix. For these firms, they find that productivity gains from IT outsourcing are substantial when modeling these gains through the transfer of knowledge from IT service firms, in contrast to the common view that firms lose IT knowledge when outsourcing. In this setting, the implication for MOT is that there are advantages in buying IT services rather than providing them in house, and these advantages are at least in part due to knowledge spillovers. Han et al. (2011) examine the relative productivity of IT outsourcing using industry level data. Using a slightly modified version of Equation1that in log form is(6)whereis the log of outsourced IT andis the remaining intermediate inputs, they find that IT outsourcing contributes a substantially higher marginal product than other intermediate inputs. Modifying Equation6to capture labor productivity they find IT outsourcing also enhances labor productivity, and effects are stronger when the industries are IT intensive such as when they have a high ratio of IT capital to output or to labor. The implication for MOT is again that buying IT services is more"
"find IT outsourcing also enhances labor productivity, and effects are stronger when the industries are IT intensive such as when they have a high ratio of IT capital to output or to labor. The implication for MOT is again that buying IT services is more productive than other intermediate inputs, and that in turn increases the productivity of labor.3.2.1 Future OpportunitiesThe increased awareness of the MES provides an important tool for assessing tradeoffs in the mix of inputs when input price changes over time differ so widely - the price of IT capital falling in contrast to prices of labor and other capital increasing. Studies providing MES within industries at the firm level may provide a better understanding of the tradeoffs between inputs in particular sectors, partially unlocking the critical MOT question ofhowIT can be a substitute or complement to labor and other capital.Furthermore, understanding the substitution or complementarity of IT with externally purchased IT services through MES estimates would enhance our understanding of how IT outsourcing increases productivity (as evidenced throughμin Equation6) as many IT outsourcing studies point to internal IT capabilities as being a contributing factor in successful IT outsourcing.In addition, with the ubiquitous presence of the Internet there is an open question regarding the productivity increases that have come as a consequence of such shared infrastructure. Shared infrastructure like the Internet can be either a"
"IT outsourcing.In addition, with the ubiquitous presence of the Internet there is an open question regarding the productivity increases that have come as a consequence of such shared infrastructure. Shared infrastructure like the Internet can be either a substitute or complement to all inputs, and likely has fundamental effects on the input mix between labor and different capitals. How shared infrastructure can be defined (e.g., the Internet, the so-called cloud) and its impact is a relatively unexplored area of MOT.3.3 CoordinationTwo articles inProduction and Operations Managementhave also had a focus on the impact of IT on coordination. At the project level, Bardhan et al. (2013) find that IT mitigates or reduces distance in the coordination of distributed teams, and this leads to higher project performance - especially for higher information volume projects. In terms of project teams, the implication for MOT is that IT can reduce time and space for distributed teams. By measuring new product development success by the proportion of revenue from new products, Bendoly et al. (2012) find that IT capability is related to new product development success. Moreover, IT capability also enhances operations-marketing coordination and operations-supply chain coordination. The MOT implications are that IT capability has direct and moderating effects on new product development success through coordination.3.3.1 Future OpportunitiesThe effects of coordination are most likely found in"
"and operations-supply chain coordination. The MOT implications are that IT capability has direct and moderating effects on new product development success through coordination.3.3.1 Future OpportunitiesThe effects of coordination are most likely found in TFP, oursin Equation2, as these productivity improvements result from how IT is combined with labor and other capital. In a descriptive article, Brynjolfsson and Hitt (2000) argue that IT can change how organizations are designed (see Vertical Relations later in this study), and can transform business processes - what they term as intangible capital. Both the coordination of distributed teams and of new product development above are intangible capital. As was shown in Kundisch et al. (2014), TFP can be comprised of rates of returns to individual inputs and technological change, where the latter can be interpreted as returns to intangible capital. As MOT is a substantial part of intangible capital, an important future research contribution is to better understand how to measure returns to intangible capital, and the effect of MOT on these returns.3.4 SustainabilityIn a seminal article inProduction and Operations Management, Kleindorfer et al. (2005) identifies multiple objectives of sustainability through a triple bottom line: people, profit and planet. Strategies to reduce the use of inputs (e.g., labor, material, energy) and the production of pollutants as outputs are key elements of the triple bottom line. These strategies"
"of sustainability through a triple bottom line: people, profit and planet. Strategies to reduce the use of inputs (e.g., labor, material, energy) and the production of pollutants as outputs are key elements of the triple bottom line. These strategies apply to firms as well as to supply chains, and an innovative approach to reduce the use of inputs and production of pollutants is closed-loop supply chains (CLSC) whereby the supply chain takes care of the entire life cycle of products from manufacture to disposal and remediation - possibly through a reverse supply chain.Drake and Spinler (2013) outline a series of firm risks associated with sustainability. There is a risk of regulation when not operating in a sustainable way, and there are also regulation threats from change in policies and tariffs when investing in sustainable goods and services. In addition, firms face increased risk where profits or cash flows are affected by changes in climate such as changes in growing seasons and natural disasters. Connecting to Kleindorfer et al. (2005), sustainability implemented as life-cycle management, CLSC, or extended producer responsibility (EPR) regulations, directly affects production technology choice. Furthermore, supply chain coordination is important because logistics creates a disproportionate share of pollution and emissions. Consequently, there are tradeoffs among trading partners in deciding where pollution and emissions are created, and greater logistics efficiency can"
"coordination is important because logistics creates a disproportionate share of pollution and emissions. Consequently, there are tradeoffs among trading partners in deciding where pollution and emissions are created, and greater logistics efficiency can mitigate net negative effects.In the IS literature, two articles inManagement Information Systems Quarterlyoutline a set of potential targets for IT and environmental sustainability. Melville (2010) focuses on environmental and economic dimensions (Kleindorferet al.'s profit and planet). Firstly, consistent with recommendations from the articles in the above two paragraphs, supply chain coordination has the opportunity to enhance both environmental and economic dimensions, and IT through spillovers and coordination in production can make substantial contributions toward sustainability and efficiency. Next, IT has contributions to make in product life-cycle assessments by helping forecast and monitor stages in product life cycles. IT makes these contributions through a big data approach: gathering data and summarizing useful metrics. More broadly, IT as a monitoring and reporting technology can affect public beliefs, and consequently motivate more environmentally responsible behavior. Finally, as a special case, IT hardware is particularly toxic when disposed of, and the short life-cycles of IT makes this particularly challenging. Watson et al. (2010) concentrate on a specific category of IT for the energy industry: energy"
"behavior. Finally, as a special case, IT hardware is particularly toxic when disposed of, and the short life-cycles of IT makes this particularly challenging. Watson et al. (2010) concentrate on a specific category of IT for the energy industry: energy informatics. The authors outline components of energy informatics as the flow network (which IT can optimize), a sensor network (IT can monitor and track) and sensitized objects (IT device that can monitor and make real-time decisions). Recognizing how quickly the energy industry is evolving, they posit a relationship between the granularity of information with enforcement/regulation of policy, incentives in policy, and use of components.3.4.1 Future OpportunitiesMOT not only involves production, but the ability to change production in response to changes in demand. A potentially important consideration is that of IT capital on capacity - does IT make production more efficient so that firms operate closer to their capacity limit, or does IT make changing production scale more flexible thereby increasing capacity so that firms operate at lower level of capacity utilization? In the latter case, IT can also facilitate the integration of contract capacity, adding to flexibility. Both connect IT to sustainability in production: increased efficiency in use of inputs or increased efficiency in growing capacity.In its most abstract form, sustainability in production is about producing output with less input or a different mix of"
"Both connect IT to sustainability in production: increased efficiency in use of inputs or increased efficiency in growing capacity.In its most abstract form, sustainability in production is about producing output with less input or a different mix of inputs. In addition to relating IT with capacity, there are tradeoffs in make vs. buy, and possible efficiency gains from the latter. One area of consideration is logistics - if there are efficiency gains from logistics outsourcing that come from wider and more interconnected transportation networks and from greater efficiency in less-than-truckload shipping, then these efficiency gains are supported by IT both within the transportation system and between customers and logistics suppliers. Understanding these relationships is also part of MOT.As an applied technology for industries, IT can also be used to monitor pollution, which can enable regulation or support incentive schemes like cap and trade systems. For end customers, monitoring energy use and therefore the resources consumed, either through the smart grid or comparable systems, has potential efficiency effects that roll back through the supply chain. In the case of electricity, greater efficiency from customers affects distribution, which affects transmission and then generation. How to best implement these technologies is an important MOT-for-sustainability topic, with the additional complication of data privacy being a critical issue for firms and individuals. Indeed,"
"distribution, which affects transmission and then generation. How to best implement these technologies is an important MOT-for-sustainability topic, with the additional complication of data privacy being a critical issue for firms and individuals. Indeed, this privacy/security issue is one of the greatest difficulties in applying CLSC: tracking the entire life cycle of products requires information about ownership and use, information typically considered private.3.5 Healthcare as a Special ExampleAs summarized in the previous subsections, researchers have looked at IT productivity from multiple aspects and across multiple industries. As a sector that makes up a large proportion of the economy and has special production characteristics, healthcare IT productivity has been particularly vexing. Bhargava and Mishra (2014) find that electronic medical records (EMR) have negligible effects on productivity possibly because EMR requirements pull the physician away from the patient, and the small effects found were for more general specialties such as pediatrics and family practice. The implication for MOT is that IT productivity in healthcare differs depending on the underlying task. Mukhopadhyay et al. (2011) find that the learning rate of newly implemented physician referral systems lags that of similar systems in other manufacturing and services industries. The referral system is essentially a routing problem for emergency, non-emergency, and out-of-network cases where the"
"rate of newly implemented physician referral systems lags that of similar systems in other manufacturing and services industries. The referral system is essentially a routing problem for emergency, non-emergency, and out-of-network cases where the sequence goes from high domain/low systems (e.g., emergency cases require immediate domain knowledge and little systems involvement) to low domain/high systems (e.g., out-of-network cases require high systems involvement to identify and notify other healthcare providers). From the perspective of MOT, the learning rate is highest for low domain knowledge/high systems involvement settings.Angst et al. (2011) examines integration between technologies in health care: medical technologies to specific health IT to more general IS. For example, a computed tomography (CT) scanner may be linked to a hospital Picture Archiving and Communication System (PACS) that is in turn integrated with other hospital systems. Thus, the CT scanner is a medical technology, PACS is a specific health IT application, and patient records, physician scheduling, accounting, etc. are general IS modules. They find that interoperability - the ability of different technologies to work together - in the sequence of technology integration yields higher productivity. In addition, they find that given more general IS is the basis for interoperability, then IS should be developed first in the order of integration. The lesson for MOT is that developing and implementing"
