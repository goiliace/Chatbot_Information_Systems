"Scholar18Li Z.andHonghong M.,Contrastive research of college students' English learning methods based on internet and traditional environment,Advances in Social Sciences Research Journal. (2020)7, no. 6,745-756,https://doi.org/10.14738/assrj.76.8530.10.14738/assrj.76.8530Google Scholar19Rajendran A.,Balakrishnan N., andAjay P.,Deep embedded median clustering for routing misbehaviour and attacks detection in ad-hoc networks,Ad Hoc Networks. (2022)126, 102757,https://doi.org/10.1016/j.adhoc.2021.102757.10.1016/j.adhoc.2021.102757Web of Science®Google Scholar20Radivojevic S.,(De) colonization of the digital environment: the internet and new(er) media as places of contemporary anthropological research and how to approach them ethnographically,Bulletin de l'Institut etnographique. (2020)68, no. 2,419-438,https://doi.org/10.2298/gei2002419r.10.2298/gei2002419rGoogle Scholar21Xu L.andTsai S. B.,The transformation of college students' ideological and political education and learning analysis of education system by streaming media technology,Mathematical Problems in Engineering. (2021)2021, no. 674,1-11,https://doi.org/10.1155/2021/3285830.10.1155/2021/4661933Web of Science®Google Scholar22Jie Y.,Guo C.,Choo K. K. R.,Liu C. Z., andLi M.,Game-theoretic resource allocation for fog-based industrial internet of things environment,IEEE Internet of Things Journal. (2020)7, no. 4,3041-3052,https://doi.org/10.1109/jiot.2020.2964590.10.1109/JIOT.2020.2964590Web of Science®Google"
"C. Z., andLi M.,Game-theoretic resource allocation for fog-based industrial internet of things environment,IEEE Internet of Things Journal. (2020)7, no. 4,3041-3052,https://doi.org/10.1109/jiot.2020.2964590.10.1109/JIOT.2020.2964590Web of Science®Google Scholar23Veselov G.,Tselykh A.,Sharma A., andHuang R.,Applications of artificial intelligence in evolution of smart cities and societies,Informatica. (2021)45, no. 5,https://doi.org/10.31449/inf.v45i5.3600.10.31449/inf.v45i5.3600Web of Science®Google Scholar24Yu H.,Application analysis of new internet multimedia technology in optimizing the ideological and political education system of college students,Wireless Communications and Mobile Computing. (2021)2021, no. 4,1-12,https://doi.org/10.1155/2021/5557343.10.1155/2021/5557343CASPubMedWeb of Science®Google Scholar25Zhang Y.,Research on ideological and political education of college students from the perspective ofsystem theory,Frontier of Higher Education. (2020)2, no. 2,1-17,https://doi.org/10.36012/fhe.v2i2.2764.10.36012/fhe.v2i2.2764Google Scholar26Yin Y.,Research on ideological and political evaluation model of university students based on data mining artificial intelligence technology,Journal of Intelligent and Fuzzy Systems. (2021)40, no. 2,3689-3698,https://doi.org/10.3233/jifs-189403.10.3233/JIFS-189403Web of Science®Google Scholar27Ma R.,Research on the cultivation of college students' ideology based on the practice of education,International Journal of Social"
"Systems. (2021)40, no. 2,3689-3698,https://doi.org/10.3233/jifs-189403.10.3233/JIFS-189403Web of Science®Google Scholar27Ma R.,Research on the cultivation of college students' ideology based on the practice of education,International Journal of Social Science and Education Research. (2020)3, no. 2,186-191.Google Scholar28Wang X.,A questionnaire analysis on the status quo of contemporary college students' ideological and political quality,Open Journal of Social Sciences. (2020)8, no. 9,207-220,https://doi.org/10.4236/jss.2020.89015.10.4236/jss.2020.89015Google ScholarCiting Literature"
"AbstractWith the increasingly fierce competition in the product economy, there are more and more constraints on the development of enterprises, especially from the requirements of customers. Enterprises should be committed to development and meet customer needs first. However, the existing marketing plan and quality management also take customer satisfaction into account, so this paper aims to design the enterprise precision marketing strategy and quality management mobile information system based on the customer satisfaction model. For the precise marketing strategy of enterprises, this paper proposes three indicators of product quality, product delivery, and product service based on the customer satisfaction model and uses the hesitant fuzzy set to quantify the indicator model and apply it in the information system. For the quality management system, this paper uses PDCA cycle indicators to upgrade and optimize the quality management system. The test results show that the system has achieved a customer retention rate of 95% in terms of precise marketing strategies; in terms of quality management, it has improved the quality of enterprise products by about 20%. In the overall test of the system, the communication delay and reliability of the system are obviously optimized. This proves that the system can adjust the marketing strategy in real time according to the opinions of customers, achieve the purpose of precise marketing, and improve the quality management to a new"
"and reliability of the system are obviously optimized. This proves that the system can adjust the marketing strategy in real time according to the opinions of customers, achieve the purpose of precise marketing, and improve the quality management to a new height in line with customer satisfaction which shows that the information system designed in this paper can meet the purpose of precise marketing strategy and quality management of enterprises.1. IntroductionIn the current digital information age, traditional management analysis and decision-making methods can no longer meet the rapid development requirements of enterprises. Faced with emerging opportunities and increasingly fierce competition, new management decision-making methods emerge as the times require, among which management methods based on data-based decision-making have received more and more attention. The main method of data-based decision-making is to use data mining and other means to analyze massive data and analyze and extract potentially useful information from a large amount of actual business data. Satisfied customers are bound to be loyal, and if this loyalty can be maintained for a long time, companies are less likely to be abandoned because other companies offer slightly lower prices. Even when an enterprise faces difficulties in its operation, satisfied customers will remain loyal for a certain period of time and within a certain range, so that the enterprise has the opportunity to take measures to"
"offer slightly lower prices. Even when an enterprise faces difficulties in its operation, satisfied customers will remain loyal for a certain period of time and within a certain range, so that the enterprise has the opportunity to take measures to deal with the difficulties and buys time for the enterprise. At the same time, satisfied customers also do not choose new products immediately, because choosing new products is also risky for customers. Therefore, it is necessary to design the enterprise precision marketing strategy and quality management mobile information system based on customer satisfaction.So far, there is no systematic research on how to reasonably improve the quality management of enterprises according to customer satisfaction. Ma et al. studied a low-cost hybrid power quality management system for negative sequence and reactive power compensation in V/v traction power supply system [1]. Baaran has done a lot of research on the quality of enterprise generation management. He upgraded the ISO 9001 standard and proposed a higher quality management system [2]. Chupikova et al. conducted research on the production quality of fishery enterprises, and they introduced the production process plan of frozen shrimp and frozen seaweed, the control points of the process, and the recommended measuring instruments for the control parameters of the process [3]. Kalmutchi conducted research on the operational safety of airlines [4]. Krupko and Shaburova described the"
"and frozen seaweed, the control points of the process, and the recommended measuring instruments for the control parameters of the process [3]. Kalmutchi conducted research on the operational safety of airlines [4]. Krupko and Shaburova described the effectiveness of expanding the field of certification in the development of a quality management system (QMS) for metrological services [5]. However, the relevant research on quality management is more concerned with the establishment of quality standards, without taking into account customer satisfaction.Precision marketing focuses on the comprehensive process control of sales management and strengthens the ability to implement the sales process. There are many studies on precision marketing. For the precision marketing of enterprises, Zhao and Ma combined the precision marketing data source system based on big data to introduce data standardization and quality model, so as to provide a reference for building a data source system based on big data [6]. Bo and Zhang aim to build an online precision marketing system model based on big data, realize the Hadoop + MapReduce precision marketing model platform, and provide a basis for enterprise decision-making [7]. Zhang et al. aims to use data mining clustering technology to analyze the characteristics of user's mobile behavior trajectory and build a tourism accurate recommendation system; it can provide support for tourism decision-making and can carry out precise marketing for"
"to use data mining clustering technology to analyze the characteristics of user's mobile behavior trajectory and build a tourism accurate recommendation system; it can provide support for tourism decision-making and can carry out precise marketing for tourist groups, so that tourists can travel more intelligently [8]. Li and Cheng use Internet technology to optimize various industrial links of agricultural production and operation, so as to achieve precise marketing of agricultural products [9]. However, the research on precision marketing rarely considers customer satisfaction, and most of them focus on tracking algorithms for customer classification and customer behavior. Therefore, the precise marketing and quality management system based on customer satisfaction in this paper is very necessary.In this paper, a method to improve the reliability of data fusion, TGDA algorithm, is proposed. In order to analyze the basic performance of the TGDA algorithm, 100 rounds of simulation experiments are performed on the OPNET platform, which proves that the communication delay of the system is reduced by about 20%, and the reliability is improved 30%. The innovations of this paper are as follows: In view of the development trend of global economic integration, high-end customers and groups are gradually increasing, the demand for high-quality products is also increasing, and customer demand is improving, and this paper designs a mobile information system based on the customer"
"of global economic integration, high-end customers and groups are gradually increasing, the demand for high-quality products is also increasing, and customer demand is improving, and this paper designs a mobile information system based on the customer satisfaction model. The system can implement precise marketing with more customer information and customer satisfaction and can manage product quality through the satisfaction returned by customers.2. Precision Marketing and Quality Management in the Context of Customer Satisfaction2.1. Precision Marketing StrategyData management capabilities have gradually become a winning factor in business competition. In the era of digital information, only with good data information collection and analysis capabilities can more accurate decisions be made and ultimately promote the continuous improvement of corporate value. Relying on advanced data management and analysis tools, precision marketing is an important scientific analysis method and technical means for enterprises to carry out customer relationship management. At the same time, precision marketing is different from traditional marketing that only rests on the performance requirements of sales personnel but emphasizes the transformation from a salesperson-centered management method to a comprehensive management and control of sales activities through planning, executing and monitoring the company's sales activities [10]. The effective management of the process is beneficial to"
"from a salesperson-centered management method to a comprehensive management and control of sales activities through planning, executing and monitoring the company's sales activities [10]. The effective management of the process is beneficial to the enterprise to discover the problems in the activity process and execution in time, help to adjust the strategy in time, and ensure the effectiveness of the activity. The relationship between customer satisfaction and precision marketing is shown in Figure1.Open in figure viewerPowerPointIn addition to the data analysis and preparation in the early stage, precision marketing includes the entire marketing business process based on data decision-making: that is, clarifying the campaign objectives and scope before creating a marketing campaign, formulating campaign plans based on marketing goals, and business personnel executing according to the plan. The activity phase summarizes and summarizes the entire process. The development of precision marketing business first needs to analyze the market and formulate targeted marketing activities [11]. The so-called market analysis is to make judgments by clarifying the background of the customers participating in the activities and the market performance of the business products related to the marketing activities before the formulation of the marketing plan and then describing the accurate characteristics of the target customers to establish a feature database. The marketing planning"
"market performance of the business products related to the marketing activities before the formulation of the marketing plan and then describing the accurate characteristics of the target customers to establish a feature database. The marketing planning process includes formulating a marketing plan based on market analysis results and marketing objectives, targeting the characteristics of target customers and designing a targeted marketing plan, clarifying marketing steps and promotion channels, and finally implementing and supervising marketing activities.The customer resource information of an enterprise is the most important enterprise resource. Only with good data management capabilities can an enterprise scientifically collect, analyze, and manage customer data. However, with the improvement of the level of informatization, consumers increasingly demand diversified, personalized, and intelligent services. In order to ensure the market competitiveness of enterprises, enterprises must be able to accurately identify the needs of customers, be customer-centric, provide accurate services to existing customers, and accurately guide potential customers, so as to achieve the goal of sustainable development. In this sense, reacquainting customers and identifying customers, being able to accurately identify important customers and effectively discover potential customers has become a crucial link in the process of customer relationship management. What this paper will study is"
"customers and identifying customers, being able to accurately identify important customers and effectively discover potential customers has become a crucial link in the process of customer relationship management. What this paper will study is the design and implementation of a customer-oriented precision marketing solution for enterprises [12].2.2. Quality Management SystemAs a quality improvement tool, PDCA quality cycle plays an important role in the quality control of \"products\" of enterprises. Through the realization and operation of each link, the quality of \"products\" is gradually improved. At the same time, the \"Quality Management System Maturity Evaluation Criteria\" propose that the PDCA cycle can also play the role of evaluation criteria in the enterprise quality management system. One is that the PDCA cycle is thoroughly implemented in every link of the quality management system, and the second is that it uses the concept of continuous improvement to achieve the idea of improving the quality of \"products,\" so that the operation of PDCA can also be used as the standard for judging the operation status of the quality management system [13]. In addition, the idea of this criterion can be used not only for self-evaluation of the internal quality management system of the enterprise, but also for the second and third parties to evaluate the operation status of the enterprise quality management system. In addition, some scholars have applied PDCA cycle to other related"
"of the internal quality management system of the enterprise, but also for the second and third parties to evaluate the operation status of the enterprise quality management system. In addition, some scholars have applied PDCA cycle to other related fields in enterprise operation such as enterprise performance evaluation and enterprise development level evaluation, which further verified that not only is PDCA a quality improvement tool, but its core idea can be applied to quality improvement of other related aspects. Among them, the specific main evaluation items are based on the four dimensions of P (Plan), D (Do), C (Check), and A (Act), and each item is quantitatively scored and qualitatively evaluated.In \"Quality Management System Maturity Evaluation Criteria,\" the criteria and framework of enterprise quality management system evaluation have been given according to PDCA cycle, which proves that PDCA cycle can not only be used as an improvement model, but also be used as evaluation criteria to measure enterprise quality management system. The development level and situation [14]: The quality management system studied in this paper is essentially a system for measuring the level of enterprise quality management. Starting from the concept of the system, the idea of quality improvement is permeated in every link of enterprise production, operation, and management, so as to achieve the goal of improving quality, purpose closely linked to corporate strategy, development"
"from the concept of the system, the idea of quality improvement is permeated in every link of enterprise production, operation, and management, so as to achieve the goal of improving quality, purpose closely linked to corporate strategy, development direction, and \"product\" production. Therefore, this paper will continue the core idea in the \"Quality Management System Maturity Evaluation Criteria\" and select four dimensions of P (Plan), D (Do), C (Check), and A (Processing) as the enterprise quality. The evaluation criteria of the management system, on the basis of ensuring that the evaluation items are reasonable and correct, further use the core idea of continuous improvement to evaluate and improve the enterprise quality management system and integrate traditional quality improvement tools with emerging quality evaluation methods. Among them are P (plan): suitability, systematicness, and effectiveness of planning output; D (implementation): comprehensiveness, continuity, and strictness of implementation; C (check): sufficiency of monitoring basis and accuracy of objects and the visibility of the results; A (treatment): analyze and evaluate the monitoring results and decide whether to implement improvements.2.3. Hesitant Fuzzy SetsThe evaluation of enterprise soft quality is a highly subjective evaluation problem, and most of the data considered in the index system are discrete data without obvious functional relationship. Therefore, compared with type-1 fuzzy sets and"
"Fuzzy SetsThe evaluation of enterprise soft quality is a highly subjective evaluation problem, and most of the data considered in the index system are discrete data without obvious functional relationship. Therefore, compared with type-1 fuzzy sets and type-2 fuzzy sets, hesitant fuzzy sets can express the subjective hesitant ambiguity of decision makers without inducting membership functions and have more practical application value.In the soft quality evaluation problem involving multigroup decision-making, the hesitant fuzzy set can avoid the distortion and distortion of information to the greatest extent when the opinions of decision makers are not unified and can avoid the problem of reaching a consensus. A process (this process itself has a certain degree of difficulty and the process is cumbersome and complicated) can retain the original and effective information [15].From a statistical point of view, it is difficult for enterprises to keep data for many years in the evaluation process. If there is a lack of data in certain years, hesitant fuzzy sets can use discrete data for each year to obtain statistical results. In the decision-making process where the minority obeys the majority, the constructiveness of minority opinions cannot be ignored. To retain all the opinions, it is obvious that hesitant fuzzy sets have this function [16].If different decision makers give results of 0.3, 0.5, and 0.7 when evaluating a certain indicator, only the weighted average will be"
"opinions cannot be ignored. To retain all the opinions, it is obvious that hesitant fuzzy sets have this function [16].If different decision makers give results of 0.3, 0.5, and 0.7 when evaluating a certain indicator, only the weighted average will be used to calculate the evaluation value of 0.5, and the two values of 0.3 and 0.7 will be obtained. The evaluation result loses its own meaning.Through the above analysis, in view of the obvious advantages of hesitant fuzzy sets in enterprise soft quality evaluation, this paper intends to use hesitant fuzzy sets as the data basis, in order to make decisions that best meet the actual needs of enterprises in the decision-making process of the expert group. Next, we will introduce the algorithm of hesitant fuzzy sets [17].LetXbe a given set(1)HMis defined as(2)For the convenience of expression, the whole hesitant fuzzy set on the finite universeXis denoted as HFS(X), andhA(x) is called the hesitant fuzzy element of A, abbreviated ashA.For any three hesitant fuzzy elementsh1,h2,h3, their algorithm is as follows (whereθis a constant):(3)Define function as Θ:(4)Leth(x) be the hesitant fuzzy element(5)The formula is called the scoring function ofh(x), where #h(x) represents the number of elements contained inh(x).2.4. Customer Satisfaction ModelThe formula for calculating customer satisfaction is as follows:(6)Among them,Cirepresents the score of the customer's evaluation of the ith indicator,Wirepresents the weight of the ith"
"number of elements contained inh(x).2.4. Customer Satisfaction ModelThe formula for calculating customer satisfaction is as follows:(6)Among them,Cirepresents the score of the customer's evaluation of the ith indicator,Wirepresents the weight of the ith indicator, and CSI represents the customer satisfaction index.2.4.1. Product Quality SatisfactionThrough the analysis of the calculation results of customer satisfaction in Table1, the customer satisfaction of the standard product quality is 7.2134, which is in a state of lower satisfaction. Among them, the fourth item in terms of product quality is the convenience, stability, reliability, and advancement of product assembly: whether the 6th item can solve the quality problems reported by customers in a timely and effective manner; whether the 7th item has repeated quality incidents in the short term; whether the 8th item is satisfied with the quality system assurance capability customer satisfaction 5.7324, item 9 on the quality improvement of products, and customer satisfaction 5.5070; whether the products developed in item 12 meet the customer's requirements, customer satisfaction 6.4014, all at the basic customer satisfaction level. The third item is whether there are appearance problems such as bumps, folds, dirt, etc. Customer satisfaction is 3.4718, which is lower than the red line of 4 points of dissatisfaction, and it is in the level of customer dissatisfaction.1.Product quality satisfaction.Three-level"
"there are appearance problems such as bumps, folds, dirt, etc. Customer satisfaction is 3.4718, which is lower than the red line of 4 points of dissatisfaction, and it is in the level of customer dissatisfaction.1.Product quality satisfaction.Three-level indicatorWeightsWiMeanCiSatisfaction CSIProduct design compliance0.15568.27.1234Product development process0.10019.1Product appearance quality0.04083.5Product assembly performance0.10896.1Quality problem solving ability0.08219.42.4.2. Satisfaction with Product DeliveryAccording to the evaluation results of the customer satisfaction statistical table in Table2, the delivery satisfaction of the standard layer products is 8.3037, and the overall score reaches the satisfaction level. However, whether the fourth item in this part meets the customer's temporary change or additional demand for goods, the satisfaction level is 6.3380, which is at 6.3380. The 8th survey content is whether to actively cooperate with customers to improve work in all aspects. Customer satisfaction is 3.5070, which is lower than the red line standard of satisfaction and is in the level of customer dissatisfaction.2.Product delivery satisfaction.Three-level indicatorWeightsWiMeanCiSatisfaction CSIPunctuality of delivery0.15038.98.4073Delivery accuracy0.15769.1Temporary supply capacity0.08976.3Spare parts delivery capability0.09018.2Logistics problem solving efficiency0.04767.12.4.3. Product Service SatisfactionAccording to the evaluation results of the"
"of delivery0.15038.98.4073Delivery accuracy0.15769.1Temporary supply capacity0.08976.3Spare parts delivery capability0.09018.2Logistics problem solving efficiency0.04767.12.4.3. Product Service SatisfactionAccording to the evaluation results of the customer satisfaction statistical table in Table3, it can be seen that the overall evaluation score of H company's product service capability is 6.7176, which is in the basic customer satisfaction level and can meet the basic needs of customers for various products and services. The content has a score of 4.4648 on the speed and efficiency of after-sales handling of product problems, which is relatively low. It can only reach the basic satisfaction level and is offline, indicating that the timeliness of solving problems is not timely enough.3.Product and service satisfaction.Three-level indicatorWeightsWiMeanCiSatisfaction CSIEase of communication0.08639.38.4107After-sales problem handling efficiency0.22974.5Effectiveness in solving quality problems0.52466.5Salesperson's work initiative0.11079.4The attitude of the sales staff0.04039.53. Enterprise-Level Precision Marketing and Quality Management Information System Design3.1. Precision Marketing System Process and Prediction Model Tool SelectionAs shown in Figure2, there is the concept of customer grouping in precision marketing, which corresponds to the recommendation system and generally refers to the prediction model technology. Prediction model refers to the use of data mining"
"Tool SelectionAs shown in Figure2, there is the concept of customer grouping in precision marketing, which corresponds to the recommendation system and generally refers to the prediction model technology. Prediction model refers to the use of data mining methods to find the rules of customer behavior based on the massive stock of historical customer behavior data and to apply these rules to predict the customer behavior that may occur in the future [18].Open in figure viewerPowerPointSAS' Enterprise Miner software is the most popular data mining analysis tool [19]. SAS can apply multiple predictive models to the data at the same time and use the \"lift chart\" to compare the predictive effects of the models used and select the optimal model based on the evaluation. The specific process of using Enterprise Miner to build a prediction model is shown in Figure3.Open in figure viewerPowerPointFirst read the data through the data reading module, then perform data transformation and data segmentation operations on the preprocessed data according to specific business requirements, and then perform the \"regression model,\" \"decision tree analysis,\" and \"decision tree analysis\" in data mining for the preprocessed data at the same time. Predictive models such as \"neural network\" algorithms are for predictive analysis. Finally, based on business requirements, model evaluation is carried out for the three prediction models, and the prediction results are finally sorted to obtain prediction"
"Predictive models such as \"neural network\" algorithms are for predictive analysis. Finally, based on business requirements, model evaluation is carried out for the three prediction models, and the prediction results are finally sorted to obtain prediction recommendation data [20].3.2. Quality Management Information SystemThis paper takes the evaluation of enterprise quality management system as the research background, selects the widely used PDCA as the evaluation criterion, and focuses on the four dimensions of P (Plan), D (Do), C (Check), and A (Process Act). Build an evaluation model that conforms to its characteristics, establish an evaluation model of the enterprise quality management system, and conduct an example analysis in the model construction of each link. The quality management information system architecture is shown in Figure4.Open in figure viewerPowerPoint3.3. Data Module Architecture DesignIn order to overcome various problems faced by data integration, the data processing part of this paper adopts ETL technology to realize the integration of customer resource data. Generally, the data obtained after the predictive model analysis of the original data (generally customer information and behavior records) cannot be directly applied to the precision marketing system. After the SAS analysis data is acquired, some data grouping and other processing operations can be performed at the same time in the process of data loading through ETL.For the above process, the"
"be directly applied to the precision marketing system. After the SAS analysis data is acquired, some data grouping and other processing operations can be performed at the same time in the process of data loading through ETL.For the above process, the precision marketing architecture of this paper designs a four-layer data structure to store analysis data at different stages. The relationship is shown in Figure5.Open in figure viewerPowerPoint3.3.1. ETL Buffer LayerSAS analysis results are generally in text or other nondatabase formats. So the first step is to load the SAS analysis results into the buffer layer data table through the ETL tool for the next step to perform data processing operations.3.3.2. Data Packet LayerETL directly performs data processing operations on the buffer layer data table. Through the processing flow configured in ETL Job, the analyzed data results are grouped or labeled according to business requirements. The data obtained after grouping and labeling operations can be used for the recommendation system engine to execute.3.3.3. Precision Marketing Business LayerThis is the business layer data table of the precision marketing system, which is generally designed according to the business function requirements of the system and the requirements of the recommendation engine. At the same time, some data (such as customer information data) will be stored in the corresponding business table when the ETL processing buffer layer operation is"
"function requirements of the system and the requirements of the recommendation engine. At the same time, some data (such as customer information data) will be stored in the corresponding business table when the ETL processing buffer layer operation is performed.3.3.4. System Configuration LayerThe system configuration layer is mainly used for the relevant configuration during the operation of the precision marketing system. At the same time, it also includes information such as user rights and departments related to the use of system management.3.4. Architecture Design of Enterprise Application Service SystemIn order to ensure the stability and pressure resistance of the enterprise-level system, the system deployment adopts B/S layering, hardware distribution, and Weblogic cluster deployment. The detailed server deployment arrangement is shown in Figure6.Open in figure viewerPowerPoint4. Enterprise Accuracy Results and Discussion4.1. Customer Satisfaction Precision Marketing PerformanceFor virtual unit scheduling considering customer satisfaction, the objective function of the running scheduling scheme has an optimal average customer satisfaction of 0.945, and the Gantt chart and convergence diagram of the optimal scheduling scheme are shown in Figures7(a)and7(b).Open in figure viewerPowerPointOpen in figure viewerPowerPointBased on the existing researches using triangular fuzzy numbers to represent the completion time and semitrapezoidal fuzzy numbers to represent the"
"scheme are shown in Figures7(a)and7(b).Open in figure viewerPowerPointOpen in figure viewerPowerPointBased on the existing researches using triangular fuzzy numbers to represent the completion time and semitrapezoidal fuzzy numbers to represent the delivery time to establish a satisfaction scheduling model, considering the characteristics and computational complexity of the actual scheduling problem, a six-point fuzzy number representation is proposed. Completion time is a trapezoidal fuzzy number representing the satisfaction scheduling model of the delivery date. This paper uses the stability evaluation index to evaluate the stability of the theoretical optimization scheme in actual implementation to verify that the representation method proposed in this paper is more in line with the actual production, and the obtained optimization scheme is more stable.The optimal scheduling scheme of manager satisfaction and customer satisfaction obtained above, as well as the triangular fuzzy number representing the processing time and the semitrapezoidal fuzzy number representing the delivery time, the optimal scheduling scheme of manager satisfaction and customer satisfaction is between 0.5 and 0.5. Solve the stability index at the 0.75 confidence level. Table4shows that the six-point fuzzy number represents the completion time scheme in the case of manager satisfaction. Contrasting triangular fuzzy numbers represent optimal results and stability values under the make-time"
"at the 0.75 confidence level. Table4shows that the six-point fuzzy number represents the completion time scheme in the case of manager satisfaction. Contrasting triangular fuzzy numbers represent optimal results and stability values under the make-time scheme.4.Comparison of optimal results and stability under managerial satisfaction.Six-point fuzzy numberTriangular fuzzy numberSatisfaction value0.8550.645Stability (α= 0.5)0.5680.521Stability (α= 0.75)0.3650.251By comparing the results in Tables4and5, it can be seen that the optimal scheduling scheme obtained by the manager satisfaction and customer satisfaction models designed in this paper is more stable than the optimal scheduling obtained by the model in the previous research at the confidence level of 0.5 and 0.75. Under the same confidence level, in the optimal scheduling scheme obtained by the model designed in this paper, the actual completion time of each workpiece is more likely to be in the excellent area of the theoretical fuzzy completion time, and the consistency between the actual and theoretical scheduling results is also more likely. Therefore, the problem of insufficient stability of the optimization scheme of the scheduling model in which the triangular fuzzy number is used to represent the completion time and the semitrapezoidal fuzzy number to represent the delivery time in the previous research is improved.5.Comparison of optimal results and stability under customer satisfaction.Six-point, trapezoidal"
"fuzzy number is used to represent the completion time and the semitrapezoidal fuzzy number to represent the delivery time in the previous research is improved.5.Comparison of optimal results and stability under customer satisfaction.Six-point, trapezoidal fuzzy numberTriangular, semitrapezoidal fuzzy numbersSatisfaction value0.9651Stability (α= 0.5)0.6090.499Stability (α= 0.75)0.3910.2504.2. System Quality Management FunctionThe main purpose of applying PDCA cycle in the enterprise quality management system is to help enterprises build a logical framework in the process of quality improvement. Only by establishing a rigorous and scientific logical framework can an enterprise maintain stability in long-term operation and continue on this basis to achieve the purpose of quality improvement and promotion. In order to ensure that the enterprise can always maintain the management foundation with quality as the core and maintain a high management level no matter it develops to any stage or period, this paper chooses PDCA cycle as the logical framework of quality management system evaluation.4.3. Overall Performance of the SystemThe nodes used in the 200 experiments in this paper are scattered in an area of 200 m∗200 m. The wireless sensor network composed of these nodes monitors the temperature of the target monitoring area in real time. Each node generates a data packet per second. The experiment assumes that the collected temperature values follow a Gaussian distribution curve."
"sensor network composed of these nodes monitors the temperature of the target monitoring area in real time. Each node generates a data packet per second. The experiment assumes that the collected temperature values follow a Gaussian distribution curve. Simulation experiments include the reliability of data fusion, the accuracy of fusion results, the average energy consumption of nodes, and the communication overhead of the network.4.3.1. Accuracy AnalysisIt can be clearly seen from Figure8(a)that the more the abnormal nodes in the network, the greater the degree of deviation of the obtained results from the actual situation. However, after removing the abnormal node, the collected data is not complete enough, which will cause a certain deviation and cannot reflect the real situation. It can be found from Figure8(b)that when the TGDA algorithm is used, the temperature value in the first 10 rounds is higher than 20°C, but after 10 rounds the temperature value fluctuates around 20°C and gradually becomes stable, because the abnormal node is continuous. The abnormal data is replaced by the predicted data, so the fusion result will gradually tend to the true value.Open in figure viewerPowerPointOpen in figure viewerPowerPoint4.3.2. Energy Consumption AnalysisFigure9shows the comparison of the three algorithms on the average energy consumption of nodes. It can be seen from the figure that the average energy consumption of the nodes of the TWDFM algorithm is the highest. This is"
"Energy Consumption AnalysisFigure9shows the comparison of the three algorithms on the average energy consumption of nodes. It can be seen from the figure that the average energy consumption of the nodes of the TWDFM algorithm is the highest. This is because the TWDFM algorithm focuses on the security of the data fusion results and improves the accuracy of the fusion results, which will increase some additional computation and data transmission, so it is different from the other two. The energy consumption of the model is relatively large compared to this model. The TGDA algorithm will remove abnormal nodes before initiating data fusion.Open in figure viewerPowerPointOpen in figure viewerPowerPoint4.3.3. Reliability ResearchAs shown in Figure10, the nodes in the TWDFM algorithm select reliable cluster head nodes by constructing a trust table and use a weighting mechanism to add abnormal nodes to the blacklist, which greatly reduces the probability of damaged nodes being selected as cluster head probability. However, in the TWDFM and TGDA algorithms, the probability of the damaged node being selected as the cluster head will increase sharply when the proportion of damaged nodes in the network exceeds 75%. The trust mechanism has no effect, and there is no way to ensure that the selected cluster head is reliable.Open in figure viewerPowerPoint5. ConclusionsWith the development of society, the sharing of resources between global supply chains is getting higher and higher, the"
"has no effect, and there is no way to ensure that the selected cluster head is reliable.Open in figure viewerPowerPoint5. ConclusionsWith the development of society, the sharing of resources between global supply chains is getting higher and higher, the competition among enterprises is becoming more and more fierce, and the profits of products in the same industry are becoming more and more transparent, but the requirements of customers are getting higher and higher. How to reduce quality costs and improve quality benefits on the premise of meeting customer product quality requirements, thereby enhancing corporate market competitiveness and stabilizing customer relationships, is a serious problem facing companies today. Customer satisfaction is an important business indicator for the normal and sustainable development of an enterprise. The results of customer satisfaction assessment directly affect the operating efficiency of the company and its reputation in the industry. Many companies unanimously recognize the importance of customer satisfaction. There is still a lot of deficiencies in the analysis and improvement of factors affecting the degree of management. How to analyze and effectively improve is also necessary to combine the theoretical basis of scientific management and the research viewpoints of scholars' literature to carry out practice verification and choose the improvement direction suitable for one's own enterprise and improve customer satisfaction.Conflicts"
"the theoretical basis of scientific management and the research viewpoints of scholars' literature to carry out practice verification and choose the improvement direction suitable for one's own enterprise and improve customer satisfaction.Conflicts of InterestThe authors declare that they have no conflicts of interest.Open ResearchData AvailabilityNo data were used to support this study.References1Ma Q.,Tan L., andLuo P.,Optimal negative-sequence compensation of hybrid power-quality management system for V/v traction substation,Electric Power Automation Equipment. (2017)37, no. 4,128-132.Google Scholar2Başaran B.,The past, present and future ISO 9001 quality management system standard,Business & Management Studies: International Journal. (2021)9, no. 1,227-247,https://doi.org/10.15295/bmij.v9i1.1756.10.15295/bmij.v9i1.1756Google Scholar3Chupikova E.,Antosyuk A., andSayapina T.,AS part of a product quality management system,Fisheries. (2021)2021, no. 3,112-116,https://doi.org/10.37663/0131-6184-2021-3-112-116.10.37663/0131-6184-2021-3-112-116Google Scholar4Kalmutchi P.,SIA quality management system' manual,Incas Bulletin. (2021)13, no. 3,235-243,https://doi.org/10.13111/2066-8201.2021.13.3.20.10.13111/2066-8201.2021.13.3.20Google Scholar5Krupko D. O.andShaburova A. V.,Interexpo GEO-Siberia,2020,6, no. 1,194-199,https://doi.org/10.33764/2618-981x-2020-6-1-194-199.10.33764/2618-981x-2020-6-1-194-199Google Scholar6Zhao S.andMa J.,Research on precision marketing data source"
"Scholar5Krupko D. O.andShaburova A. V.,Interexpo GEO-Siberia,2020,6, no. 1,194-199,https://doi.org/10.33764/2618-981x-2020-6-1-194-199.10.33764/2618-981x-2020-6-1-194-199Google Scholar6Zhao S.andMa J.,Research on precision marketing data source system based on big data,International Journal of Advanced Media and Communication. (2017)7, no. 2,93-100,https://doi.org/10.1504/ijamc.2017.085933, 2-s2.0-85028504681.10.1504/IJAMC.2017.085933CASGoogle Scholar7Bo Z.andZhang B.,Precise marketing of precision marketing value chain process on the H group line based on big data,Journal of Intelligent and Fuzzy Systems. (2018)35, no. 3,2837-2845,https://doi.org/10.3233/jifs-169637, 2-s2.0-85054875094.10.3233/JIFS-169637Web of Science®Google Scholar8Zhang J.,Wu T., andFan Z.,Research on precision marketing model of tourism industry based on user's mobile behavior trajectory,Mobile Information Systems. (2019)2019, no. 4,14, 6560848,https://doi.org/10.1155/2019/6560848, 2-s2.0-85062343486.10.1155/2019/6560848Web of Science®Google Scholar9Li J.andCheng T.,Analysis of precision marketing mode of green food enterprises based on E-business big data platform,Paper Asia. (2018)34, no. 4,56-60.CASGoogle Scholar10Zhang G.,Construction of the college education quality management system based on big data and its evaluation,Agro Food Industry Hi-Tech. (2017)28, no. 1,3124-3127.Google Scholar11Harzli I.,Application to risk management as part of the transition of the quality management system from ISO"
"education quality management system based on big data and its evaluation,Agro Food Industry Hi-Tech. (2017)28, no. 1,3124-3127.Google Scholar11Harzli I.,Application to risk management as part of the transition of the quality management system from ISO 17025 v2005 to ISO 17025 v2017: case of MULTILAB laboratory in Tunisia,Journal of Business and Management Sciences. (2021)9, no. 3,130-144.Google Scholar12Kavalieratou A.,Garofyllou G.,Evangelidou E., andMantzanas M.,Quality management system in a haemodialysis unit and patient satisfaction,SciMedicine Journal. (2021)3, no. 3,209-218,https://doi.org/10.28991/scimedj-2021-0303-2.10.28991/SciMedJ-2021-0303-2Google Scholar13Editorial B.,Correction: quality management system in trade: internationalisation of marketing relations with consumers,Acta Agriculturae Serbica. (2020)25, no. 50,https://doi.org/10.5937/aaser2050199e.10.5937/AASer2050199EGoogle Scholar14Dužević I.,Student satisfaction vs. student achievements--should quality management system in higher education aim at student satisfaction or student achievements?,Poslovna izvrsnost - Business excellence. (2020)14, no. 2,51-67,https://doi.org/10.22598/pi-be/2020.14.2.51.10.22598/pi-be/2020.14.2.51Google Scholar15Chiu M. C.andChuang K. H.,Applying transfer learning to automate annotation in an omni-channel system--a case study of a shared kitchen platform,International Journal of Production Research. (2021)4,1-16.Google Scholar16Zhang W.,Tan G., andSun C.,Design and"
"M. C.andChuang K. H.,Applying transfer learning to automate annotation in an omni-channel system--a case study of a shared kitchen platform,International Journal of Production Research. (2021)4,1-16.Google Scholar16Zhang W.,Tan G., andSun C.,Design and development of an intelligent tourist guide system,Journal of Geomatics. (2018)43, no. 5,79-84.Google Scholar17Hsieh L. C.andChen T. H.,The innovative design of automatic opening/closing gull-wing frame system by morphological chart analysis,Transactions of the Canadian Society for Mechanical Engineering. (2017)41, no. 5,657-668,https://doi.org/10.1139/tcsme-2017-501, 2-s2.0-85058322166.10.1139/tcsme-2017-501Web of Science®Google Scholar18Ge B.,Based on vonstruction design of clothing engineering of full channel marketing system cloud,Wool Textile Journal. (2017)45, no. 5,77-81.Google Scholar19Zhang L.,Li G.,Chen Y.,Sun Z., andTian H.,Customer segmentation and value evaluation method based on data mining for electric vehicles,Dianli Xitong Baohu yu Kongzhi/Power System Protection and Control. (2018)46, no. 22,124-130.CASGoogle Scholar20Agarwal R.,Dugas M.,Gao G. G., andKannan P. K.,Emerging technologies and analytics for a new era of value-centered marketing in healthcare,Journal of the Academy of Marketing Science. (2020)48, no. 1,9-23,https://doi.org/10.1007/s11747-019-00692-4.10.1007/s11747-019-00692-4Web of Science®Google ScholarCiting Literature"
"AbstractThe purpose of this paper is to explore the practical application of big data comprehensive mining and analysis technology in the overall human resource management work of the entire enterprise under the gradual increase in the amount of enterprise data, so as to effectively improve the overall core strategic competitiveness of the entire enterprise and improve the overall human resource management level of the entire enterprise. This article adopts the risk management theory of quantifying the characteristics of business management data, analyzes various management models in modern human resource information system management, and analyzes the entire process of modern enterprise daily operation and various types of human resource system risk management and business data. Combined with quantitative management theory, it introduces the basic concepts of business data feature mining system theory and its most common six data analysis and calculation methods. The module design examples are organically combined, and the traditional data mining analysis theory and its application are extended to the enterprise human resource project management information system. Finally, the experimental results show that the use of big data mining and analysis technology can solve the problems of human resource quality management in small- and medium-sized enterprises. The independent quantitative data mining analysis model has achieved 25% improvement in the application effect of the"
"data mining and analysis technology can solve the problems of human resource quality management in small- and medium-sized enterprises. The independent quantitative data mining analysis model has achieved 25% improvement in the application effect of the analysis of the types of human resources in management enterprises, the prevention of internal talent loss in management enterprises, and the performance evaluation management system of enterprises.1. IntroductionSince China formally joined the WTO, its leading position in the Chinese market economy has gradually become known and recognized by the social world [1]. The market competition among enterprises is becoming fiercer and fiercer, so how to use the market advantages of enterprises to allocate resources has become more important. The market competition of enterprises is actually the market competition of professionals. In the daily management business activities of the manager of the human resources department of an enterprise, such as managerial career development and skill training, position level setting, salary ratio distribution, performance appraisal, employee skill promotion, and other employee responsibility rewards and punishments, they are traditionally used daily. The continuous accumulation of corporate surface management information data in corporate management is used to accurately implement corporate decision-making, so that in large corporate organizations, the proportion of wages is unevenly"
"used daily. The continuous accumulation of corporate surface management information data in corporate management is used to accurately implement corporate decision-making, so that in large corporate organizations, the proportion of wages is unevenly distributed, the performance appraisal is not effective, brain drain and low employee job satisfaction, HR management is often in a passive position [2]. How to effectively realize the real-time dynamic and efficient management of enterprise human resources in China's modern enterprise human resources business management; how to transform various forms of training, employment, unemployment, reuse training, reemployment, selection, elimination, and comprehensive utilization into one management system; etc. require a lot of management information [3]. Since the current traditional type data analysis and query methods can generally only directly obtain the external surface structure information of these types of data but cannot directly obtain the internal data attributes and implicit data information, it is necessary to change the concept, explore the use of data mining theory. The technology intelligently and automatically analyzes these raw data so that a large amount of data information can be used effectively [4]. This paper studies the application of data mining in enterprise human resource management, mainly to find valuable knowledge in human resource management through a large amount of data information, guide practical"
"information can be used effectively [4]. This paper studies the application of data mining in enterprise human resource management, mainly to find valuable knowledge in human resource management through a large amount of data information, guide practical work, and improve enterprise competition in the market [5].There are many scholars who have provided references for the research on enterprise human resource management. Massaro et al. and Gaber et al. emphasize that companies cannot pay attention to their market forecasts and development plans for talents, there is serious brain drain, the development of human resources market economy is not perfect enough, talent training is ignored, and effective talent incentive mechanisms are really scarce [6,7]. Joseph SIT analyzed what kind of value orientation the internal culture of a coal enterprise should have in a good coal enterprise, and then analyzed and put forward some targeted guidance measures to strengthen the internal cultural image of the coal enterprise and the internal human resource culture of the enterprise [8,9]. Romero and Ventura analyze the three major difficulties and development status of human resource training and management of coal enterprises and propose specific solutions and specific management strategies. This paper systematically analyzes and deeply evaluates the current development status of the grassroots talent team of large state-owned coal enterprises and puts forward some policy suggestions to"
"specific solutions and specific management strategies. This paper systematically analyzes and deeply evaluates the current development status of the grassroots talent team of large state-owned coal enterprises and puts forward some policy suggestions to stabilize and continuously strengthen the coal talent team [10]. The article by Cominola focuses on the important humanistic and social values of enterprise human resource management, puts forward various management issues for state-owned enterprises and their owners in the internal human resource management of enterprises, and puts forward some questions about them [11]. Decompose the overall strategic goal management of an enterprise into more specific management personnel work, and grasp the key to realize an enterprise's strategic goals while always maintaining the reliable and sustainable core competitiveness and advantages of the enterprise. Saura and Bennett state that the army can be divided into multiple strategic levels, management level and enterprise operation level. The strategic planning level mainly includes corporate leadership team development strategic plan, human resource team development strategic plan, and corporate organizational capacity development strategic plan [12]. Alloghani et al. recommend that we not only focus on preemployment education, postemployment continuing education, and vocational continuing education, but also organize the on-the-job vocational training of trainees in several stages"
"strategic plan [12]. Alloghani et al. recommend that we not only focus on preemployment education, postemployment continuing education, and vocational continuing education, but also organize the on-the-job vocational training of trainees in several stages and at several levels to improve the work skills of trainees, vocational training assessment work skills, and the quality level of on-the-job training [13-15]. These studies have incomplete experimental data, and the conclusions have yet to be investigated, so they are not suitable for popularization and promotion.Data mining application technology analysis is an effective technical means that is ubiquitous in the collection and mining of massive enterprise data [16,17]. Its wide application in the process of enterprise human resources management is mainly reflected in the collection, analysis, and information processing of employees, and related personal information of large enterprises [18]. They can also help unearth information hidden in deep data. Based on this, in view of the two main problems in the practice of modern human resource data management, this paper introduces a new technology of data mining in detail from the aspect of modern human resources data management [19,20]. Taking some economic measures, such as retaining some potentially important corporate employees, can be considered to greatly reduce the economic losses of these companies. Second, cluster analysis is performed on the data types of the"
"management [19,20]. Taking some economic measures, such as retaining some potentially important corporate employees, can be considered to greatly reduce the economic losses of these companies. Second, cluster analysis is performed on the data types of the existing degree certificate evaluation system using the calculation method of cluster analysis, and Shenyang Digital Co., Ltd. divides the degrees into different types through the calculation method of cluster analysis according to the existing degree evaluation data. Assessing categories, companies in different environments should use different methods in different categories, so that employees can feel the company's care for them, to increase the enthusiasm of employees and thus enhance the cohesion of the company. Finally, this article summarizes the research content, points out its shortcomings, and looks forward to the future research directions.This article first discusses the content and current situation of human resource management information system, analyzes the main problems faced by human resource management information system, and introduces the application and research status of data mining technology in human resource management information system. Currently, there are two problems in human resource management: First, the employee turnover rate is high, and the company does not know which of the existing employees has the intention to leave. Second, the company uses the degree performance appraisal method to"
"there are two problems in human resource management: First, the employee turnover rate is high, and the company does not know which of the existing employees has the intention to leave. Second, the company uses the degree performance appraisal method to assess employees and obtain various types of appraisal data, but there is no effective method to analyze these data effectively, and they cannot support the company's strategic decision-making.2. Related Technology Introduction2.1. Fuzzy Decision Tree AlgorithmAt present, there are many algorithms based on decision tree learning, but the core algorithm still adopts a top-down approach, that is, using a greedy algorithm to search the entire decision tree space. The most successful algorithm using this algorithm idea is the ID3 algorithm, which was proposed by machine learning researchers in 1986. It is a decision tree learning algorithm based on information gain. Since the algorithm was proposed, it has been widely used in various fields; the main application fields of ID3 algorithm are machine learning and natural language processing, but in the application process, it was also found that the ID3 algorithm was not perfect, which led to the research boom of decision tree learning algorithms. The improved algorithm is C4.5. This algorithm not only inherits the advantages of ID3, but also improves its defects. The biggest difference is that C4.5 is based on information acquisition rate. This section mainly introduces a"
"tree learning algorithms. The improved algorithm is C4.5. This algorithm not only inherits the advantages of ID3, but also improves its defects. The biggest difference is that C4.5 is based on information acquisition rate. This section mainly introduces a comparison between ID3 and C4.5.2.1.1. Attribute Selection MeasurementThe attribute selection metric refers to the criterion of selection split, which determines which attribute can be classified best. For the purpose of the classification algorithm, the higher the purity of each partition, the more ideal it is. Therefore, the attribute with the best metric is taken as the decision point. ID3 and C4.5 use information gain and information gain rate as their attribute selection metrics, respectively. The biggest difference between these two algorithms is the attribute selection metric.2.1.2. Information EntropyEntropy was originally a thermodynamic concept. It was interpreted as the expectation of the occurrence of random variables and used to describe the uncertainty of unknown information. The definition of entropy in information theory is as follows: if there are multiple events in systemS, thenS= {E1, ...,En}, the probability distribution of each eventP= {p1...,pn}, and then the amount of information is single. The meaning of the event is as follows:(1)Then, the entropy of the entire system is as follows:(2)For classification problems, the \"category\" is equal to the random variableS, the probability of a category is equal"
"the amount of information is single. The meaning of the event is as follows:(1)Then, the entropy of the entire system is as follows:(2)For classification problems, the \"category\" is equal to the random variableS, the probability of a category is equal toP, andnrepresents the total number of categories. Then, the entropy of the classification system can be expressed as follows:(3)whereCrepresents the category set andcirepresents a value of the setC.2.1.3. Information Gain and Gain RateInformation gain is used to describe the change of information entropy. Suppose the elements inDare divided according to attributeA, attributeAhasmdifferent values {a1,a2,a3, ...,am}, and thenDis divided intoMsubsets {D1,D2,D3,...,Dm}. We always hope that the purity of each division is the most ideal, so the basis of judgment is how much information is needed after division, that is, the information entropy after division:(4)It can be seen that the smaller theHA(D), the more ideal the division, and the higher the purity.The definition of information gain is the difference between the information entropy before division and the information entropy after division; namely,(5)Among them, Gain (A) refers to the information gain after attributeAis divided; that is, the greater the information gain, the higher the purity of the division.The standardized information gain of the gain rate overcomes the shortcomings of information gain. The department is pure, and the information obtained is as"
"divided; that is, the greater the information gain, the higher the purity of the division.The standardized information gain of the gain rate overcomes the shortcomings of information gain. The department is pure, and the information obtained is as follows:(6)The information gain is the greatest. However, such a division is meaningless, because there is only one element under each division, so the classification is meaningless, or overfitting.In order to correct the above offset, we introduce split information to standardize the information gain, which is defined as follows:(7)This formula expresses the information generated by dividingDaccording to attributeA, and each division corresponds tomvalues inA. Finally we define the gain rate:(8)When the segmentation information approaches 0, this ratio will become unstable. In order to solve this problem, we need to add a condition that the information gain of the candidate attribute is not less than the mean value of all information gains.2.1.4. Fuzzy Decision Tree AlgorithmFor a particular thing, its structure is known, and then its set of factorsUcan be determined. The membership degree of each factor in the factor setUto the evaluation setVis obtained by the method of single factor evaluation:(9)From (9), it can be seen that the fuzzy relationship vector between the factorUiand the evaluation setVcan be expressed as follows:(10)From (10), the result of individual evaluation of each factorUican be obtained, that is, the fuzzy"
"factor evaluation:(9)From (9), it can be seen that the fuzzy relationship vector between the factorUiand the evaluation setVcan be expressed as follows:(10)From (10), the result of individual evaluation of each factorUican be obtained, that is, the fuzzy vector of evaluation level of each factor. Combining the fuzzy relationship vectors between all the individual factorsUiandV, we can obtain the fuzzy relationship matrix betweenUandVsets, that is, the fuzzy decision tree matrix used in this article, as in the following formula:(11)Since the weight of each element in the factor setUis often different in the evaluation process of things, in the comprehensive fuzzy evaluation, the influence of each evaluation factor on the evaluation result needs to be considered, that is, the size of the weight. Suppose the influence of the elements of the fuzzy decision tree factor setUon the evaluation result is represented by the following fuzzy vector:(12)The vector in (12) is the weight vector of things evaluation, whereairepresents the degree of membership ofUiinfluence on the evaluation and can also be regarded as a mathematical expression that only considers the influence of the evaluation factorUion the evaluation result.2.2. Data Mining Technology Introduction2.2.1. The Concept of Data MiningWhether it is normal work or daily life, people will never do without the convenience of using computers [21,22]. However, the massive user data generated by the user in the process of using it"
"Technology Introduction2.2.1. The Concept of Data MiningWhether it is normal work or daily life, people will never do without the convenience of using computers [21,22]. However, the massive user data generated by the user in the process of using it still has great commercial development and application value. Therefore, people very much hope to analyze this geographical information accurately, effectively, and reasonably and use the results of these analyses effectively and reasonably through a certain scientific method. Under this urgent market demand, new technologies such as data mining have emerged [23,24]. Data mining related technology research involves many specialized disciplines and professional fields. From the perspective of professional technology application, data mining technology is a process of mining a large amount of unknown professional knowledge and sensitive information hidden in it through data analysis of a large amount of professional data automation. In fact, the research objects of data analysis and mining are often the basic characteristics of very large-scale, rapidly growing, and diversified functions.2.2.2. Current Status of Data Mining\"There is a huge amount of data, but little information is available,\" which is an embarrassment that most online financial service companies often face. In the current industry environment, most of the underlying databases that the financial industry needs to implement can only directly implement some underlying"
"available,\" which is an embarrassment that most online financial service companies often face. In the current industry environment, most of the underlying databases that the financial industry needs to implement can only directly implement some underlying data functions such as input, query, and statistics of the upper database, and it is impossible to automatically find various useful financial pieces of information from these data [25,26]. As a kind of industrial application analysis technology, data mining technology can be accurately said to cover a wide range of applications. Especially in developed countries, the application of new technologies such as data mining is more and more complicated. The data in the network already includes not only network images and digital texts, but also other data streams and other digital streams. It can be said that data mining will definitely become a very important area of economic growth in the next few years, and the application of data analysis and mining technology will become more and more extensive in the future. The research and analysis results show that the data volume of the processors used by enterprises will increase rapidly year by year to a certain extent, reaching a very surprising level of change. Most software companies have hardly encountered the security problem of insufficient data. Excessive duplication and inconsistency of databases can cause a large number of problems. This makes many companies encounter many"
"very surprising level of change. Most software companies have hardly encountered the security problem of insufficient data. Excessive duplication and inconsistency of databases can cause a large number of problems. This makes many companies encounter many problems in how to use and effectively manage these massive data in the execution of corporate decisions [27,28].2.2.3. Data Mining ApplicationBecause enterprise data mining technology can effectively analyze the useful and specific information in enterprise data collection and bring huge political, economic, and social benefits to the entire enterprise organization, mining and analysis technology in big data has become more and more popular. Retail store managers need to accurately analyze and forecast the average sales volume of commodities in the next few years to effectively reduce inventory management costs. Using the latest data mining analysis technology, inventory management costs are only reduced by 3.8% compared with the original inventory level costs. For HSBC, we need to accurately classify the needs of the rapidly growing target customer base, find the most expensive target customer for each new product plan, and reduce product marketing management costs by 30% through the widely used big data mining and analysis technology. Every year, the US Department of Defense Finance needs to quickly find the most likely various fraudulent transactions among millions of fraudulent arms transactions and treat them using"
"30% through the widely used big data mining and analysis technology. Every year, the US Department of Defense Finance needs to quickly find the most likely various fraudulent transactions among millions of fraudulent arms transactions and treat them using its big data mining analysis technology. Conduct in-depth investigations, effectively saving a lot of commercial investigation costs.2.3. Application of Data Mining Technology in Enterprise Human Resource ManagementIn modern machine intelligence learning, the decision tree model is a linear predictive function model; it can represent the linear mapping function relationship between the given attribute value of the object and the attribute value of the given object. Each leaf node in the tree structure abstractly represents a node object, the path of each node branch tree abstractly represents a possible object attribute parameter value, and each leaf child node abstractly corresponds to a child that may have the above two attribute parameter values. The decision tree module has only one type of output; if you need multiple types of output at the same time, you can consider establishing an independent decision tree module to process different single outputs at the same time. Each decision tree represents a decision tree classification structure, and each branch of it classifies the decision object structure of the structure type according to the classification attributes. The decision tree can be constructed directly using"
"Each decision tree represents a decision tree classification structure, and each branch of it classifies the decision object structure of the structure type according to the classification attributes. The decision tree can be constructed directly using the probability function based on the conditions in the calculation. Decision tree analysis adopts new mathematical calculation and analysis methods so that you can quickly obtain more ideal decision results.(1)According to the theory of human resource economics, in reality, some social capital economic management activities of human beings can always be directly described and recorded in the form of economic data; the technical construction of data warehouses and the modeling technology of data mining libraries are the two key technical elements in the construction of enterprise value chain for enterprise data warehouse mining. Generally speaking, data mining mainly has the following six statistical methods: structure description statistics, association and interaction correlation, classification and comprehensive clustering, prediction, optimization and processing of structural analysis equations and modeling.(2)It is precise because the basic characteristics of enterprise human resources are the necessary conditions for enterprises to form their own irreproducible core competitive advantages, so according to the functional modules of enterprise human resources management, different companies need to classify the abilities"
"human resources are the necessary conditions for enterprises to form their own irreproducible core competitive advantages, so according to the functional modules of enterprise human resources management, different companies need to classify the abilities of all employees and conduct a comprehensive analysis of their attributes. To sum up, the general Chinese corporate recruitment human resource control management model can be roughly divided into the following five main modules: corporate recruitment mechanism management, turnover mechanism management, performance mechanism management, salary mechanism management, and training mechanism management. Different corporate human resource decision-making management system modules can have different corporate decision-making management attributes. These decision-making attributes can form a decision tree, analyze and collect human resource management data, and provide management basis for carrying out corresponding management decision-making activities.(3)Basic information classification attributes are gender, age, education level, and region.(4)Recruitment module classification attributes are professional knowledge and skills, professional positioning, behavioral personality, language organization and expression ability, team spirit, and initiative.(5)The classification attributes of the resignation module are benefits, job accomplishment, self-development, fairness, interpersonal communication, identity, etc.(6)Performance module"
"organization and expression ability, team spirit, and initiative.(5)The classification attributes of the resignation module are benefits, job accomplishment, self-development, fairness, interpersonal communication, identity, etc.(6)Performance module classification attributes are performance plan, performance commitment, and performance indicators.(7)The classification attributes of the salary module are department, key positions, job evaluation elements, weights of job evaluation elements, salary levels, title levels, and salary ranges at all levels.(8)The classification attributes of training modules are the division of training objects, the skill mastery of trainers, the division of organization and job types, training costs, and training types.The concept of rough set can effectively abstract the objective environment or abstract external environment into an information system, also known as an attribute-value system. Attribute setting is usually divided into two groups; C and DC represent attribute settings,Drepresents the decision attribute set,A=C∪D, and the requirement isC∩D, that is, the degree and importance of dependence,CandD. Finally, the highest attribute information gain value is obtained according to the calculation result to obtain the decision attribute. Combining the above theories, we can define the classification attributes of all modules of human resources as attributes to complete the settings, and the label attribute selected by the research module of"
"result to obtain the decision attribute. Combining the above theories, we can define the classification attributes of all modules of human resources as attributes to complete the settings, and the label attribute selected by the research module of any classification attribute is set to C, and the other classification attribute modules are used as the decision attribute set, and then the corresponding analysis is carried out to obtain the decision attribute module.3. Experimental Conditions and Procedures3.1. Experimental Data AcquisitionThe data in this article comes from the talent information database of the human resource network. Due to the large amount of historical data in the talent pool, various types, and complex structures, it is necessary to filter the extracted data to ensure the quality of the data. The principle of selection is as follows: the extracted data can reflect the macro connection between job seekers, and the job seeker information must cover people of all backgrounds; in order to reflect the recent trend of job seekers' job selection, attention must be paid to the freshness of job information. The degree, release time, and delivery time are as close as possible to the current time to improve the accuracy of mining rules. According to the above requirements, we choose to represent the data tables in the talent information database, including the basic information table of applicants, the professional skill information table of job applicants with"
"accuracy of mining rules. According to the above requirements, we choose to represent the data tables in the talent information database, including the basic information table of applicants, the professional skill information table of job applicants with educational experience, the position delivery record table of job applicants, this position information table, and the company information form.3.2. Experimental Conditions and ControlSince most statistical analysis techniques are based on strict mathematical theories and highly skilled application techniques, it is difficult for general users to easily master them. If an enterprise wants to achieve the purpose of data mining through relatively simple learning and understanding, then it needs to rely on combining the business logic of a specific industry to implement data mining on the business application platform. The experiment in this paper is carried out on a high-performance computer, using SPSS 22.1 as the statistical software and PyCharm as the model database and preprocessing software for data preservation and preprocessing.1.Comparison of data distribution.Age18-2525-3031-3536-4041-4545-50>50661772295142604023EducationUndergraduate (L)Undergraduate (M)Undergraduate or above (H)988898164Open in figure viewerPowerPoint2.Adjustment of execution parameters.Age554565Education455670Party member506074Marital status6756523.3. Experimental Steps(1)Clarify the mining goals, consider the actual situation of the enterprise's"
"or above (H)988898164Open in figure viewerPowerPoint2.Adjustment of execution parameters.Age554565Education455670Party member506074Marital status6756523.3. Experimental Steps(1)Clarify the mining goals, consider the actual situation of the enterprise's human resource management, and understand the relationship between the above attributes and whether or not to leave based on the title and education of the employees in the enterprise. Investigate employees who may leave from within the enterprise and actively adopt incentive measures for potential leavers, such as raising salaries and changing jobs, to retain professional talents, reduce losses caused by brain drain, and improve the stability of the enterprise workforce.(2)Prepare to mine data, and clarify employee resource connections based on the data provided by the human resource organization(3)Substitute the prepared data into a mature model for experimental verification and comparison.4. Experimental Comparative Analysis4.1. Establishing a Comparison of Decision Trees for Job Search Tendency Analysis(1)The data selected in this article comes from the talent information database of the human resource market information platform, where there are 19 attributes of \"job-seeking tendency,\" with \"gender,\" \"age,\" \"educational background,\" \"political status,\" and \"marital status\" as decision-making attributes. This section randomly selects 2000 job search records as a sample. These job search records are as close as possible to"
"tendency,\" with \"gender,\" \"age,\" \"educational background,\" \"political status,\" and \"marital status\" as decision-making attributes. This section randomly selects 2000 job search records as a sample. These job search records are as close as possible to the current time, including 1,645 job applicants and 471 positions. We use 80% of the data as the training set and 20% of the data as the test set. The data distribution is shown in Table1, and the experimental analysis is shown in Figure1.(2)Confidence is an important indicator to measure the quality of generated rules, and it reflects their accuracy. In the C4.5 algorithm, the default value of confidence is 25%. If you use the default value, too many rules will be generated and the quality of the rules will be uneven. Depending on the specific situation, the recommended confidence level is between 60% and 80%. In other words, the rule is considered effective only when the confidence level is greater than the threshold, as shown in Table2.The degree of improvement is an indicator to measure the reliability of the generated rule, and the intuitive meaning is the correlation between the rule and the target category. Therefore, the degree of promotion is introduced to further control the quality of the generated rules. An improvement degree less than 1 is a negative correlation, indicating that there is a mutually exclusive relationship between the two; a degree greater than 1 indicates a positive correlation, indicating a certain"
"the quality of the generated rules. An improvement degree less than 1 is a negative correlation, indicating that there is a mutually exclusive relationship between the two; a degree greater than 1 indicates a positive correlation, indicating a certain relationship between the two. In general, as long as the degree of improvement is greater than 1, it can be shown in Figure2.Open in figure viewerPowerPointOpen in figure viewerPowerPointOpen in figure viewerPowerPoint4.2. Exploration of Using Data Mining Technology in Human Resource Management(1)In today's market environment, most companies have begun to improve their human resource management level and have established a relatively complete management system and data management system. However, in actual work, the collected relevant data is often only used for corporate report statistics or daily data retrieval, and it is impossible to \"dig\" the value of the data and apply it to human resource management, as shown in Figure3.(2)The establishment of a brain drain risk management data center in large enterprises requires in-depth data analysis and risk management. First of all, we must consider establishing a perfect corporate brain drain risk management mechanism. It can effectively avoid the loss of corporate talents and can effectively reduce the large amount of unnecessary human management fees and capital investment in the human resource management of small- and medium-sized enterprises. Use the corporate brain drain"
"effectively avoid the loss of corporate talents and can effectively reduce the large amount of unnecessary human management fees and capital investment in the human resource management of small- and medium-sized enterprises. Use the corporate brain drain tracking management mechanism to track and analyze the specific resignation basic information of each resigning manager, and organize it into a resignation form, as shown in Figure4.5. ConclusionsIn summary, the gradual analysis and research of the practical application of new technologies such as big data analysis and mining in China's human resource quality management industry will help gradually enhance the internal core competitiveness of the entire Chinese enterprise. Through the introduction of these relevant practical application cases, the effectiveness of enterprise human resource talent management can be significantly improved, more and more outstanding talents that are more suitable for the current strategic development of internal enterprises are recruited, and internal enterprise human resources can be rationally allocated to retain more excellent talents in enterprises and reduce the cost flow rate of enterprise human resources. Therefore, great attention should be paid to the full promotion and application of new technologies such as big data analysis and mining in the internal human resource quality management system of Chinese enterprises in order to effectively promote the stable and healthy development of"
"be paid to the full promotion and application of new technologies such as big data analysis and mining in the internal human resource quality management system of Chinese enterprises in order to effectively promote the stable and healthy development of the entire Chinese enterprise. Data mining analysis technology can indeed play a leading role in an enterprise's long-term human resource operation and management. Using this information technology platform can effectively improve the talent management system of small- and medium-sized enterprises, helping them to establish and improve the risk prediction and evaluation mechanism of layoffs and resignation as soon as possible, rationally allocate human resources, and reduce excessive waste of human resources.Human resource professional management technology has a relatively easy to understand and broad interpretation. It refers to the use of various modern scientific technical methods by enterprises to deal with various related enterprise human resource issues that are common within and outside China's enterprises. It is reasonable and scientifically important. Data mining analysis technology has always played an important guiding role in the development of an enterprise's long-term business strategy and the entire business process, providing valuable professional knowledge for an enterprise's senior business management decision-makers, so that enterprises can obtain greater market profits and unique market competitiveness and"
"business strategy and the entire business process, providing valuable professional knowledge for an enterprise's senior business management decision-makers, so that enterprises can obtain greater market profits and unique market competitiveness and advantages. The great importance of enterprises in promoting the national economic and social development directly determines the great necessity of introducing enterprise data mining technology into Chinese enterprises for human resource management. In view of this, this article puts forward the specific strategy of directly integrating enterprise data mining application technology into modern coal enterprise internal human resource quality management information system. The in-depth research and promotion of this management technology have improved the level of human resource management in enterprises, which can greatly enhance the corporate image, make the company stand out in the complex economic society, and create high economic value. Therefore, it has important technical practical significance and broad international application development prospects.In the reality of the enterprise, the purpose of its work is mainly to give full play to the various subjective initiatives of enterprise people through the organization to carry out long-term and effective vocational training; organization and reasonable deployment of enterprise human resources; and appropriate passive induction, control, and active coordination to change"
"of enterprise people through the organization to carry out long-term and effective vocational training; organization and reasonable deployment of enterprise human resources; and appropriate passive induction, control, and active coordination to change people. The various thoughts, psychology, and social behaviors of the company can fully meet the current and future corporate development strategic needs of the corporate organization and ensure the realization of corporate strategic goals and the maximum benefit of the common development of all members. In this era of knowledge economy development, human resources gradually develop beyond the material production resources of enterprises and enterprise financial management resources and become the important core resources of modern enterprises. Various important key technologies of data analysis and mining also help to effectively analyze and control the processing of massive data, discover the deep data relationships and knowledge between and behind the data, and support and help enterprises in making correct decisions. Therefore, data mining technology can be used to study and explore the business process of an enterprise and provide valuable knowledge for the business decision of the enterprise, so that the enterprise can obtain greater profits and unique competitive advantages. This study uses a small amount of data in the experiment, and the experimental results are not very explanatory, so it is recommended that the"
"decision of the enterprise, so that the enterprise can obtain greater profits and unique competitive advantages. This study uses a small amount of data in the experiment, and the experimental results are not very explanatory, so it is recommended that the experimental data amount be expanded in future research.Conflicts of InterestThe author declares no conﬂicts of interest.Open ResearchData AvailabilityThe data that support the findings of this study are available from the author upon reasonable request.References1Zeebaree S. R. M.,Shukur H. M., andHussan B. K.,Human resource management systems for enterprise organizations: a review,Periodicals of Engineering and Natural Sciences. (2019)7, no. 2,https://doi.org/10.21533/pen.v7i2.428.10.21533/pen.v7i2.428Google Scholar2Huang D.-H.,Tsai C.-H.,Chueh H.-E., andWei L.-Y.,A hybrid model based on EMD-feature selection and random forest method for medical data forecasting,International Journal of Academic Research in Accounting, Finance and Management Sciences. (2020)9, no. 4,https://doi.org/10.6007/ijarafms/v9-i4/6841.10.6007/IJARAFMS/v9-i4/6841Google Scholar3Yang Y.andChen T.,Analysis and visualization implementation of medical big data resource sharing mechanism based on deep learning,IEEE Access. (2019)7, no. 99,156077-156088,https://doi.org/10.1109/access.2019.2949879.10.1109/ACCESS.2019.2949879Google Scholar4Arias M.,Saavedra R.,Marques M. R.,Munoz-Gama J., andSepúlveda M.,Human resource allocation in business process"
"deep learning,IEEE Access. (2019)7, no. 99,156077-156088,https://doi.org/10.1109/access.2019.2949879.10.1109/ACCESS.2019.2949879Google Scholar4Arias M.,Saavedra R.,Marques M. R.,Munoz-Gama J., andSepúlveda M.,Human resource allocation in business process management and process mining,Management Decision. (2018)56, no. 2,376-405,https://doi.org/10.1108/md-05-2017-0476, 2-s2.0-85042375105.10.1108/MD-05-2017-0476Web of Science®Google Scholar5Scuotto V.andShukla S.,Being Innovator or \"Imovator\": Current DilemmaAdascalitei, Dragos. Handbook of Research on Comparative Human Resource Management (Research Handbooks in Business and Management Series),2013, Edward Elgar,Cheltenham, Chris Brewster and Wolfgang Mayrhofer.Google Scholar6Massaro A.,Vitti V.,Lisco P., andGaliano A. N.,A business intelligence platform Implemented in a big data system embedding data mining: a case of study,International Journal of Data Mining & Knowledge Management Process. (2019)09, no. 1,01-20,https://doi.org/10.5121/ijdkp.2019.9101.10.5121/ijdkp.2019.9101CASGoogle Scholar7Gaber M. M.,Aneiba A.,Basurra S., andBatty O. A.,Internet of Things and data mining: from applications to techniques and systems,WIREs Data Mining and Knowledge Discovery. (2019)9, no. 3, e1292,https://doi.org/10.1002/widm.1292, 2-s2.0-85056190992.10.1002/widm.1292Web of Science®Google Scholar8S I. T. J.andThanakumar I.,Survey of data mining algorithm's for intelligent computing system,Journal of Trends in Computer Science and Smart"
"no. 3, e1292,https://doi.org/10.1002/widm.1292, 2-s2.0-85056190992.10.1002/widm.1292Web of Science®Google Scholar8S I. T. J.andThanakumar I.,Survey of data mining algorithm's for intelligent computing system,Journal of Trends in Computer Science and Smart Technology. (2019)01, no. 1,14-23,https://doi.org/10.36548/jtcsst.2019.1.002.10.36548/jtcsst.2019.1.002Google Scholar9Saleem H.,Muhammad K. B.,Saleem S.,Saleem R.,Hussain A., andAslam A. M.,Novel intelligent electronic booking framework for E-business with distributed computing and data mining,IJCSNS. (2019)19, no. 4.Google Scholar10Romero C.andVentura S.,Educational data mining and learning analytics: an updated survey,WIREs Data Mining and Knowledge Discovery. (2020)10, no. 3, e1355,https://doi.org/10.1002/widm.1355.10.1002/widm.1355Web of Science®Google Scholar11Cominola A.,Nguyen K.,Giuliani M., andStewart R. A. H. R. A.,Data mining to uncover heterogeneous water use behaviors from smart meter data,Water Resources Research. (2019)55, no. 11,9315-9333,https://doi.org/10.1029/2019wr024897.10.1029/2019WR024897Web of Science®Google Scholar12Saura J. R.andBennett D. R.,A three-stage method for data text mining: using UGC in business intelligence analysis,Symmetry. (2019)11, no. 4,https://doi.org/10.3390/sym11040519, 2-s2.0-85065488859.10.3390/sym11040519Google Scholar13Alloghani M.,Al-Jumeily D.,Hussain A.,Mustafina J.,Baker T., andAljaaf A. J.,Implementation of machine learning and data mining to improve cybersecurity and"
"no. 4,https://doi.org/10.3390/sym11040519, 2-s2.0-85065488859.10.3390/sym11040519Google Scholar13Alloghani M.,Al-Jumeily D.,Hussain A.,Mustafina J.,Baker T., andAljaaf A. J.,Implementation of machine learning and data mining to improve cybersecurity and limit vulnerabilities to cyber attacks,Nature-Inspired Computation in Data Mining and Machine Learning. (2020) Springer,Cham,47-76,https://doi.org/10.1007/978-3-030-28553-1_3.10.1007/978-3-030-28553-1_3Google Scholar14Gholami H.,Mohamadifar A., andCollins A. L.,Spatial mapping of the provenance of storm dust: application of data mining and ensemble modelling,Atmospheric Research. (2020)233, 104716,https://doi.org/10.1016/j.atmosres.2019.104716.10.1016/j.atmosres.2019.104716Google Scholar15Cui L.,Complex industrial automation data stream mining algorithm based on random Internet of robotic things,Automatika. (2019)60, no. 5,570-579,https://doi.org/10.1080/00051144.2019.1683287.10.1080/00051144.2019.1683287Google Scholar16Liao S. H.andHo C. H.,Mobile payment and mobile application (app) behavior for online recommendations,Journal of Organizational and End User Computing. (2021)33, no. 6,1-26,https://doi.org/10.4018/JOEUC.20211101.oa2.10.4018/JOEUC.20211101.oa2Web of Science®Google Scholar17Hong J. Y.,Ko H.,Mesicek L., andSong M. B.,Cultural intelligence as education contents: exploring the pedagogical aspects of effective functioning in higher education,Concurrency and Computation Practice and Experience. (2019)Hoboken, New"
"Scholar17Hong J. Y.,Ko H.,Mesicek L., andSong M. B.,Cultural intelligence as education contents: exploring the pedagogical aspects of effective functioning in higher education,Concurrency and Computation Practice and Experience. (2019)Hoboken, New Jersey, U.S,https://doi.org/10.1002/cpe.5489, 2-s2.0-85071394518.10.1002/cpe.5489Google Scholar18Singh S. K.andEl-Kassar A.-N.,Role of big data analytics in developing sustainable capabilities,Journal of Cleaner Production. (2019)213,1264-1273,https://doi.org/10.1016/j.jclepro.2018.12.199, 2-s2.0-85059282088.10.1016/j.jclepro.2018.12.199Web of Science®Google Scholar19Tomasevic N.,Gvozdenovic N., andVranes S.,An overview and comparison of supervised data mining techniques for student exam performance prediction,Computers & Education. (2020)143, 103676,https://doi.org/10.1016/j.compedu.2019.103676.10.1016/j.compedu.2019.103676Web of Science®Google Scholar20Abu Saa A.,Al-Emran M., andShaalan K.,Factors affecting students' performance in higher education: a systematic review of predictive data mining techniques,Technology, Knowledge and Learning. (2019)24, no. 4,567-598,https://doi.org/10.1007/s10758-019-09408-7, 2-s2.0-85065046120.10.1007/s10758-019-09408-7Web of Science®Google Scholar21Xl A.,Hao L. A.,Wang W.,Zheng Y.,Lv H., andLv Z.,Big data analysis of the internet of things in the digital twins of smart city based on deep learning,2021,128,167-177.Google Scholar22Lv Z.,Lou R.,Li J., andSingh A. K. H.,Big data analytics for"
"Scholar21Xl A.,Hao L. A.,Wang W.,Zheng Y.,Lv H., andLv Z.,Big data analysis of the internet of things in the digital twins of smart city based on deep learning,2021,128,167-177.Google Scholar22Lv Z.,Lou R.,Li J., andSingh A. K. H.,Big data analytics for 6G-enabled massive internet of things,IEEE Internet of Things Journal. (2021)8, no. 7,5350-5359,https://doi.org/10.1109/jiot.2021.3056128.10.1109/JIOT.2021.3056128Web of Science®Google Scholar23Li L.andZhang J.,Research and analysis of an enterprise E-commerce marketing system under the big data environment,Journal of Organizational and End User Computing. (2021)33, no. 6,1-19,https://doi.org/10.4018/JOEUC.20211101.oa15.10.4018/JOEUC.20211101.oa15CASWeb of Science®Google Scholar24He G.,Enterprise E-commerce marketing system based on big data methods of maintaining social relations in the process of E-commerce environmental commodity,Journal of Organizational and End User Computing. (2021)33, no. 6,1-16,https://doi.org/10.4018/JOEUC.20211101.oa16.10.4018/JOEUC.20211101.oa16Web of Science®Google Scholar25Rajendran S.,Khalaf O. I.,Alotaibi Y., andAlghamdi S.,MapReduce-based big data classification model using feature subset selection and hyperparameter tuned deep belief network,Scientific Reports. (2021)11, no. 1, 24138,https://doi.org/10.1038/s41598-021-03019-y.10.1038/s41598-021-03019-yCASPubMedWeb of Science®Google Scholar26Tavera Romero C. A.,Ortiz J. H.,Khalaf O. I., andRíos Prado A.,Business intelligence: business"
"network,Scientific Reports. (2021)11, no. 1, 24138,https://doi.org/10.1038/s41598-021-03019-y.10.1038/s41598-021-03019-yCASPubMedWeb of Science®Google Scholar26Tavera Romero C. A.,Ortiz J. H.,Khalaf O. I., andRíos Prado A.,Business intelligence: business evolution after industry 4.0,Sustainability. (2021)13, no. 18, 10026,https://doi.org/10.3390/su131810026.10.3390/su131810026Web of Science®Google Scholar27Javed Awan M.,Shafry Mohd Rahim M.,Nobanee H.,Yasin A.,Ibrahim Khalaf O., andIshfaq U.,A big data approach to black Friday sales,Intelligent Automation & Soft Computing. (2021)27, no. 3,785-797,https://doi.org/10.32604/iasc.2021.014216.10.32604/iasc.2021.014216Web of Science®Google Scholar28Lee M.,Mesicek L., andBae K.,AI Advisor Platform for Disaster Response Based on Big Data,CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE. (2021)Hoboken, New Jersey, U.S.Google ScholarCiting Literature"
"AbstractA model for early construction cost prediction is useful for all construction project participants. This paper presents a combination of process-based and data-driven model for construction cost prediction in early project phases. Bromilow's \"time-cost\" model is used as process-based model and general regression neural network (GRNN) as data-driven model. GRNN gave the most accurate prediction among three prediction models using neural networks which were applied, with the mean absolute percentage error (MAPE) of about 0.73% and the coefficient of determinationR2of 99.55%. The correlation coefficient between the predicted and the actual values is 0.998. The model is designed as an integral part of the cost predicting system (CPS), whose role is to estimate project costs in the early stages. The obtained results are used as Cost Model (CM) input being both part of the Decision Support System (DSS) and part of the wider Building Management Information System (BMIS). The model can be useful for all project participants to predict construction cost in early project stage, especially in the phases of bidding and contracting when many factors, which can determine the construction project implementation, are yet unknown.1. IntroductionThe complex cost estimation problem in the field of building construction is the problem which is traditionally burdened by lack of data, uncertainties, and risks, but at the same time very important for the success of a construction project."
"IntroductionThe complex cost estimation problem in the field of building construction is the problem which is traditionally burdened by lack of data, uncertainties, and risks, but at the same time very important for the success of a construction project. Due to all of these, numerous construction projects are faced with significant cost overruns, which are elaborated extensively in the paper. The causes of this condition are complex and are the subject of research presented in this paper and supported by data. One of the causes, which is to be particularly emphasized, is the focal point of this paper. This important cause is an early initial cost prediction, which is often of unsatisfactory accuracy. The reason is the lack of information in the initial stages and the desire to get results in a short time, not going too far into its accuracy and the extent of the consequences such data could have on the project. Such a superficial and inaccurate assessment results in a number of further steps in the project, resulting in multiple negative consequences that could jeopardize the implementation of project goals. The desire of the parties to come up with information about the costs as soon as possible is understandable and will always be present, regardless of the type of project or of its size. Therefore, there is a need to create a reliable cost prediction system.The unsatisfactory and uncertain cost prediction [1] and their overrun in construction projects are a very frequent"
"always be present, regardless of the type of project or of its size. Therefore, there is a need to create a reliable cost prediction system.The unsatisfactory and uncertain cost prediction [1] and their overrun in construction projects are a very frequent [2-4] and not easily solvable problem. Due to the uniqueness, diversity, complexity of projects, and the ever-present risks, establishing the model for enough accurate assessment of the project costs is doubtless a challenging task. That is why for many researchers this problem is often the subject of their research, whereby they use different approaches and methods often for a certain type of buildings and structures [1,5-16]. The aim is to establish as accurate a cost estimation model as possible that would be applied in the initial project phases. The fact that the contracted costs are often exceeded is also evidence of the claim that the cost prediction is in a lot of projects inadequate. The cause may be \"... a heavily experience-based process\" according to Alex et al. (2010) as it is cited in [1], which means that the estimation is not based on scientifically proven methods, then the application of low-accuracy models or inadequate models for the case under consideration, or even intentional miscalculations [3]. Data on cost overruns of completed projects that are the subject of numerous scientific studies are the evidence of a previous claim of the frequency of cost overruns [2-4]. As stated by Žujo et al. [2], one"
"or even intentional miscalculations [3]. Data on cost overruns of completed projects that are the subject of numerous scientific studies are the evidence of a previous claim of the frequency of cost overruns [2-4]. As stated by Žujo et al. [2], one of the reasons is \"...the absence of a thorough expert analysis of conditions, circumstances, and possible risks when concluding a contract.\"There are numerous reasons why research often focuses on construction cost. Cost is factor that can be expressed quantitatively and unambiguously. When conducting research regarding construction costs in different countries, numerous researchers indicate frequent significant cost overruns of many construction projects [3,4,17,18]. Hence, for example, Baloi and Andrew [19] have presented the results of the Morris and Hough [20] research resulting in significantly exceeded costs in 63% of the 1778 projects financed by the World Bank, constructed between 1974 and 1988.The authors in [19] state that cost overrun is more a rule than an exception. Moreover, according to the reports from the World Bank in 2007, road construction in India suffers about 25% of contracted price overrun [21]. According to the research conducted in China [22], where various types of reconstructed structures were considered, the construction contracted price overrun of more than 10% was recorded at 26.39% of the structures and 5-10% at 55.56% of the structures.In Slovenia, a research was conducted on a sample of 92"
"various types of reconstructed structures were considered, the construction contracted price overrun of more than 10% was recorded at 26.39% of the structures and 5-10% at 55.56% of the structures.In Slovenia, a research was conducted on a sample of 92 traffic structures built in the period from 1993 to 1998. The average contracted price overrun was 51% [23]. A similar study was conducted in Australia in the period from 1992 to 1999. 93 structures were analyzed and the cost overrun was recorded in 21 or 22.58% of structures [24].Within the scientific research project conducted in Croatia [25], 333 structures were investigated in the period from 1996 to 1998. Price overrun at 81% of structures was recorded.A similar research was conducted in Bosnia and Herzegovina on 177 structures built from 1995 till 2006. The results indicated that the contracted date was not met in 51.40% of structures and the contracted price was not met in 41.23% of structures [26].It can be concluded that construction cost overrun is present not only in underdeveloped countries and developing countries but also in developed countries. This was also confirmed by Baloi and Andrew [19], stressing that \"... in most developing countries ... the problem is more acute.\" Reasons are surely multifaceted and multilayer and deserve a deeper analysis of the issue.Therefore, estimating construction costs already in the initial stages of the project is the subject of special attention of the researchers, which does"
"more acute.\" Reasons are surely multifaceted and multilayer and deserve a deeper analysis of the issue.Therefore, estimating construction costs already in the initial stages of the project is the subject of special attention of the researchers, which does not lose on the actuality. In doing so, the special attention of the researchers is focused on modeling the interdependence of costs and other variables, primarily on the duration of the construction.Considering the complexity and the significance of the problem, other opportunities should be explored, which have a greater potential for solving such complex tasks, which are undoubtedly integrated management information systems whose prediction cost system should be an integral part.2. The Main Objectives and the Research FrameworkOne of the main objectives of the research is to evaluate the results of applying the proposed combined process-based and data-driven cost estimation model, that is, hybrid model, and compare its accuracy with the results of simple models. The second objective is to propose a basic concept of cost prediction system (CPS) as a part of a Building Management Information System (BMIS), with a more detailed elaboration of NNs module which includes also hybrid models.The recommendation about applying the results of the considered case of the proposed hybrid model in CPS will also be presented.Steps in researching, implementing, and displaying the results are as follows:(1)Review of the existing"
"also hybrid models.The recommendation about applying the results of the considered case of the proposed hybrid model in CPS will also be presented.Steps in researching, implementing, and displaying the results are as follows:(1)Review of the existing references on cost prediction in construction projects.(2)Review of the existing references on CPS ontology basics.(3)Creating a proposal for cost prediction system ontology.(4)Predicting construction costs by using a hybrid process-based and data-driven model.(5)Recommendations for the results' integration into the CPS.3. Literature Review: Construction Cost PredictionThe Australian Bromilow was the first to investigate financial execution in relation to construction time for a total of 329 structures in the building construction area (built in Australia between 1963 and 1967). The research resulted in establishing the so-called \"time-cost\" model (hereinafter BTC or TC model) [27,28]. The simple linear regression analysis method was applied whose suitability was also proven in numerous later researches [18,29]. Despite being originally a \"time-cost\" model, it also served as a template for examining the interdependence between construction costs and construction time. It was noted that construction cost prediction and also cost interdependence with time (as quantitative factors) can be mathematically modeled according to Bromilow \"time-cost\" model by using simple linear regression [2,29]. Furthermore, scientific studies indicate"
"that construction cost prediction and also cost interdependence with time (as quantitative factors) can be mathematically modeled according to Bromilow \"time-cost\" model by using simple linear regression [2,29]. Furthermore, scientific studies indicate that there is a dependency between the contracted construction price/cost and time at various construction markets [3,4,17,18,30].However, the researchers did not only rely on modeling the interdependence of building time costs but have also introduced new predictors, for example, number of floors, gross floor area, type of facility, and type of client. In their research, some researchers emphasized the risk factors that cause cost overruns. Thus, Le-Hoai et al. [4] apply the factor analysis technique to categorize the causes. Ranking of causes in terms of occurrence and severity was conducted. \"Poor site management and supervision, poor project management assistance, financial difficulties of owner, and financial difficulties of contractor are ranked as the first problems.\" Spearman's rank correlation tests do not point out differences in ranking the main causes among three groups of respondents (owners, contractors, and consultants).Multiregression analysis is also applied as a mathematical method. Hence, Alshamrani [5] developed a multiregression model for conceptual initial cost estimation of conventional and sustainable college buildings in North America. The obtained model can predict the initial cost in USD/ft2in"
"as a mathematical method. Hence, Alshamrani [5] developed a multiregression model for conceptual initial cost estimation of conventional and sustainable college buildings in North America. The obtained model can predict the initial cost in USD/ft2in dependence on the following predictors: height of one floor, building space, number of floors, sustainability index (1 for conventional and 2 for sustainable), and structure type.Multiple regression analysis is also used by authors [6] to develop an early parametric model, that is, a model for early cost estimation. The research was based on data for thirty-three real-constructed road tunnel projects. It was concluded that the employed approach using multiple regression analysis is valid for heavy construction projects.In addition to researching the application of regression analysis to estimate the cost of construction projects, another direction of research has been focused on the application of neural networks to obtain expected project costs. Thus, Ahiaga-Dagbui and Smith [1] in their research on 98 water-related construction projects built in Scotland in the period 2007-2011 applied ANN to determine models for cost estimation. Impacts, such as construction site conditions, price changes, purchases, various possible risks, and contractual changes, were taken into account.Separate cost models for normalized target cost and log of target costs were developed. Variable transformation and weight decay regularization were then"
"price changes, purchases, various possible risks, and contractual changes, were taken into account.Separate cost models for normalized target cost and log of target costs were developed. Variable transformation and weight decay regularization were then explored to improve the final model's performance. As a prototype of a wider research, the final model's performance was very satisfactory, demonstrating ANN's ability to capture the interactions between the predictor variables and final cost. Ten input variables, all readily available or measurable at the planning stages for the project, were used within a Multilayer Perceptron Architecture and a quasi-Newton training algorithm [1].El Sawy et al. [31] pointed out that cost prediction is one of the tasks of successful management of construction projects, that is, cost management. Cost prediction is a demanding task. Instead of the usual methods, one should turn to the more sophisticated ways of predicting. In the mentioned research [31], the researchers used the ANN approach to develop a parametric cost-estimating model for site overhead costs. The research was conducted on 52 real-life cases of building projects constructed in Egypt during the seven-year period from 2002 to 2009. N-Connection Professional Software version 2.0 was used for the development of neural network models. The neural network architecture is presented for the estimation of site overhead costs as a percentage of the total project price.When it comes to"
"2009. N-Connection Professional Software version 2.0 was used for the development of neural network models. The neural network architecture is presented for the estimation of site overhead costs as a percentage of the total project price.When it comes to the problem of construction site overhead costs, it is worth noting the quite new research from Poland from 2019 [16] for a few reasons. The authors claim that the \"Construction site overhead costs are key components of cost estimation in construction projects. The estimates are expected to be accurate, but there is a growing demand to shorten the time necessary to deliver cost estimates.\" After considering and then combining several types of neural networks, in order to select the members of the ensemble, the authors developed three models intending to predict a construction site overhead cost index.It was proved that proposed models offer better cost prediction than those based on single neural networks [16].Neural networks are also applied by Petroutsatou, Georgopoulos, Lambropoulos, and Pantouvakis [7] for early cost estimation for 33 twin tunnels with a total length of 46 km in Greece. As first, the authors determined the parameters that affect the temporary/final support and the final cost of tunnel construction, such as geometrical, geological, and data related to quantities of works. After that, the data were analyzed using two neural network types: the first was multilayer feed-forward network (MLFN), and the second"
"and the final cost of tunnel construction, such as geometrical, geological, and data related to quantities of works. After that, the data were analyzed using two neural network types: the first was multilayer feed-forward network (MLFN), and the second was a general regression neural network (GRNN). In the next step, model results have been compared with costs and quantities from the real projects. It was concluded that the usage of developed models leads to fairly accurate cost estimation and quantities of works for road tunnels. It was also concluded that the NNs usage for cost estimation is beneficial, due to NNs capability for modeling nonlinear data relationships.A very interesting artificial neural network (ANN) approach to predicting index of indirect cost of construction projects in Poland was applied in research presented in [32]. Based on the quantitative study of 72 cases of building projects constructed in Poland, \"the factors conditioning indirect costs and the actual costs incurred by enterprises during project implementation\" have been determined [15].Another relevant research was carried out by Juszczyk et al. [8] on a sample of 129 sports field construction projects that have been implemented in Poland in recent years. The possibility and justification of the application of the NN for the assessment of total construction costs for sports' fields were explored. As one of the research tasks was to establish a set of cost predictors, 7 predictors regarding the"
"years. The possibility and justification of the application of the NN for the assessment of total construction costs for sports' fields were explored. As one of the research tasks was to establish a set of cost predictors, 7 predictors regarding the technical and functional characteristics were established. After that, the data were analyzed using two neural network types: multilayer perceptron networks (MLP) and radial base function networks (RBF). By applying Pearson's correlation coefficient between real and predicted values of construction costs and by using the root mean square error (RMSE) as the measure of prediction errors, satisfactory results were established for MLP networks. This proved the applicability of the cost estimation network. In the next step, the analysis for a group of 5 MLP networks was performed and the results were compared. As a comparison measure, Pearson's correlation coefficient was used between the actual and predicted construction cost and the root mean square error (RMSE) as the measure of the prediction errors. The accuracy of the estimation was tested using mean absolute percentage error (MAPE). The best results for all assessors were established for one network. In conclusion, this type of network can be recommended for estimating the sports field construction costs.It was to be expected that the course of modeling development of these interdependencies would be redirected towards the comparison of the accuracy and applicability of the"
"of network can be recommended for estimating the sports field construction costs.It was to be expected that the course of modeling development of these interdependencies would be redirected towards the comparison of the accuracy and applicability of the models obtained using various techniques. In this respect, comparative models obtained by applying different regression techniques without neural networks, as well as using neural networks, supporting vectors, case-based reasoning techniques, and others, have been developed.Kim et al. [9] have been exploring the performance of three cost estimation models. A database of 530 implemented project costs of Korean residential buildings has been used. Three-type techniques have been applied for estimating construction costs and their results have been compared: multiple regression analysis (MRA), neural networks (NNs), and case-based reasoning (CBR). Model performance was measured by the Mean Absolute Error Rate (MAER) as the measure of the difference between estimated and actual construction costs. Comparing results from 40 test data, the best MAER of 2.97% with the 48% of the estimates within 0-2.5% of the actual error rate and 98% within 10% has been established. The CBR model gave MAER of 4.81% with 43% of the estimates within 2.5% and 83% within 10%. In spite of these results, the authors point to slowness in establishing a NN model because of the trial and error process. They point to the need to take into account the"
"model gave MAER of 4.81% with 43% of the estimates within 2.5% and 83% within 10%. In spite of these results, the authors point to slowness in establishing a NN model because of the trial and error process. They point to the need to take into account the compromise between accuracy, speed, and clarity when explaining the cost and choosing an estimation model. In this sense, CBR is considered a better model. Future research is expected to create a hybrid model that would combine different techniques.On the other hand, the research, which was carried by the authors [33], compared the accuracy of cost estimation using two types of models-linear based regression models and vector support vector machines (SVMs) models. The models were applied on a database of 75 buildings built on the territory of the Federation of Bosnia and Herzegovina. The usual estimators, the coefficient of determinationR2, and the mean absolute percentage error (MAPE) were used. MAPE is a measure of accuracy, so a better result was established for SVM which also has a betterR2. The weakness of the SVM model is the speed of convergence in relation to the LR model.From all of the aforementioned, it can be concluded that neither one of the techniques nor one of the estimation models can be considered absolutely the best for all the conditions and circumstances of the construction of this type of structure. Olawe and Sun [34] and Ahsan and Gunawan [35] stated that, despite the availability of various control"
"of the estimation models can be considered absolutely the best for all the conditions and circumstances of the construction of this type of structure. Olawe and Sun [34] and Ahsan and Gunawan [35] stated that, despite the availability of various control techniques and project control software, many construction projects still do not achieve their cost goals.4. Cost Predicting System (CPS) as the Part of Building Management Information System (BMIS)4.1. Basic FrameworkTimely cost estimation of satisfying accuracy is one of the crucial factors that affect project performance and thus represent essential management information for the highest level of management in business systems. In this regard, a cost predicting system (CPS) is proposed as a possible integrative component of the system responsible for improving the effectiveness and effectivity of the construction through cost planning and predicting different levels of detail, phases, and project as a whole. All of these systems are integrated into the Building Management Information System (BMIS) as shown in Figure1.Figure 1Open in figure viewerPowerPointCPS ontology.As the assessment procedures themselves are demanding in terms of required knowledge as well as time-consuming, it is necessary to integrate them into a single information management system that possesses the necessary historical and other data used in these models and forms part of the Decision Support System (DSS) in business construction and project"
"it is necessary to integrate them into a single information management system that possesses the necessary historical and other data used in these models and forms part of the Decision Support System (DSS) in business construction and project systems. Ma et al. [36] point out a large amount of information that is collected on a daily basis, thanks to information systems in construction companies. Authors call them \"reusable legacy information\" and discuss two approaches to their possible use, using general or specialized software.Reflecting on the future development of construction through the prism of past experience and knowledge as well as of new development trends, the integration of separate segments is a development challenge and therefore probably an imperative. The solutions it brings have a synergistic potential with the ability to improve significantly the operational, functional, economic, management, and quality dimensions of the construction. Watson [37] classifies the \"fragmented structure\" into one of the underlying, inherent construction industry problems. Egan [38], in his famous Rethinking Construction, advocates \"... the use of computer modeling to predict the performance for the customer.\" The same author considers one of the goals to be \"annual reductions of 10% in construction cost and construction time.\"It can be argued that the strength and potential of computer modeling, as a technical platform, are unprecedented at the obtained development level."
"considers one of the goals to be \"annual reductions of 10% in construction cost and construction time.\"It can be argued that the strength and potential of computer modeling, as a technical platform, are unprecedented at the obtained development level. What needs to be reexamined is the utilization of such potential and of new possibilities. Again, utilization should be linked to a human factor, that is, lack of readiness, engagement, organizational, and managerial competencies, that is, attitude and commitment to integration. Egan [38] points out that \"... the way forward for achieving the ambition of a modern construction industry lies in commitment.\" Recognizing the benefits that integration can bring and the commitment to integration is a longer-term process that will underpin the future development of construction industry.The development of a unique information management system is inevitable technical support for the operation of an integrated construction system. The authors of this paper advocate an open modular, upgradeable, flexible, and adaptable system that would in its generic form be widely applicable, with the possibility of incremental adaptation and upgrade depending on the local needs. In this regard, it is worth highlighting the developed multimodel-based Management Information System concept as one of the results of the \"Mefisto\" research project presented by Scherer and Schapke in their paper [39]. The conceptual multilevel model of the information"
"it is worth highlighting the developed multimodel-based Management Information System concept as one of the results of the \"Mefisto\" research project presented by Scherer and Schapke in their paper [39]. The conceptual multilevel model of the information system is presented in the paper, in which the third level is foreseen for construction economic (cost and time) and specification models.4.2. CPS OntologyWhen it comes to the starting points for creating the proposed CPS ontology, it is the result of previous and subsequent research of other authors and own research results [1,8,10,18,29,30,33,40].Its essential determinants are as follows:(i)Integration of different models and cost prediction techniques.(ii)Use of historical data for implemented projects.(iii)Valorization of results obtained by applying two or more estimation models.(iv)Foreseeing the application of hybrid models depending on the degree of their development.(v)Integration of output into the Decision Support System (DSS).Although the proposed CPS ontology integrates different models of cost predicting, this paper focuses on NNs due to their specific characteristics and capabilities identified by previous research [7,8,10-12,33,40,41].Based on the above, the following benefits of NNs should be highlighted:(i)Self-learning ability in the training-process.(ii)Knowledge-generalization ability.(iii)Possible prediction on other data sets.(iv)Processing rate.(v)Rate of estimation of a large number of"
"the above, the following benefits of NNs should be highlighted:(i)Self-learning ability in the training-process.(ii)Knowledge-generalization ability.(iii)Possible prediction on other data sets.(iv)Processing rate.(v)Rate of estimation of a large number of variants.(vi)Applicability for problems in which it is difficult to determine the functional dependence between dependent and independent variables.(vii)Good predictive ability in conditions of insecurity and incomplete data.(viii)Prediction based on previous cases and so on.Figure1shows the basic structure of CPS ontology as part of the comprehensive Building Management Information System (BMIS).Although NN also has deficiencies (\"black box\" decisions), it can generally be said that they are more pronounced when it comes to other intelligent techniques applied to cost estimation. Significant contribution in terms of comparing \"intelligent techniques in construction project cost estimation\" was made by Elfaki et al. [10] The authors compared five categories of intelligent cost estimation techniques: Machine Learning Systems (ML) techniques- neural networks and the support vector machine (SVM), Knowledge-Based Systems (KBS) techniques, expert systems and case-based reasoning (CBR), evolutionary systems (ES) used as optimization tools, Agent-Based System (ABS) simulating actions, and interactions and evaluating the effects on the system. Hybrid Systems (HS) is the fifth and perhaps the most challenging category because it"
"(CBR), evolutionary systems (ES) used as optimization tools, Agent-Based System (ABS) simulating actions, and interactions and evaluating the effects on the system. Hybrid Systems (HS) is the fifth and perhaps the most challenging category because it represents a set of different techniques. This enables overcoming the limitations of each individual technique.Thus, for example, the authors list deficiencies of the KBS systems to be \"difficulty of self-learning and time-consuming during the rule acquisition process,\" while for ES somewhat difficult generalization is listed.Based on the above, the proposed CPS ontology was structured, consisting of the following components:(i)Input-data component.(ii)Central-processing component.(iii)Output with the evaluation module.The input part consists of a database of historical project data and an input parameter database. These bases are complex and structured according to certain predetermined criteria (e.g., by category and type of structures or by other defaults), so that data selection can be made according to a variety of criteria. This allows the creation of homogeneous databases that provide accurate time estimation data while processing. The historical database includes data on constructed structures, planned and incurred costs, and time of construction, as well as reasons for cost and deadline overruns (risks). It also includes categories and types of structures, their purpose, and their technical characteristics, for example,"
"constructed structures, planned and incurred costs, and time of construction, as well as reasons for cost and deadline overruns (risks). It also includes categories and types of structures, their purpose, and their technical characteristics, for example, the number of floors, size, surface, type of facade, year of construction or reconstruction, type of client, and type of contract.The input parameter database contains the appropriate parameters that are the inputs in the estimation models and defines the individual features from the historical database. There are, for example, price indices by months and years, currency rates, parameters that determine the technical characteristics of the structure (e.g., various types of facades can be encoded with certain numbers), parameters of the purpose of the structure, parameters related to the type of risk, and type of client and contract.The process part integrates appropriate prognostic software systems that use these data, so that, through processing, the estimated costs for a particular structure based on its characteristics are obtained, and by data processing, a more similar and homogeneous group of previously constructed structures is determined. In the specific case, the processing can be done using one (which is not recommended), two, or more models within the system, and in the evaluation part, the accuracy of the results is compared using statistical indicators (most often it will be MAPE andR2) as the usual measures of"
"can be done using one (which is not recommended), two, or more models within the system, and in the evaluation part, the accuracy of the results is compared using statistical indicators (most often it will be MAPE andR2) as the usual measures of accuracy and suitability of the model. As can be seen from Figure2, the NNs module itself integrates different types of networks (GRNN, MLP, Multilayer Perceptron, RBF NNs, Polynomial NNs, Cascade Correlation NN, Probabilistic NNs, etc.), which are suitable for different data types so that, by processing, the optimal type and network architecture for the structure in question are determined on the homogeneous database as possible. The homogeneity of the base is achieved by a series of parameters, not only by the type of structures but also by the financial value of the investment, similar technical characteristics, the type of client and contract, and so on. The homogeneity of the database positively influences the reliability of the estimation. If necessary, the normalization of the input data is performed. As the result of the processing of a particular database, the optimal network type with all the indicators that define it is obtained. The results are stored in the DSS system and used in cost estimation and future business decisions. In this paper, the GRNN network is presented as part of the NNs of the CPS module. Optimal data processing results would be integrated into the DSS system together with the parameters of the"
"and used in cost estimation and future business decisions. In this paper, the GRNN network is presented as part of the NNs of the CPS module. Optimal data processing results would be integrated into the DSS system together with the parameters of the selected network and data processing architecture (the number of neurons per layer, the number of hidden layers, the activation function, the sigma parameter value, the number of iterations, the conjugate algorithm gradient, the validation method, and other).Figure 2Open in figure viewerPowerPointNNs as part of CPS.One of the future development trends should certainly be sought in the development and application of hybrid models that carry significant synergistic potential in solving cost prediction problems, but also other complex problems.The chosen most accurate result, together with all the relevant features of the processed model, becomes part of the Decision Support System (DSM), which has a complex structure, Cost System (CS) being an integral part of it, while both are part of the wider Building Management Information System (BMIS). Regardless of the choice of modules and techniques, it is clear that such an integrated cost prediction system provides a powerful tool for fast multivariate data processing and evaluation of results and saves time compared to conventional unintegrated partial and time-consuming processes. This is a strong argument for applying such a system as systematic support in making business"
"tool for fast multivariate data processing and evaluation of results and saves time compared to conventional unintegrated partial and time-consuming processes. This is a strong argument for applying such a system as systematic support in making business decisions.5. Predicting Construction Costs by Using Process-Based and Data-Driven Model5.1. MethodsAs the first phase of the investigation, a survey was conducted to collect data for estimated and real construction cost of the structures, construction time (predicted and real), year of the construction, structure type (purpose), construction site region, technical characteristics of the structure, and other data (e.g., about risk factors), but not relevant for this research. Data were collected by the questionnaires and, due to the sensitivity of some data, during face-to-face interviews with project participants (investors, contractors, designers, and construction surveyors). The survey covered one hundred and sixteen structures constructed in the Republic of North Macedonia and in the Republic of Croatia during the last two decades. The database will be described in more detail below. In the next phase of the investigation, the historical data for constructed structures were used in the process for developing the construction cost prediction model.In order to predict the price of the construction accurately, the combination of two types of methods (models) is used: process-based method and data-driven method. The main"
"were used in the process for developing the construction cost prediction model.In order to predict the price of the construction accurately, the combination of two types of methods (models) is used: process-based method and data-driven method. The main difference between process-based models and data-driven (statistical) models is that the process-based models are based on the assumed knowledge of the actual process. Process-based models use the laws of the considered physical process, so that their results have broad applicability. To develop a process-based model, a very good understanding of the process is required, along with accurate and extensive data in order to obtain that analytical law (mathematical formulae) for the process [32].The data-driven (statistical) models are based only on the observed relationships in the data and do not assume knowledge about the laws between the input and output variables in the actual process; they use only the actual values of the input and output variables and need only good selection of relevant independent variables and an appropriate output (dependent) variable which will describe the process well.When the estimations of the parameters for the process-based models are difficult to be obtained, when they are not precise, or when the data for the development of the process-based models are not available, then the data-driven models can be used [32]. In civil engineering, data-driven models became popular because of the increasing"
"to be obtained, when they are not precise, or when the data for the development of the process-based models are not available, then the data-driven models can be used [32]. In civil engineering, data-driven models became popular because of the increasing availability of the data in the construction industry. They make maximal use of the available data, extracting useful relationships and conclusions from the existing data sets.5.2. Process-Based ModelThe process-based model used in this paper for predicting the construction cost is Bromilow's well-known \"time-cost\" model [28], which gives the relation between the construction time and construction price (equation (1)).(1)whereAis the contracted time,Bis the contracted price,Pis the model parameter showing the average time needed for construction of a monetary value, andQis the parameter that shows time dependence of cost change [28].Equation (1) is used in this paper for the relation of contracted time and contracted price and also for real time and real price, because these data are available in the input data:(2)(3)whereA1andB1are contracted time and contracted construction cost, respectively, andA2andB2are real time and real construction cost, respectively.In order to obtain simpler equations for modeling, equations (2) and (3) will be logarithmized:(4)(5)By summing up equations (4) and (5), (6) is obtained:(6)From equation (6), the dependence ofB2(real cost) fromA1,A2, andB1can be obtained:(7)Because of equation (7), as"
"simpler equations for modeling, equations (2) and (3) will be logarithmized:(4)(5)By summing up equations (4) and (5), (6) is obtained:(6)From equation (6), the dependence ofB2(real cost) fromA1,A2, andB1can be obtained:(7)Because of equation (7), as input data for the artificial neural network used in this paper, the actual values for real price, real time, contracted price, and contracted time are not used, but logarithm of their values.5.3. Data-Driven ModelThe data-driven model used in this paper is artificial neural network (ANN), more specifically, general regression neural network (GRNN), which will be described below.Over the last two decades, artificial neural networks (ANNs) were of great interest in civil engineering, because they have demonstrated very good and often very accurate solutions to the wide range of complex nonlinear computation problems from many branches of civil engineering [40,42]. ANNs are empirically derived modeling methods and versatile predictors that are being trained using a comprehensive set of examples of the problem, which is being solved, and their target solutions. Inspired by biological neural systems, they learn from experience, that is, from many input patterns and their appropriate outputs. The success of ANN applications depends mostly on selecting appropriate type and structure of the NN for solving the problem and the quality of the data used for training of the ANN.For different type of data, different type of ANN or modeling"
"outputs. The success of ANN applications depends mostly on selecting appropriate type and structure of the NN for solving the problem and the quality of the data used for training of the ANN.For different type of data, different type of ANN or modeling method will be suitable. Several types of modeling methods should be always tested in order to choose the one which will give the most accurate results. In this research, multilayer perceptron (MLP), radial basis function (RBF), and general regression neural network (GRNN) were tested and the most accurate predicting was obtained using GRNN.5.4. General Regression Neural Network (GRNN)GRNN is a neural network with a highly parallel structure that provides estimation of numerical variables and converges to a linear or nonlinear regression surface. This NN can be used for any nonlinear regression problem, for prediction, mapping, and modeling, or as a controller [43].GRNN needs only a few training samples in order to converge to the basic function of the data, which makes this NN be very useful tool for application in practice, particularly for sparse data.GRNN is very similar to RBF (radial basis function NN) with many nodes and, in comparison with well-known MLP NN (multilayer perceptron NN), it is faster to train and in many cases more accurate, but it is slower than MLP at classification of new cases and needs more memory space for storing the model.The basic regression equation, from the statistical theory, is(8)E[y/X] is"
"perceptron NN), it is faster to train and in many cases more accurate, but it is slower than MLP at classification of new cases and needs more memory space for storing the model.The basic regression equation, from the statistical theory, is(8)E[y/X] is the conditional expectation ofyfor givenXandf(X,y) is the joint probability density function (jpdf) of the vectorXand scalary. When the functionf(X,y) is not known, it is being estimated from any of the Parzen estimators [44] using a finite set of observations ofXandyand Gaussian Kernel [43]:(9)wherepis the dimension of the input vectorX, n is the number of training samples,σis the smoothing parameter,Xis the input vector for whichyshould be estimated, Xiis i-th training sample, and Yiis the appropriate measured value ofy.The integration overyin equation (8) can be computed by substitution equation (9) in equation (8), and the obtained estimation forYis given in equation (10) [45].(10)The architecture of GRNN is shown in Figure3[46]. There is the same number of neurons in the input layer as predictor variables and input neurons feed the values of input variables to the neurons in the hidden layer. Each neuron from the hidden layer contains the data for each row (case) from the training set, that is, the values of all predictors and target value for one case. The hidden layer computes the Euclidean distance of the test case from the neuron's center and applies kernel RBF function. The resulting value is fed to the next pattern"
"training set, that is, the values of all predictors and target value for one case. The hidden layer computes the Euclidean distance of the test case from the neuron's center and applies kernel RBF function. The resulting value is fed to the next pattern layer. Pattern layer has only two neurons: numerator summation unit which for each hidden neuron adds up the weight values multiplied by the actual value of the target variable and denominator summation unit which adds up the weight values from the hidden neurons. The value from the numerator summation unit is divided by the value from the denominator summation unit in the decision layer.Figure 3Open in figure viewerPowerPointGRNN architecture [46].In the next section, the results for the prediction is going to be presented.5.5. DatabaseDatabase consists of 116 structures data, built on the territory of the Republic of North Macedonia, 75 in total, and 41 built on the territory of the Republic of Croatia during the last two decades. The database consists of 51 buildings data, 53 construction structures, and 12 others (e.g., gas stations, multilevel car parking, electrical substations, and storage buildings). For future research, homogenization of bases is recommended to obtain more accurate results. In this research, the focus was on the number of cases in the database and the analysis and comparison of multiple models with an emphasis on the evaluation of the hybrid model.6. ResultsFor modeling the data and predicting the"
"more accurate results. In this research, the focus was on the number of cases in the database and the analysis and comparison of multiple models with an emphasis on the evaluation of the hybrid model.6. ResultsFor modeling the data and predicting the real construction price, general regression neural network (GRNN) from the predicting modeling software DTREG [46,47] was used. The standard estimators of the model, the mean absolute percentage error (MAPE), and the coefficient of determinationR2which reflects the overall fit of the model are MAPE = 0.73% andR2= 99.55%. The coefficient of correlation between actual and predicted values of the target variable is 0.998 (Table1, Validation data).Table  1.Results for the training and validation data (DTREG software).Estimators of the model accuracy (DTREG)ValueTraining dataMean target value for input data13.358369Mean target value for predicted values13.356284Variance in input data4.4677631Residual variance after model fit0.0024144Proportion of variance explained by modelR20.99946 (99.946%)Coefficient of variation (CV)0.003678Normalized mean square error (NMSE)0.000540Correlation between actual and predicted R0.999731Maximum error0.3219897RMSE (root mean squared error)0.0491365MSE (mean squared error)0.0024144MAE (mean absolute error)0.0288461MAPE (mean absolute percentage error)0.2199448Validation dataMean target value for input data13.358369Mean target value for predicted values13.35876Variance in input data4.4677631Residual"
